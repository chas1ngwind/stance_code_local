{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "# torch.cuda.empty_cache()\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "# from pytorch_pretrained_bert.tokenization import BertTokenizer, WordpieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_classifier import ColaProcessor, MrpcProcessor, logger, convert_examples_to_features,\\\n",
    "    set_optimizer_params_grad, copy_optimizer_params_to_model, accuracy, p_r_f1, tp_pcount_gcount, convert_claims_to_features, convert_pers_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "#     device = torch.device(\"cpu\")\n",
    "    print('There are %d GPU(s) available.' % n_gpu)\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2020 22:50:08 - INFO - transformers.file_utils -   PyTorch version 1.4.0 available.\n",
      "05/27/2020 22:50:10 - INFO - transformers.file_utils -   TensorFlow version 2.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertPreTrainedModel, BertModel, BertConfig\n",
    "from torch.nn import BCEWithLogitsLoss, CosineEmbeddingLoss,CrossEntropyLoss, MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_and_test(data_dir, bert_model=\"bert-base-uncased\", task_name=None,\n",
    "#                    output_dir=None, max_seq_length=128, do_train=False, do_eval=False, do_lower_case=False,\n",
    "#                    train_batch_size=32, eval_batch_size=8, learning_rate=5e-5, num_train_epochs=3,\n",
    "#                    warmup_proportion=0.1,no_cuda=False, local_rank=-1, seed=42, gradient_accumulation_steps=1,\n",
    "#                    optimize_on_cpu=False, fp16=False, loss_scale=128, saved_model=\"\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForConsistencyCueClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_labels=2):\n",
    "        super(BertForConsistencyCueClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size*3, num_labels)\n",
    "        self.classifier2 = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "        self.apply(self.init_bert_weights)\n",
    "#         self.init_weights()\n",
    "\n",
    "#     @add_start_docstrings_to_callable(BERT_INPUTS_DOCSTRING)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        input_ids2=None,\n",
    "        attention_mask2=None,\n",
    "        token_type_ids2=None,\n",
    "        position_ids2=None,\n",
    "        head_mask2=None,\n",
    "        inputs_embeds2=None,\n",
    "        labels2=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n",
    "            Labels for computing the sequence classification/regression loss.\n",
    "            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n",
    "            If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "\n",
    "    Returns:\n",
    "        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.BertConfig`) and inputs:\n",
    "        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n",
    "            Classification (or regression if config.num_labels==1) loss.\n",
    "        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`):\n",
    "            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
    "        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
    "            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
    "\n",
    "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n",
    "            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n",
    "\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        from transformers import BertTokenizer, BertForSequenceClassification\n",
    "        import torch\n",
    "\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "\n",
    "        loss, logits = outputs[:2]\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        _, outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "#             position_ids=position_ids,\n",
    "#             head_mask=head_mask,\n",
    "#             inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        _, outputsC = self.bert(\n",
    "            input_ids2,\n",
    "            attention_mask=attention_mask2,\n",
    "            token_type_ids=token_type_ids2,\n",
    "#             position_ids=position_ids2,\n",
    "#             head_mask=head_mask2,\n",
    "#             inputs_embeds=inputs_embeds2,\n",
    "        )\n",
    "#         print(\"Careful, outputs:\")\n",
    "#         print(outputs)\n",
    "#         print(outputsC)\n",
    "        pooled_output = outputs\n",
    "        pooled_outputC = outputsC\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_outputC = self.dropout(pooled_outputC)\n",
    "        \n",
    "#         cos_pooled_outputs = torch.cosine_similarity(pooled_output, pooled_outputC, dim=1)\n",
    "        final_output_cat = torch.cat((pooled_output, pooled_outputC))\n",
    "        final_output_minus = torch.abs(pooled_output-pooled_outputC)\n",
    "#         final_output_mult = torch.mul(pooled_output, pooled_outputC)\n",
    "#         final_output_mimu = torch.cat((final_output_minus, final_output_mult))\n",
    "#         final_output_camu = torch.cat((final_output_cat, final_output_mult))\n",
    "        final_output_cami = torch.cat((final_output_cat, final_output_minus))\n",
    "#         final_output_camimu = torch.cat((final_output_cat, final_output_minus, final_output_mult))\n",
    "#         1\n",
    "#         torch.Size([64, 768])\n",
    "#         2\n",
    "#         torch.Size([32, 768])\n",
    "#         3\n",
    "#         torch.Size([32, 768])\n",
    "#         4\n",
    "#         torch.Size([64, 768])\n",
    "#         5\n",
    "#         torch.Size([96, 768])\n",
    "#         6\n",
    "#         torch.Size([96, 768])\n",
    "#         7\n",
    "#         torch.Size([128, 768])\n",
    "#         print(1)\n",
    "#         print(final_output_cat.size())\n",
    "#         print(2)\n",
    "#         print(final_output_minus.size())\n",
    "#         print(3)\n",
    "#         print(final_output_mult.size())\n",
    "#         print(4)\n",
    "#         print(final_output_mimu.size())\n",
    "#         print(5)\n",
    "#         print(final_output_camu.size())\n",
    "#         print(6)\n",
    "#         print(final_output_cami.size())\n",
    "#         print(7)\n",
    "#         print(final_output_camimu.size())\n",
    "        \n",
    "        \n",
    "#         print('pooled_output size:')\n",
    "#         print(pooled_output.size())\n",
    "#         print(pooled_output)\n",
    "#         print('cos_pooled_outputs size:')\n",
    "#         print(cos_pooled_outputs.size())\n",
    "#         print(cos_pooled_outputs)\n",
    "        batch_size = list(pooled_output.size())[0]\n",
    "        hidden_size = list(pooled_output.size())[1]\n",
    "\n",
    "        logits_ce = self.classifier2(pooled_output)\n",
    "        print('logits_ce:')\n",
    "        print(logits_ce)\n",
    "        \n",
    "    \n",
    "        ## v2: concat\n",
    "        ## v3: multiply\n",
    "        ## v4: v2 & ce_cos_similarity\n",
    "        ## v5: v3 & ce_cos_similarity\n",
    "        \n",
    "#         print(torch.cat((pooled_output, cos_pooled_outputs.unsqueeze(1)),1))\n",
    "#         print((pooled_output*cos_pooled_outputs.unsqueeze(1)))\n",
    "#         logits_cos = self.classifier(torch.cat((pooled_output, cos_pooled_outputs.unsqueeze(1)),1))\n",
    "#         logits_cos = self.classifier2((pooled_output*cos_pooled_outputs.unsqueeze(1)))\n",
    "#         self.classifier = torch.nn.Linear(hidden_size+batch_size, 2).to(device)\n",
    "#         logits_cos = self.classifier(torch.cat((pooled_output, cos_pooled_outputs.repeat(batch_size,1)),1))\n",
    "#         print('logits_cos:')\n",
    "#         print(logits_cos)\n",
    "        \n",
    "#         logits = self.classifier(pooled_output)\n",
    "#         logitsC = self.classifier(pooled_outputC)\n",
    "\n",
    "#         outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "#         print(logits)\n",
    "#         print('xd')\n",
    "#         print(outputs[2:])\n",
    "#         outputs = (logits,) + outputs[2:]\n",
    "#         print(\"labels:\")\n",
    "#         print(labels)\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "#                 loss_fct_ce = CrossEntropyLoss()\n",
    "#                 loss_ce = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "                loss_fct_ce = CrossEntropyLoss()\n",
    "#                 print('pooled_output size:')\n",
    "#                 print(pooled_output.size())\n",
    "                loss_ce = loss_fct_ce(logits_ce.view(-1, self.num_labels), labels.view(-1))\n",
    "#                 loss_ce = loss_fct_ce(pooled_output.view(-1), labels.view(-1))\n",
    "                print('loss_ce:')\n",
    "                print(loss_ce)\n",
    "\n",
    "                \n",
    "#                 loss_fct_cos = CosineEmbeddingLoss()\n",
    "# #                 print(labels)\n",
    "# #                 print(pooled_outputC)\n",
    "\n",
    "\n",
    "#                 labels2[labels2==0] = -1\n",
    "#                 loss_cos = loss_fct_cos(pooled_output, pooled_outputC, labels2)\n",
    "#                 labels2[labels2==-1] = 0\n",
    "        \n",
    "# #                 loss_cos = loss_fct_cos(logits_ce, logits_cos, labels2)\n",
    "# #                 loss_cos = loss_fct_ce(logits_cos.view(-1, self.num_labels), labels2.view(-1))\n",
    "#                 print('loss_cos:')\n",
    "#                 print(loss_cos)\n",
    "            \n",
    "                loss = loss_ce\n",
    "                print('final loss:')\n",
    "                print(loss)\n",
    "#                 logits = self.classifier(loss)\n",
    "#             outputs = (loss,) + outputs\n",
    "#             outputs = (loss,) + logits_cos \n",
    "                outputs = loss\n",
    "                return outputs\n",
    "        else:\n",
    "            return logits_ce\n",
    "        \n",
    "          # (loss), logits, (hidden_states), (attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labe = torch.ones(8)\n",
    "# print(labe )\n",
    "# labe[labe==1] = -1\n",
    "# labe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.tensor([[4.2,5,6,7,8],[9,10,11,12,13]])\n",
    "# b = torch.tensor([[3.4,5,6,7,8],[9,10,11,12,13]])\n",
    "\n",
    "# # a = torch.tensor([[4,5,6,7,8],[9,10,11,12,13]])\n",
    "# # b = torch.tensor([1,2])\n",
    "# c= torch.cosine_similarity(a,b,dim=1)\n",
    "# # b.unsqueeze(1)\n",
    "# # # a.size()\n",
    "# # torch.cat((a,c.unsqueeze(1)),1)\n",
    "# a*c.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input1 = torch.randn(100, 128)\n",
    "# input2 = torch.randn(100, 128)\n",
    "# output = torch.cosine_similarity(input1, input2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2020 22:50:12 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\arsen\\.cache\\torch\\transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2020 22:50:14 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\arsen\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "05/27/2020 22:50:14 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file C:\\Users\\arsen\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\arsen\\AppData\\Local\\Temp\\tmpmqsnqj0q\n",
      "05/27/2020 22:50:18 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/27/2020 22:50:21 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForConsistencyCueClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias', 'classifier2.weight', 'classifier2.bias']\n",
      "05/27/2020 22:50:21 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForConsistencyCueClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForConsistencyCueClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=2304, out_features=2, bias=True)\n",
       "  (classifier2): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare model \n",
    "model = BertForConsistencyCueClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 203 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "classifier.weight                                          (2, 2304)\n",
      "classifier.bias                                                 (2,)\n",
      "classifier2.weight                                          (2, 768)\n",
      "classifier2.bias                                                (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "    \n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2020 22:50:22 - INFO - run_classifier -   LOOKING AT D:/Jupyter/data/dataset/perspective_stances/train.tsv\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"D:/Jupyter/data/dataset/perspective_stances/\"\n",
    "data_dir_output = \"D:/Projects/Stance/Models/Consistency_Cues/\"\n",
    "output_dir=data_dir_output\n",
    "max_seq_length=32\n",
    "max_grad_norm = 1.0\n",
    "num_training_steps = 1000\n",
    "num_warmup_steps = 100\n",
    "warmup_proportion = float(num_warmup_steps) / float(num_training_steps)  # 0.1\n",
    "# warmup_proportion = 0.1\n",
    "# train_batch_size=32\n",
    "train_batch_size=16\n",
    "eval_batch_size=8\n",
    "learning_rate=5e-5\n",
    "num_train_epochs=3\n",
    "local_rank=-1\n",
    "seed=42\n",
    "gradient_accumulation_steps=1\n",
    "loss_scale=128\n",
    "train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "\n",
    "processors = {\n",
    "        \"mrpc\": MrpcProcessor,\n",
    "    }\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "processor = processors['mrpc']()\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)\n",
    "# print('label list')\n",
    "# print(label_list)\n",
    "\n",
    "train_examples = processor.get_train_examples(data_dir)\n",
    "num_train_steps = int(\n",
    "    len(train_examples) / train_batch_size / gradient_accumulation_steps * num_train_epochs)\n",
    "\n",
    "##preprare optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "t_total = num_train_steps\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=learning_rate,\n",
    "                         warmup=warmup_proportion,\n",
    "                         t_total=t_total)\n",
    "# optimizer = AdamW(optimizer_grouped_parameters,\n",
    "#                   lr = learning_rate, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "#                   eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n",
    "#                   correct_bias=False\n",
    "#                 )\n",
    "\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)  # PyTorch scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/27/2020 22:50:22 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   guid: train-1\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP]\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   guid: train-2\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP]\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   guid: train-3\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP]\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   guid: train-4\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   tokens: [CLS] punishment should fit the criminal [SEP]\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   input_ids: 101 7750 2323 4906 1996 4735 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   guid: train-5\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   tokens: [CLS] punishment should fit the criminal [SEP]\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   input_ids: 101 7750 2323 4906 1996 4735 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:22 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:23 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:23 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   *** Perspective Example ***\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   guid: train-1\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   tokens: [CLS] parents have the right to use their best judgment , in the light of medical advice , as to what is in the best interest of their child [SEP]\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   input_ids: 101 3008 2031 1996 2157 2000 2224 2037 2190 8689 1010 1999 1996 2422 1997 2966 6040 1010 2004 2000 2054 2003 1999 1996 2190 3037 1997 2037 2775 102 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   *** Perspective Example ***\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   guid: train-2\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   tokens: [CLS] parents know what best for th ##ier child [SEP]\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   input_ids: 101 3008 2113 2054 2190 2005 16215 3771 2775 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   *** Perspective Example ***\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   guid: train-3\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   tokens: [CLS] parents have the right to make the decisions for their child [SEP]\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   input_ids: 101 3008 2031 1996 2157 2000 2191 1996 6567 2005 2037 2775 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   *** Perspective Example ***\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   guid: train-4\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   tokens: [CLS] it will cause less re - offenders . [SEP]\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   input_ids: 101 2009 2097 3426 2625 2128 1011 19591 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   *** Perspective Example ***\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   guid: train-5\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   tokens: [CLS] adequate punishment reduces future offenses . [SEP]\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   input_ids: 101 11706 7750 13416 2925 25173 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/27/2020 22:50:24 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/27/2020 22:50:26 - INFO - run_classifier -   ***** Running training *****\n",
      "05/27/2020 22:50:26 - INFO - run_classifier -     Num examples = 7007\n",
      "05/27/2020 22:50:26 - INFO - run_classifier -     Batch size = 24\n",
      "05/27/2020 22:50:26 - INFO - run_classifier -     Num steps = 875\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "claim_features = convert_claims_to_features(train_examples, label_list, max_seq_length, tokenizer)\n",
    "train_features = convert_pers_to_features(train_examples, label_list, max_seq_length, tokenizer)\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "\n",
    "claims_input_ids = torch.tensor([f.input_ids for f in claim_features], dtype=torch.long)\n",
    "claims_input_mask = torch.tensor([f.input_mask for f in claim_features], dtype=torch.long)\n",
    "claims_segment_ids = torch.tensor([f.segment_ids for f in claim_features], dtype=torch.long)\n",
    "claims_label_ids = torch.tensor([f.label_id for f in claim_features], dtype=torch.long)\n",
    "\n",
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, claims_input_ids, claims_input_mask, claims_segment_ids, claims_label_ids)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
    "\n",
    "# claims_data = TensorDataset(claims_input_ids, claims_input_mask, claims_segment_ids, claims_label_ids)\n",
    "# claims_sampler = RandomSampler(claims_data)\n",
    "# claims_dataloader = DataLoader(claims_data, sampler=train_sampler, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                                                               | 0/292 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.5682,  0.4962],\n",
      "        [ 0.8382, -0.0029],\n",
      "        [ 1.2075,  0.3548],\n",
      "        [ 1.1347,  0.4528],\n",
      "        [ 0.6349,  0.2852],\n",
      "        [ 0.1978,  0.0209],\n",
      "        [ 1.2417,  0.2353],\n",
      "        [ 0.9766,  0.3450],\n",
      "        [ 0.7621,  0.1910],\n",
      "        [ 0.9718,  0.2926],\n",
      "        [ 1.0185,  0.2992],\n",
      "        [ 0.9080,  0.4186],\n",
      "        [ 0.9509,  0.6817],\n",
      "        [ 1.4224,  0.3140],\n",
      "        [ 0.2798, -0.3070],\n",
      "        [ 1.0768,  0.4200],\n",
      "        [ 0.6680,  0.1469],\n",
      "        [ 0.6982,  0.3754],\n",
      "        [ 0.4612,  0.1361],\n",
      "        [ 1.4902,  0.5567],\n",
      "        [ 1.0488,  0.4561],\n",
      "        [ 1.0867,  0.5935],\n",
      "        [ 0.8491,  0.4162],\n",
      "        [ 0.6271,  0.2939]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.9434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "final loss:\n",
      "tensor(0.9434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "out_results:\n",
      "tensor(0.9434, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   0%|▏                                                                      | 1/292 [00:01<07:21,  1.52s/it]\u001b[A\n",
      "Epoch:   0%|                                                                                     | 0/3 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 2.92 GiB already allocated; 7.80 MiB free; 3.05 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-324d50c589de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#         print(\"end\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mout_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_segment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_label_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;31m#         loss = ce_loss + cos_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"out_results:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-8aef70e76245>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, input_ids2, attention_mask2, token_type_ids2, position_ids2, head_mask2, inputs_embeds2, labels2)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0minput_ids2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;31m#             position_ids=position_ids2,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;31m#             head_mask=head_mask2,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[0;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[0;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[0;32m    734\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1372\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1373\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 2.92 GiB already allocated; 7.80 MiB free; 3.05 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids, claim_input_ids, claim_input_mask, claim_segment_ids, claim_label_ids = batch\n",
    "#         ce_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "#         cos_loss = model(claim_input_ids, claim_segment_ids, claim_input_mask, claim_label_ids)\n",
    "        \n",
    "#         print(\"start\")\n",
    "#         print(input_ids)\n",
    "#         print(input_mask)\n",
    "#         print(segment_ids)\n",
    "#         print(label_ids)\n",
    "#         print(claim_input_ids)\n",
    "#         print(claim_input_mask)\n",
    "#         print(claim_segment_ids)\n",
    "#         print(claim_label_ids)\n",
    "#         print(\"end\")\n",
    "    \n",
    "        out_results = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, labels=label_ids, input_ids2=claim_input_ids, token_type_ids2=claim_segment_ids, attention_mask2=claim_input_mask, labels2=claim_label_ids)\n",
    "#         loss = ce_loss + cos_loss\n",
    "        print(\"out_results:\")\n",
    "        print(out_results)\n",
    "        loss = out_results\n",
    "#         print(cos_loss)\n",
    "#         print(loss.item())\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "#         if fp16 and loss_scale != 1.0:\n",
    "#             # rescale loss for fp16 training\n",
    "#             # see https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html\n",
    "#             loss = loss * loss_scale\n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "#             if fp16 or optimize_on_cpu:\n",
    "#                 if fp16 and loss_scale != 1.0:\n",
    "#                     # scale down gradients for fp16 training\n",
    "#                     for param in model.parameters():\n",
    "#                         if param.grad is not None:\n",
    "#                             param.grad.data = param.grad.data / loss_scale           \n",
    "#                 is_nan = set_optimizer_params_grad(param_optimizer, model.named_parameters(), test_nan=True)\n",
    "#                 if is_nan:\n",
    "#                     logger.info(\"FP16 TRAINING: Nan in gradients, reducing loss scaling\")\n",
    "#                     loss_scale = loss_scale / 2\n",
    "#                     model.zero_grad()\n",
    "#                     continue \n",
    "#                 optimizer.step()\n",
    "# #                 scheduler.step()\n",
    "#                 copy_optimizer_params_to_model(model.named_parameters(), param_optimizer)\n",
    "#             else:\n",
    "#                 torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "#                 scheduler.step()\n",
    "            model.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "        \n",
    "## v2: concat\n",
    "## v3: multiply\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "torch.save(model.state_dict(), output_dir + \"siamese_bert.pth\")\n",
    "torch.save(model_to_save.state_dict(), output_dir + \"siamese_bert.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "def train_and_test(data_dir, bert_model=\"bert-base-uncased\", task_name=None,\n",
    "                   output_dir=None, max_seq_length=32, do_train=False, do_eval=False, do_lower_case=False,\n",
    "                   train_batch_size=32, eval_batch_size=8, learning_rate=5e-5, num_train_epochs=3,\n",
    "                   warmup_proportion=0.1,no_cuda=False, local_rank=-1, seed=42, gradient_accumulation_steps=1,\n",
    "                   optimize_on_cpu=False, fp16=False, loss_scale=128, saved_model=\"\"):\n",
    "\n",
    "\n",
    "    # ## Required parameters\n",
    "    # parser.add_argument(\"--data_dir\",\n",
    "    #                     default=None,\n",
    "    #                     type=str,\n",
    "    #                     required=True,\n",
    "    #                     help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n",
    "    # parser.add_argument(\"--bert_model\", default=None, type=str, required=True,\n",
    "    #                     help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
    "    #                          \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\")\n",
    "    # parser.add_argument(\"--task_name\",\n",
    "    #                     default=None,\n",
    "    #                     type=str,\n",
    "    #                     required=True,\n",
    "    #                     help=\"The name of the task to train.\")\n",
    "    # parser.add_argument(\"--output_dir\",\n",
    "    #                     default=None,\n",
    "    #                     type=str,\n",
    "    #                     required=True,\n",
    "    #                     help=\"The output directory where the model checkpoints will be written.\")\n",
    "\n",
    "    ## Other parameters\n",
    "    # parser.add_argument(\"--max_seq_length\",\n",
    "    #                     default=128,\n",
    "    #                     type=int,\n",
    "    #                     help=\"The maximum total input sequence length after WordPiece tokenization. \\n\"\n",
    "    #                          \"Sequences longer than this will be truncated, and sequences shorter \\n\"\n",
    "    #                          \"than this will be padded.\")\n",
    "    # parser.add_argument(\"--do_train\",\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to run training.\")\n",
    "    # parser.add_argument(\"--do_eval\",\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to run eval on the dev set.\")\n",
    "    # parser.add_argument(\"--do_lower_case\",\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Set this flag if you are using an uncased model.\")\n",
    "    # parser.add_argument(\"--train_batch_size\",\n",
    "    #                     default=32,\n",
    "    #                     type=int,\n",
    "    #                     help=\"Total batch size for training.\")\n",
    "    # parser.add_argument(\"--eval_batch_size\",\n",
    "    #                     default=8,\n",
    "    #                     type=int,\n",
    "    #                     help=\"Total batch size for eval.\")\n",
    "    # parser.add_argument(\"--learning_rate\",\n",
    "    #                     default=5e-5,\n",
    "    #                     type=float,\n",
    "    #                     help=\"The initial learning rate for Adam.\")\n",
    "    # parser.add_argument(\"--num_train_epochs\",\n",
    "    #                     default=3.0,\n",
    "    #                     type=float,\n",
    "    #                     help=\"Total number of training epochs to perform.\")\n",
    "    # parser.add_argument(\"--warmup_proportion\",\n",
    "    #                     default=0.1,\n",
    "    #                     type=float,\n",
    "    #                     help=\"Proportion of training to perform linear learning rate warmup for. \"\n",
    "    #                          \"E.g., 0.1 = 10%% of training.\")\n",
    "    # parser.add_argument(\"--no_cuda\",\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether not to use CUDA when available\")\n",
    "    # parser.add_argument(\"--local_rank\",\n",
    "    #                     type=int,\n",
    "    #                     default=-1,\n",
    "    #                     help=\"local_rank for distributed training on gpus\")\n",
    "    # parser.add_argument('--seed',\n",
    "    #                     type=int,\n",
    "    #                     default=42,\n",
    "    #                     help=\"random seed for initialization\")\n",
    "    # parser.add_argument('--gradient_accumulation_steps',\n",
    "    #                     type=int,\n",
    "    #                     default=1,\n",
    "    #                     help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "    # parser.add_argument('--optimize_on_cpu',\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to perform optimization and keep the optimizer averages on CPU\")\n",
    "    # parser.add_argument('--fp16',\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to use 16-bit float precision instead of 32-bit\")\n",
    "    # parser.add_argument('--loss_scale',\n",
    "    #                     type=float, default=128,\n",
    "    #                     help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    processors = {\n",
    "#         \"cola\": ColaProcessor,\n",
    "#         \"mnli\": MnliProcessor,\n",
    "        \"mrpc\": MrpcProcessor,\n",
    "    }\n",
    "\n",
    "    if local_rank == -1 or no_cuda:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "    else:\n",
    "        device = torch.device(\"cuda\", local_rank)\n",
    "        n_gpu = 1\n",
    "        # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "        torch.distributed.init_process_group(backend='nccl')\n",
    "        if fp16:\n",
    "            logger.info(\"16-bits training currently not supported in distributed training\")\n",
    "            fp16 = False # (see https://github.com/pytorch/pytorch/pull/13496)\n",
    "    logger.info(\"device %s n_gpu %d distributed training %r\", device, n_gpu, bool(local_rank != -1))\n",
    "\n",
    "    if gradient_accumulation_steps < 1:\n",
    "        raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(\n",
    "                            gradient_accumulation_steps))\n",
    "\n",
    "    train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    if not do_train and not do_eval:\n",
    "        raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "    if do_train:\n",
    "        if os.path.exists(output_dir) and os.listdir(output_dir):\n",
    "            raise ValueError(\"Output directory ({}) already exists and is not emp1ty.\".format(output_dir))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    task_name = task_name.lower()\n",
    "\n",
    "    if task_name not in processors:\n",
    "        raise ValueError(\"Task not found: %s\" % (task_name))\n",
    "\n",
    "    processor = processors[task_name]()\n",
    "    label_list = processor.get_labels()\n",
    "\n",
    "#     tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=do_lower_case)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    train_examples = None\n",
    "    num_train_steps = None\n",
    "    if do_train:\n",
    "        train_examples = processor.get_train_examples(data_dir)\n",
    "        num_train_steps = int(\n",
    "            len(train_examples) / train_batch_size / gradient_accumulation_steps * num_train_epochs)\n",
    "\n",
    "    # Prepare model\n",
    "#     model = BertForSequenceClassification.from_pretrained(bert_model,\n",
    "#                 cache_dir=PYTORCH_PRETRAINED_BERT_CACHE / 'distributed_{}'.format(local_rank), num_labels = 2)\n",
    "\n",
    "        model = BertForConsistencyCueClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "        model.to(device)\n",
    "        if fp16:\n",
    "            model.half()\n",
    "\n",
    "        if local_rank != -1:\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank],\n",
    "                                                              output_device=local_rank)\n",
    "        elif n_gpu > 1:\n",
    "            model = torch.nn.DataParallel(model)\n",
    "\n",
    "        # Prepare optimizer\n",
    "        if fp16:\n",
    "            param_optimizer = [(n, param.clone().detach().to('cpu').float().requires_grad_()) \\\n",
    "                                for n, param in model.named_parameters()]\n",
    "        elif optimize_on_cpu:\n",
    "            param_optimizer = [(n, param.clone().detach().to('cpu').requires_grad_()) \\\n",
    "                                for n, param in model.named_parameters()]\n",
    "        else:\n",
    "            param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "            ]\n",
    "        t_total = num_train_steps\n",
    "#     print(t_total)\n",
    "    if local_rank != -1:\n",
    "        t_total = t_total // torch.distributed.get_world_size()\n",
    "    if do_train:\n",
    "        optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=learning_rate,\n",
    "                         warmup=warmup_proportion,\n",
    "                         t_total=t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    if do_train:\n",
    "        train_features = convert_examples_to_features(\n",
    "            train_examples, label_list, max_seq_length, tokenizer)\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "        logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "        logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "        train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "        if local_rank == -1:\n",
    "            train_sampler = RandomSampler(train_data)\n",
    "        else:\n",
    "            train_sampler = DistributedSampler(train_data)\n",
    "        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
    "\n",
    "        model.train()\n",
    "        for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
    "            tr_loss = 0\n",
    "            nb_tr_examples, nb_tr_steps = 0, 0\n",
    "            for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids, input_mask, segment_ids, label_ids, = batch\n",
    "                loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "                if n_gpu > 1:\n",
    "                    loss = loss.mean() # mean() to average on multi-gpu.\n",
    "                if fp16 and loss_scale != 1.0:\n",
    "                    # rescale loss for fp16 training\n",
    "                    # see https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html\n",
    "                    loss = loss * loss_scale\n",
    "                if gradient_accumulation_steps > 1:\n",
    "                    loss = loss / gradient_accumulation_steps\n",
    "                loss.backward()\n",
    "                tr_loss += loss.item()\n",
    "                nb_tr_examples += input_ids.size(0)\n",
    "                nb_tr_steps += 1\n",
    "                if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                    if fp16 or optimize_on_cpu:\n",
    "                        if fp16 and loss_scale != 1.0:\n",
    "                            # scale down gradients for fp16 training\n",
    "                            for param in model.parameters():\n",
    "                                if param.grad is not None:\n",
    "                                    param.grad.data = param.grad.data / loss_scale\n",
    "                        is_nan = set_optimizer_params_grad(param_optimizer, model.named_parameters(), test_nan=True)\n",
    "                        if is_nan:\n",
    "                            logger.info(\"FP16 TRAINING: Nan in gradients, reducing loss scaling\")\n",
    "                            loss_scale = loss_scale / 2\n",
    "                            model.zero_grad()\n",
    "                            continue\n",
    "                        optimizer.step()\n",
    "                        copy_optimizer_params_to_model(model.named_parameters(), param_optimizer)\n",
    "                    else:\n",
    "                        optimizer.step()\n",
    "                    model.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "        torch.save(model.state_dict(), output_dir + \"output.pth\")\n",
    "\n",
    "\n",
    "    if do_eval and (local_rank == -1 or torch.distributed.get_rank() == 0):\n",
    "        eval_examples = processor.get_test_examples(data_dir)\n",
    "#         eval_examples = processor.get_dev_examples(data_dir)\n",
    "        eval_features = convert_examples_to_features(\n",
    "            eval_examples, label_list, max_seq_length, tokenizer)\n",
    "        claim_features = convert_claims_to_features(eval_examples, label_list, max_seq_length, tokenizer)    \n",
    "    \n",
    "        logger.info(\"***** Running evaluation *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "        logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "        \n",
    "        claims_input_ids = torch.tensor([f.input_ids for f in claim_features], dtype=torch.long)\n",
    "        claims_input_mask = torch.tensor([f.input_mask for f in claim_features], dtype=torch.long)\n",
    "        claims_segment_ids = torch.tensor([f.segment_ids for f in claim_features], dtype=torch.long)\n",
    "        claims_label_ids = torch.tensor([f.label_id for f in claim_features], dtype=torch.long)\n",
    "        \n",
    "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, claims_input_ids, claims_input_mask, claims_segment_ids, claims_label_ids)\n",
    "        # Run prediction for full data\n",
    "#         eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "#         print('all_input_ids:')\n",
    "#         print(all_input_ids)\n",
    "        \n",
    "        \n",
    "\n",
    "#         model.load_state_dict(torch.load(saved_model))\n",
    "        model_state_dict = torch.load(saved_model)\n",
    "        model = BertForConsistencyCueClassification.from_pretrained('bert-base-uncased', num_labels=2, state_dict=model_state_dict)\n",
    "        model.to(device)\n",
    "        \n",
    "        model.eval()\n",
    "        # eval_loss, eval_accuracy = 0, 0\n",
    "\n",
    "        eval_tp, eval_pred_c, eval_gold_c = 0, 0, 0\n",
    "        eval_loss, eval_macro_p, eval_macro_r = 0, 0, 0\n",
    "\n",
    "        raw_score = []\n",
    "\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "        for input_ids, input_mask, segment_ids, label_ids, claim_input_ids, claim_input_mask, claim_segment_ids, claim_label_ids in eval_dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "            claim_input_ids = claim_input_ids.to(device)\n",
    "            claim_input_mask = claim_input_mask.to(device)\n",
    "            claim_segment_ids = claim_segment_ids.to(device)\n",
    "            claim_label_ids = claim_label_ids.to(device)\n",
    "\n",
    "#             print(\"start\")\n",
    "#             print(input_ids)\n",
    "#             print(input_mask)\n",
    "#             print(segment_ids)\n",
    "#             print(label_ids)\n",
    "#             print(claim_input_ids)\n",
    "#             print(claim_input_mask)\n",
    "#             print(claim_segment_ids)\n",
    "#             print(claim_label_ids)\n",
    "#             print(\"end\")\n",
    "            with torch.no_grad():\n",
    "                tmp_eval_loss = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, labels=label_ids, input_ids2=claim_input_ids, token_type_ids2=claim_segment_ids, attention_mask2=claim_input_mask, labels2=claim_label_ids)\n",
    "                \n",
    "                logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, input_ids2=claim_input_ids, token_type_ids2=claim_segment_ids, attention_mask2=claim_input_mask)\n",
    "            \n",
    "            print(logits)\n",
    "#             print(logits[0])\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            print(logits)\n",
    "            label_ids = label_ids.to('cpu').numpy()\n",
    "#             print(label_ids)\n",
    "\n",
    "            # Micro F1 (aggregated tp, fp, fn counts across all examples)\n",
    "            tmp_tp, tmp_pred_c, tmp_gold_c = tp_pcount_gcount(logits, label_ids)\n",
    "            eval_tp += tmp_tp\n",
    "            eval_pred_c += tmp_pred_c\n",
    "            eval_gold_c += tmp_gold_c\n",
    "            \n",
    "            pred_label = np.argmax(logits, axis=1)\n",
    "            raw_score += zip(logits, pred_label, label_ids)\n",
    "            \n",
    "            # Macro F1 (averaged P, R across mini batches)\n",
    "            tmp_eval_p, tmp_eval_r, tmp_eval_f1 = p_r_f1(logits, label_ids)\n",
    "\n",
    "            eval_macro_p += tmp_eval_p\n",
    "            eval_macro_r += tmp_eval_r\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_examples += input_ids.size(0)\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "\n",
    "        # Micro F1 (aggregated tp, fp, fn counts across all examples)\n",
    "        eval_micro_p = eval_tp / eval_pred_c\n",
    "        eval_micro_r = eval_tp / eval_gold_c\n",
    "        eval_micro_f1 = 2 * eval_micro_p * eval_micro_r / (eval_micro_p + eval_micro_r)\n",
    "\n",
    "        # Macro F1 (averaged P, R across mini batches)\n",
    "        eval_macro_p = eval_macro_p / nb_eval_steps\n",
    "        eval_macro_r = eval_macro_r / nb_eval_steps\n",
    "        eval_macro_f1 = 2 * eval_macro_p * eval_macro_r / (eval_macro_p + eval_macro_r)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        result = {\n",
    "                  'eval_loss': eval_loss,\n",
    "                  'eval_micro_p': eval_micro_p,\n",
    "                  'eval_micro_r': eval_micro_r,\n",
    "                  'eval_micro_f1': eval_micro_f1,\n",
    "                  'eval_macro_p': eval_macro_p,\n",
    "                  'eval_macro_r': eval_macro_r,\n",
    "                  'eval_macro_f1': eval_macro_f1,\n",
    "#                   'global_step': global_step,\n",
    "#                   'loss': tr_loss/nb_tr_steps\n",
    "                  }\n",
    "\n",
    "        output_eval_file = os.path.join(output_dir, \"v5_cos_dev_eval_results.txt\")\n",
    "        output_raw_score = os.path.join(output_dir, \"v5_cos_dev_raw_score.csv\")\n",
    "        with open(output_eval_file, \"w\") as writer:\n",
    "            logger.info(\"***** Eval results *****\")\n",
    "            for key in sorted(result.keys()):\n",
    "                logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "        with open(output_raw_score, 'w') as fout:\n",
    "            fields = [\"undermine_score\", \"support_score\",\"predict_label\", \"gold\"]\n",
    "            writer = csv.DictWriter(fout, fieldnames=fields)\n",
    "            writer.writeheader()\n",
    "            for score, pred, gold in raw_score:\n",
    "                writer.writerow({\n",
    "                    \"undermine_score\": str(score[0]),\n",
    "                    \"support_score\": str(score[1]),\n",
    "                    \"predict_label\": str(pred),\n",
    "                    \"gold\": str(gold)\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiments():\n",
    "    data_dir = \"D:/Jupyter/data/dataset/perspective_stances/\"\n",
    "#     data_dir = \"/home/syg340/Dataset/\"\n",
    "\n",
    "    # data_dir_output = data_dir + \"output2/\"\n",
    "    data_dir_output = \"D:/Projects/Stance/Models/\"\n",
    "    train_and_test(data_dir=data_dir, do_train=True, do_eval=True, output_dir=data_dir_output,task_name=\"Mrpc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_with_pretrained():\n",
    "    bert_model = \"D:/Projects/Stance/Models/Consistency_Cues/cos_emb.pth\"\n",
    "    data_dir = \"D:/Jupyter/data/dataset/perspective_stances/\"\n",
    "    # data_dir_output = data_dir + \"output2/\"\n",
    "    ## v2: concat\n",
    "    ## v3: multiply\n",
    "    data_dir_output = \"D:/Projects/Stance/Evaluation/bert_dummy_output/cos_emb\"\n",
    "    train_and_test(data_dir=data_dir, do_train=False, do_eval=True, output_dir=data_dir_output,task_name=\"mrpc\",saved_model=bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2020 18:56:57 - INFO - run_classifier -   device cuda n_gpu 1 distributed training False\n",
      "05/04/2020 18:56:59 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\arsen\\.cache\\torch\\transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   guid: test-1\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] lessons would feel less broken . [SEP]\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 8220 2052 2514 2625 3714 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   guid: test-2\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] not enough fund ##ng . . . [SEP]\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2025 2438 4636 3070 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   guid: test-3\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] so much easier for parents ! [SEP]\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2061 2172 6082 2005 3008 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   guid: test-4\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] less need for homework . [SEP]\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2625 2342 2005 19453 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   guid: test-5\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] time to finish activities [SEP]\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2051 2000 3926 3450 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   guid: test-1\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP]\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   guid: test-2\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP]\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   guid: test-3\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP]\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   guid: test-4\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP]\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   guid: test-5\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP]\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:57:01 - INFO - run_classifier -   ***** Running evaluation *****\n",
      "05/04/2020 18:57:01 - INFO - run_classifier -     Num examples = 2773\n",
      "05/04/2020 18:57:01 - INFO - run_classifier -     Batch size = 8\n",
      "05/04/2020 18:57:02 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\arsen\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "05/04/2020 18:57:02 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file C:\\Users\\arsen\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\arsen\\AppData\\Local\\Temp\\tmp5viwdsdd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2020 18:57:05 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0515, -0.0181],\n",
      "        [-0.0517, -0.0180],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0514, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2802, -0.2851]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6808, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8058, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0515, -0.0181],\n",
      "        [-0.0517, -0.0180],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0514, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2802, -0.2851]], device='cuda:0')\n",
      "[[-0.27977967 -0.28498852]\n",
      " [-0.27959052 -0.28497428]\n",
      " [-0.27981746 -0.28502113]\n",
      " [-0.27980983 -0.28500932]\n",
      " [-0.2802535  -0.28503895]\n",
      " [-0.2804121  -0.28502113]\n",
      " [-0.2804786  -0.28501478]\n",
      " [-0.2802497  -0.28505084]]\n",
      "logits_ce:\n",
      "tensor([[-0.0518, -0.0180],\n",
      "        [-0.0517, -0.0181],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0512, -0.0183],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2805, -0.2850],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2802, -0.2851],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6890, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0640, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0518, -0.0180],\n",
      "        [-0.0517, -0.0181],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0512, -0.0183],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2805, -0.2850],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2802, -0.2851],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "[[-0.2804786  -0.28501478]\n",
      " [-0.28040233 -0.28502455]\n",
      " [-0.27977    -0.28499871]\n",
      " [-0.28047982 -0.2850105 ]\n",
      " [-0.2804883  -0.28501427]\n",
      " [-0.28010368 -0.28504372]\n",
      " [-0.28019235 -0.28505382]\n",
      " [-0.2796355  -0.28496626]]\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2798, -0.2850],\n",
      "        [-0.2802, -0.2851],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6974, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3224, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2798, -0.2850],\n",
      "        [-0.2802, -0.2851],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27983546 -0.28499162]\n",
      " [-0.28019235 -0.28505382]\n",
      " [-0.27978197 -0.28500134]\n",
      " [-0.27981436 -0.28500345]\n",
      " [-0.27976686 -0.2849885 ]\n",
      " [-0.2796203  -0.28497064]\n",
      " [-0.27979475 -0.28499228]\n",
      " [-0.2797786  -0.28498897]]\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0186],\n",
      "        [-0.0515, -0.0181],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0517, -0.0181]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2849],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2804, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6770, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.7136e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6770, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0186],\n",
      "        [-0.0515, -0.0181],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0517, -0.0181]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2849],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2804, -0.2850]], device='cuda:0')\n",
      "[[-0.27944046 -0.28493732]\n",
      " [-0.28029686 -0.28504056]\n",
      " [-0.27967262 -0.28496248]\n",
      " [-0.27971667 -0.28497708]\n",
      " [-0.28002548 -0.28502733]\n",
      " [-0.27972847 -0.28499347]\n",
      " [-0.27986407 -0.28501827]\n",
      " [-0.28040153 -0.28502333]]\n",
      "logits_ce:\n",
      "tensor([[-0.0510, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0505, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0512, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7095, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.0000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.7095, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0510, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0505, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0512, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "[[-0.27991426 -0.2850117 ]\n",
      " [-0.2797864  -0.2850017 ]\n",
      " [-0.27964398 -0.28497118]\n",
      " [-0.28005353 -0.28502798]\n",
      " [-0.2798956  -0.28500867]\n",
      " [-0.27951312 -0.28497288]\n",
      " [-0.2793017  -0.28492844]\n",
      " [-0.28006786 -0.28502995]]\n",
      "logits_ce:\n",
      "tensor([[-0.0512, -0.0183],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0508, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0512, -0.0183],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6975, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3225, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0512, -0.0183],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0508, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0512, -0.0183],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.28008503 -0.28503984]\n",
      " [-0.27971298 -0.28498745]\n",
      " [-0.27973706 -0.284984  ]\n",
      " [-0.27995116 -0.28501925]\n",
      " [-0.28010952 -0.28504276]\n",
      " [-0.27933797 -0.2849415 ]\n",
      " [-0.27920783 -0.28491414]\n",
      " [-0.27917242 -0.2849245 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0515, -0.0181],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0514, -0.0182],\n",
      "        [-0.0516, -0.0181]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2803, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2804, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0515, -0.0181],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0514, -0.0182],\n",
      "        [-0.0516, -0.0181]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2803, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2804, -0.2850]], device='cuda:0')\n",
      "[[-0.280309   -0.285046  ]\n",
      " [-0.28002164 -0.28503913]\n",
      " [-0.2798847  -0.28500497]\n",
      " [-0.27989626 -0.28501517]\n",
      " [-0.2792287  -0.28493637]\n",
      " [-0.27920875 -0.28492454]\n",
      " [-0.28023398 -0.285046  ]\n",
      " [-0.28035247 -0.28503296]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0187],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6853, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.2500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.9353, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0187],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "[[-0.2792005  -0.28492808]\n",
      " [-0.27984607 -0.28501937]\n",
      " [-0.27974936 -0.28499725]\n",
      " [-0.27995378 -0.28500566]\n",
      " [-0.2793475  -0.28492332]\n",
      " [-0.27903038 -0.28486866]\n",
      " [-0.2797125  -0.28496498]\n",
      " [-0.27931863 -0.28493172]]\n",
      "logits_ce:\n",
      "tensor([[-0.0513, -0.0182],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0513, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6895, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0645, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0513, -0.0182],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0513, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "[[-0.28014976 -0.28503123]\n",
      " [-0.27992553 -0.2849974 ]\n",
      " [-0.27963656 -0.28494602]\n",
      " [-0.2791425  -0.28489745]\n",
      " [-0.2792517  -0.284915  ]\n",
      " [-0.27907515 -0.2848994 ]\n",
      " [-0.27970004 -0.2849565 ]\n",
      " [-0.28012455 -0.28502393]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0499, -0.0190],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2788, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0499, -0.0190],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2788, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.27907914 -0.2849362 ]\n",
      " [-0.27924788 -0.28492093]\n",
      " [-0.27926433 -0.28494027]\n",
      " [-0.27883583 -0.2848794 ]\n",
      " [-0.27973062 -0.2849868 ]\n",
      " [-0.27975753 -0.28499657]\n",
      " [-0.27968848 -0.28497994]\n",
      " [-0.27971196 -0.2849828 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0513, -0.0182],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0515, -0.0181]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2803, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6810, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8060, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0513, -0.0182],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0515, -0.0181]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2803, -0.2850]], device='cuda:0')\n",
      "[[-0.28011113 -0.28502822]\n",
      " [-0.27961057 -0.28498065]\n",
      " [-0.27946752 -0.28495157]\n",
      " [-0.28014025 -0.28503388]\n",
      " [-0.27981752 -0.28499532]\n",
      " [-0.27948236 -0.2849519 ]\n",
      " [-0.27967042 -0.28499252]\n",
      " [-0.28027615 -0.28502452]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2799, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6933, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1933, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2799, -0.2850]], device='cuda:0')\n",
      "[[-0.27965456 -0.28496766]\n",
      " [-0.27966094 -0.2849837 ]\n",
      " [-0.2796692  -0.28497094]\n",
      " [-0.27988052 -0.28501523]\n",
      " [-0.2801091  -0.28503793]\n",
      " [-0.27910423 -0.28490654]\n",
      " [-0.27997345 -0.2850076 ]\n",
      " [-0.27986708 -0.2849974 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0514, -0.0181],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2802, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6773, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(2.1607e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6773, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0514, -0.0181],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2802, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "[[-0.2802477  -0.2850435 ]\n",
      " [-0.27924123 -0.2849477 ]\n",
      " [-0.27904457 -0.28492638]\n",
      " [-0.2793963  -0.28494447]\n",
      " [-0.27918744 -0.28491586]\n",
      " [-0.27981052 -0.28500342]\n",
      " [-0.27935272 -0.284954  ]\n",
      " [-0.27948004 -0.28496888]]\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0516, -0.0181],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0503, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2790, -0.2850],\n",
      "        [-0.2790, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6895, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0645, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0516, -0.0181],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0503, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2790, -0.2850],\n",
      "        [-0.2790, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.2791939  -0.28493035]\n",
      " [-0.28035933 -0.28503066]\n",
      " [-0.27958584 -0.28499696]\n",
      " [-0.2795864  -0.2849906 ]\n",
      " [-0.2790218  -0.28495458]\n",
      " [-0.27895683 -0.2849601 ]\n",
      " [-0.27983683 -0.28500775]\n",
      " [-0.2792424  -0.28490373]]\n",
      "logits_ce:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0504, -0.0186],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7012, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.7500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.4512, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0186],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2850]], device='cuda:0')\n",
      "[[-0.27934378 -0.28492177]\n",
      " [-0.27977717 -0.2849794 ]\n",
      " [-0.2793106  -0.28491682]\n",
      " [-0.27930248 -0.28493834]\n",
      " [-0.27929556 -0.2849214 ]\n",
      " [-0.27925307 -0.2849248 ]\n",
      " [-0.27929872 -0.2849357 ]\n",
      " [-0.2794284  -0.28495482]]\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.27925125 -0.284922  ]\n",
      " [-0.27942142 -0.28495765]\n",
      " [-0.27929837 -0.28493434]\n",
      " [-0.27924222 -0.284927  ]\n",
      " [-0.27955344 -0.28495786]\n",
      " [-0.27951658 -0.28495508]\n",
      " [-0.279492   -0.2849466 ]\n",
      " [-0.27922043 -0.28492677]]\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0186],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2794, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6853, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.2500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.9353, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0186],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2794, -0.2849]], device='cuda:0')\n",
      "[[-0.27951676 -0.28495875]\n",
      " [-0.27942473 -0.2849319 ]\n",
      " [-0.27916047 -0.28492603]\n",
      " [-0.2795961  -0.28496888]\n",
      " [-0.27969986 -0.2849928 ]\n",
      " [-0.27944833 -0.28494468]\n",
      " [-0.27945453 -0.28495133]\n",
      " [-0.27944762 -0.28494543]]\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6812, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8062, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27949083 -0.28495574]\n",
      " [-0.27970588 -0.28498238]\n",
      " [-0.27991626 -0.28500783]\n",
      " [-0.27964252 -0.28497863]\n",
      " [-0.2796536  -0.28497526]\n",
      " [-0.2797345  -0.28496996]\n",
      " [-0.27922976 -0.28491375]\n",
      " [-0.2798227  -0.28499907]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6772, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(2.6077e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6772, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27964622 -0.28497875]\n",
      " [-0.2794354  -0.28494453]\n",
      " [-0.279602   -0.28496194]\n",
      " [-0.27994    -0.28501767]\n",
      " [-0.27970713 -0.28496784]\n",
      " [-0.27947822 -0.28495902]\n",
      " [-0.27975345 -0.2849728 ]\n",
      " [-0.27977663 -0.2849809 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0510, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2800, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6891, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0641, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0510, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2800, -0.2850]], device='cuda:0')\n",
      "[[-0.2796295  -0.28496578]\n",
      " [-0.27955675 -0.28494096]\n",
      " [-0.2796965  -0.28496456]\n",
      " [-0.27956668 -0.28495443]\n",
      " [-0.27933604 -0.2849361 ]\n",
      " [-0.27897716 -0.28490767]\n",
      " [-0.27912104 -0.2849027 ]\n",
      " [-0.27998042 -0.2850076 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2794, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6972, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3222, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2794, -0.2849]], device='cuda:0')\n",
      "[[-0.27963012 -0.28496575]\n",
      " [-0.2797322  -0.28498542]\n",
      " [-0.2796753  -0.28496838]\n",
      " [-0.27954924 -0.28493983]\n",
      " [-0.27962917 -0.2849896 ]\n",
      " [-0.27956298 -0.28496736]\n",
      " [-0.27914047 -0.2849325 ]\n",
      " [-0.27943265 -0.28493077]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6813, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8063, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "[[-0.27946383 -0.28493732]\n",
      " [-0.2796023  -0.2849361 ]\n",
      " [-0.27949113 -0.28495246]\n",
      " [-0.27928028 -0.28491837]\n",
      " [-0.2794091  -0.28495318]\n",
      " [-0.27969992 -0.28498763]\n",
      " [-0.27962232 -0.2849838 ]\n",
      " [-0.27934414 -0.2849421 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0512, -0.0183],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0499, -0.0187],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6933, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1933, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0512, -0.0183],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0499, -0.0187],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.27961165 -0.28495312]\n",
      " [-0.27959    -0.28494895]\n",
      " [-0.279696   -0.28497875]\n",
      " [-0.280118   -0.28502005]\n",
      " [-0.28005248 -0.28501976]\n",
      " [-0.27938455 -0.28493798]\n",
      " [-0.27887627 -0.28486264]\n",
      " [-0.27916694 -0.2848775 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0500, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2788, -0.2849],\n",
      "        [-0.2790, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6933, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1933, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0500, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2788, -0.2849],\n",
      "        [-0.2790, -0.2849]], device='cuda:0')\n",
      "[[-0.27903655 -0.2848573 ]\n",
      " [-0.27894652 -0.28488496]\n",
      " [-0.27925813 -0.28487912]\n",
      " [-0.2789544  -0.2849444 ]\n",
      " [-0.27921814 -0.2849142 ]\n",
      " [-0.27896166 -0.28489548]\n",
      " [-0.2788381  -0.28492364]\n",
      " [-0.27897787 -0.28488958]]\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0507, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0513, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2789, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2797, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2848],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6892, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0642, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0507, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0513, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2789, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2797, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2848],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "[[-0.27892792 -0.28490964]\n",
      " [-0.2790209  -0.2849071 ]\n",
      " [-0.2796865  -0.2849498 ]\n",
      " [-0.27963036 -0.2849447 ]\n",
      " [-0.2794308  -0.28493533]\n",
      " [-0.2791689  -0.2848456 ]\n",
      " [-0.27919257 -0.28487605]\n",
      " [-0.280141   -0.28503096]]\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6774, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(2.6822e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6774, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.27960044 -0.28495574]\n",
      " [-0.2797221  -0.2849584 ]\n",
      " [-0.2791452  -0.2848764 ]\n",
      " [-0.2792728  -0.28490847]\n",
      " [-0.27927506 -0.2848781 ]\n",
      " [-0.27926606 -0.28486928]\n",
      " [-0.27949774 -0.28491625]\n",
      " [-0.2791937  -0.284858  ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0498, -0.0188],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2789, -0.2850],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2788, -0.2850],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6852, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.2500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.9352, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0498, -0.0188],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2789, -0.2850],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2788, -0.2850],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27931404 -0.28488696]\n",
      " [-0.27890894 -0.28495204]\n",
      " [-0.27887642 -0.28492138]\n",
      " [-0.27879483 -0.28496003]\n",
      " [-0.279298   -0.28495574]\n",
      " [-0.2799554  -0.28501606]\n",
      " [-0.27948487 -0.28494775]\n",
      " [-0.27980122 -0.28500435]]\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2795, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6813, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8063, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2795, -0.2849]], device='cuda:0')\n",
      "[[-0.27941    -0.28494042]\n",
      " [-0.27951908 -0.28494525]\n",
      " [-0.2798277  -0.28499398]\n",
      " [-0.27991465 -0.28500143]\n",
      " [-0.27944422 -0.2849412 ]\n",
      " [-0.27955103 -0.284946  ]\n",
      " [-0.27962005 -0.2849446 ]\n",
      " [-0.27953607 -0.28494287]]\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6973, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3223, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "[[-0.2797488  -0.28497237]\n",
      " [-0.27934515 -0.2849381 ]\n",
      " [-0.2791713  -0.2849025 ]\n",
      " [-0.27977985 -0.28498697]\n",
      " [-0.27969897 -0.28497016]\n",
      " [-0.27925342 -0.28491077]\n",
      " [-0.27964658 -0.28496137]\n",
      " [-0.27957746 -0.2849607 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0184],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0188],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7012, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.7500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.4512, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0184],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0188],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "[[-0.27949405 -0.2849524 ]\n",
      " [-0.27910757 -0.28489462]\n",
      " [-0.2789886  -0.28490603]\n",
      " [-0.27952176 -0.2849522 ]\n",
      " [-0.27905208 -0.28489712]\n",
      " [-0.27907658 -0.28488728]\n",
      " [-0.27954054 -0.28495574]\n",
      " [-0.2791309  -0.28491083]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6815, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8065, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.27904755 -0.2849146 ]\n",
      " [-0.27922153 -0.28492284]\n",
      " [-0.27913228 -0.2848984 ]\n",
      " [-0.27903548 -0.28489226]\n",
      " [-0.27915835 -0.28491053]\n",
      " [-0.2791323  -0.2848956 ]\n",
      " [-0.2790568  -0.28488344]\n",
      " [-0.27916384 -0.28487766]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6776, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(2.2352e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6776, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.27908152 -0.284889  ]\n",
      " [-0.27910137 -0.28488553]\n",
      " [-0.27908796 -0.28491086]\n",
      " [-0.27906585 -0.28487438]\n",
      " [-0.27897632 -0.28485543]\n",
      " [-0.27917784 -0.2848891 ]\n",
      " [-0.27902836 -0.28486985]\n",
      " [-0.27917522 -0.28489068]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6775, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.6391e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6775, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "[[-0.2791199  -0.28489438]\n",
      " [-0.27930218 -0.28490555]\n",
      " [-0.27911967 -0.28489184]\n",
      " [-0.27909523 -0.28488335]\n",
      " [-0.27904928 -0.284881  ]\n",
      " [-0.27905053 -0.28487054]\n",
      " [-0.27916706 -0.2848994 ]\n",
      " [-0.2790887  -0.28490204]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6774, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.4156e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6774, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "[[-0.279089   -0.28490672]\n",
      " [-0.27929458 -0.28491086]\n",
      " [-0.27918324 -0.28489786]\n",
      " [-0.2792561  -0.2849062 ]\n",
      " [-0.27933082 -0.28491783]\n",
      " [-0.27940965 -0.2849229 ]\n",
      " [-0.27922946 -0.28490752]\n",
      " [-0.27933323 -0.28491935]]\n",
      "logits_ce:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0514, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0512, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6973, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3223, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0514, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0512, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "[[-0.27930543 -0.28491932]\n",
      " [-0.27959052 -0.28495115]\n",
      " [-0.2801915  -0.2850276 ]\n",
      " [-0.2796395  -0.28497878]\n",
      " [-0.28001547 -0.28501087]\n",
      " [-0.27967423 -0.2849651 ]\n",
      " [-0.2800098  -0.285013  ]\n",
      " [-0.2800771  -0.2850156 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0514, -0.0181],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6770, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.7881e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6770, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0514, -0.0181],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.27956566 -0.28496814]\n",
      " [-0.27984402 -0.28497973]\n",
      " [-0.27977937 -0.2849648 ]\n",
      " [-0.27974987 -0.28495848]\n",
      " [-0.27982792 -0.28496632]\n",
      " [-0.2796315  -0.28495532]\n",
      " [-0.280235   -0.2850265 ]\n",
      " [-0.2796619  -0.28497285]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6932, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1932, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2849]], device='cuda:0')\n",
      "[[-0.27961853 -0.28498352]\n",
      " [-0.2799171  -0.28499797]\n",
      " [-0.27984092 -0.28498602]\n",
      " [-0.27989566 -0.28499782]\n",
      " [-0.27959433 -0.28496045]\n",
      " [-0.27978814 -0.28496462]\n",
      " [-0.2796419  -0.28496268]\n",
      " [-0.2795429  -0.28494775]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0499, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0500, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2789, -0.2848],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2790, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6932, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1932, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0499, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0500, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2789, -0.2848],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2790, -0.2849]], device='cuda:0')\n",
      "[[-0.2796543  -0.28496277]\n",
      " [-0.27902895 -0.2849219 ]\n",
      " [-0.27887994 -0.28487203]\n",
      " [-0.27894044 -0.28484023]\n",
      " [-0.27890375 -0.2849021 ]\n",
      " [-0.27946472 -0.2849404 ]\n",
      " [-0.27947605 -0.28494132]\n",
      " [-0.27897984 -0.28490865]]\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0498, -0.0190],\n",
      "        [-0.0499, -0.0189],\n",
      "        [-0.0498, -0.0190],\n",
      "        [-0.0498, -0.0190],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2789, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2786, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0498, -0.0190],\n",
      "        [-0.0499, -0.0189],\n",
      "        [-0.0498, -0.0190],\n",
      "        [-0.0498, -0.0190],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2789, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2786, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "[[-0.27892494 -0.2848693 ]\n",
      " [-0.27866286 -0.28490272]\n",
      " [-0.27873966 -0.2849157 ]\n",
      " [-0.27865943 -0.28490943]\n",
      " [-0.27863497 -0.28489244]\n",
      " [-0.27919912 -0.28489757]\n",
      " [-0.27915254 -0.28490597]\n",
      " [-0.27964717 -0.28496394]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7013, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.7500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.4513, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.2791456  -0.28489104]\n",
      " [-0.27918425 -0.284918  ]\n",
      " [-0.2796076  -0.28495455]\n",
      " [-0.28004533 -0.2850244 ]\n",
      " [-0.27908075 -0.28489694]\n",
      " [-0.27926865 -0.28490353]\n",
      " [-0.27944294 -0.28493738]\n",
      " [-0.27969885 -0.2849796 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0501, -0.0187]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0501, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "[[-0.2794248  -0.28493848]\n",
      " [-0.27945757 -0.28493315]\n",
      " [-0.2793044  -0.28492182]\n",
      " [-0.2791955  -0.28486878]\n",
      " [-0.27986825 -0.28499755]\n",
      " [-0.2798436  -0.28500473]\n",
      " [-0.2796015  -0.28497052]\n",
      " [-0.27905315 -0.28489122]]\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2794, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7054, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.8750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.5804, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2794, -0.2849]], device='cuda:0')\n",
      "[[-0.27930662 -0.2849338 ]\n",
      " [-0.27929753 -0.28496122]\n",
      " [-0.28002495 -0.2850247 ]\n",
      " [-0.2793835  -0.28494725]\n",
      " [-0.279525   -0.28495222]\n",
      " [-0.27952474 -0.28496462]\n",
      " [-0.27990538 -0.28500712]\n",
      " [-0.27936366 -0.28493994]]\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "[[-0.2792462  -0.2849186 ]\n",
      " [-0.27958387 -0.2849532 ]\n",
      " [-0.2791777  -0.28490782]\n",
      " [-0.2795611  -0.28496552]\n",
      " [-0.27960116 -0.28497934]\n",
      " [-0.27919292 -0.2849332 ]\n",
      " [-0.2793077  -0.28492975]\n",
      " [-0.27914822 -0.28490517]]\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6933, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1933, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "[[-0.27911127 -0.2849352 ]\n",
      " [-0.27905995 -0.28489453]\n",
      " [-0.2792171  -0.2849247 ]\n",
      " [-0.27961177 -0.28496504]\n",
      " [-0.27926546 -0.28493255]\n",
      " [-0.27964866 -0.28496373]\n",
      " [-0.2792814  -0.28492895]\n",
      " [-0.2795276  -0.28496853]]\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0498, -0.0189],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2788, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6851, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.2500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.9351, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0498, -0.0189],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2788, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "[[-0.2794662  -0.28496233]\n",
      " [-0.27977267 -0.2849946 ]\n",
      " [-0.2797373  -0.2849854 ]\n",
      " [-0.2798716  -0.2849974 ]\n",
      " [-0.27950513 -0.28493732]\n",
      " [-0.27879766 -0.28490764]\n",
      " [-0.27950516 -0.2849685 ]\n",
      " [-0.27948695 -0.2849584 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0500, -0.0188],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6815, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8065, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0500, -0.0188],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2849]], device='cuda:0')\n",
      "[[-0.27909452 -0.2849293 ]\n",
      " [-0.2789266  -0.2848929 ]\n",
      " [-0.279141   -0.28491777]\n",
      " [-0.27903557 -0.28492567]\n",
      " [-0.27895224 -0.28493354]\n",
      " [-0.2793091  -0.28493375]\n",
      " [-0.27934188 -0.28494835]\n",
      " [-0.2794609  -0.28494677]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0501, -0.0188],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0499, -0.0189]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2850],\n",
      "        [-0.2788, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6934, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1934, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0501, -0.0188],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0499, -0.0189]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2850],\n",
      "        [-0.2788, -0.2850]], device='cuda:0')\n",
      "[[-0.27965194 -0.2849526 ]\n",
      " [-0.2790187  -0.28493506]\n",
      " [-0.27888918 -0.28490323]\n",
      " [-0.2791248  -0.2849323 ]\n",
      " [-0.2790838  -0.28494334]\n",
      " [-0.2795148  -0.28494227]\n",
      " [-0.2791736  -0.28495103]\n",
      " [-0.2787584  -0.2849692 ]]\n",
      "logits_ce:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7013, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.7500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.4513, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "[[-0.27911723 -0.2849078 ]\n",
      " [-0.27903652 -0.28491995]\n",
      " [-0.27965057 -0.2849552 ]\n",
      " [-0.27913618 -0.2849204 ]\n",
      " [-0.2790577  -0.28493592]\n",
      " [-0.27947092 -0.2849332 ]\n",
      " [-0.27924842 -0.284925  ]\n",
      " [-0.27962294 -0.2849586 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0185],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0514, -0.0181],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0503, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2848],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6812, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8062, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0185],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0514, -0.0181],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0503, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2848],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "[[-0.2792654  -0.28492776]\n",
      " [-0.27925417 -0.28490394]\n",
      " [-0.2790956  -0.28484792]\n",
      " [-0.2796386  -0.284966  ]\n",
      " [-0.27936336 -0.28491384]\n",
      " [-0.28015983 -0.2850121 ]\n",
      " [-0.2796247  -0.28495532]\n",
      " [-0.27934653 -0.2848885 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0183],\n",
      "        [-0.0510, -0.0182],\n",
      "        [-0.0507, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0498, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0499, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2789, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7092, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.0000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.7092, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0183],\n",
      "        [-0.0510, -0.0182],\n",
      "        [-0.0507, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0498, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0499, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2789, -0.2849]], device='cuda:0')\n",
      "[[-0.27970123 -0.2849625 ]\n",
      " [-0.27994055 -0.28501773]\n",
      " [-0.27973056 -0.28494442]\n",
      " [-0.27952978 -0.28494614]\n",
      " [-0.27894646 -0.28488278]\n",
      " [-0.27873933 -0.28489462]\n",
      " [-0.2788852  -0.2848965 ]\n",
      " [-0.2789274  -0.28493816]]\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0188],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2790, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2790, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6853, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.2500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.9353, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0188],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2790, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2790, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "[[-0.27899235 -0.284945  ]\n",
      " [-0.27900696 -0.28493476]\n",
      " [-0.27900168 -0.28495723]\n",
      " [-0.27897084 -0.28493595]\n",
      " [-0.27892828 -0.28493506]\n",
      " [-0.27954525 -0.28496215]\n",
      " [-0.279774   -0.2849928 ]\n",
      " [-0.27961928 -0.28499484]]\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0515, -0.0181],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0510, -0.0182],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6932, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1932, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0515, -0.0181],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0510, -0.0182],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.27974594 -0.28498676]\n",
      " [-0.27929646 -0.28489453]\n",
      " [-0.27950293 -0.28489476]\n",
      " [-0.27961293 -0.28495193]\n",
      " [-0.28028715 -0.28503424]\n",
      " [-0.27974617 -0.2849541 ]\n",
      " [-0.27987683 -0.28498155]\n",
      " [-0.27965218 -0.28495818]]\n",
      "logits_ce:\n",
      "tensor([[-0.0509, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6974, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3224, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0509, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.2798691  -0.28499153]\n",
      " [-0.27971452 -0.28495908]\n",
      " [-0.27987364 -0.28499043]\n",
      " [-0.27984464 -0.28496832]\n",
      " [-0.27998078 -0.2849974 ]\n",
      " [-0.27966136 -0.2849686 ]\n",
      " [-0.27987283 -0.28500804]\n",
      " [-0.27970627 -0.28499997]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0502, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0503, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6933, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1933, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0502, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0503, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "[[-0.27963877 -0.28499454]\n",
      " [-0.27998957 -0.285     ]\n",
      " [-0.27927035 -0.28485996]\n",
      " [-0.27941483 -0.2849231 ]\n",
      " [-0.27976108 -0.2849887 ]\n",
      " [-0.2791878  -0.2848831 ]\n",
      " [-0.2800591  -0.2850086 ]\n",
      " [-0.2793274  -0.2849383 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0509, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6853, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.2500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.9353, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0509, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27979988 -0.28497738]\n",
      " [-0.2796176  -0.28498012]\n",
      " [-0.27929282 -0.28494972]\n",
      " [-0.27996048 -0.28499687]\n",
      " [-0.27984557 -0.2849843 ]\n",
      " [-0.27927387 -0.28493145]\n",
      " [-0.28002656 -0.2850002 ]\n",
      " [-0.27982235 -0.28497982]]\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0503, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2849],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6935, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1935, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0503, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2849],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "[[-0.2795785  -0.28494793]\n",
      " [-0.27993542 -0.2850057 ]\n",
      " [-0.2801038  -0.28501016]\n",
      " [-0.28048015 -0.28499687]\n",
      " [-0.27975672 -0.28500634]\n",
      " [-0.27983236 -0.2850082 ]\n",
      " [-0.2793381  -0.28494263]\n",
      " [-0.2792859  -0.2849426 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0516, -0.0180],\n",
      "        [-0.0514, -0.0181],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0497, -0.0190]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2785, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6933, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1933, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0516, -0.0180],\n",
      "        [-0.0514, -0.0181],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0497, -0.0190]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2785, -0.2850]], device='cuda:0')\n",
      "[[-0.2797019  -0.28500873]\n",
      " [-0.27973127 -0.28498036]\n",
      " [-0.27979252 -0.28497478]\n",
      " [-0.27903086 -0.28486776]\n",
      " [-0.28037262 -0.28501675]\n",
      " [-0.28024253 -0.28503174]\n",
      " [-0.2801528  -0.28503036]\n",
      " [-0.27851582 -0.28496632]]\n",
      "logits_ce:\n",
      "tensor([[-0.0513, -0.0182],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0513, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6891, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0641, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0513, -0.0182],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0513, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "[[-0.28013968 -0.2850064 ]\n",
      " [-0.28002024 -0.28500727]\n",
      " [-0.28010654 -0.2850206 ]\n",
      " [-0.28009373 -0.28499767]\n",
      " [-0.27980027 -0.2849583 ]\n",
      " [-0.27995974 -0.2849955 ]\n",
      " [-0.27986845 -0.28498703]\n",
      " [-0.28014654 -0.28500736]]\n",
      "logits_ce:\n",
      "tensor([[-0.0512, -0.0182],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2797, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2799, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6810, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8060, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0512, -0.0182],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2797, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2799, -0.2850]], device='cuda:0')\n",
      "[[-0.28006947 -0.28501302]\n",
      " [-0.27990395 -0.28498513]\n",
      " [-0.28015915 -0.285021  ]\n",
      " [-0.27973992 -0.2849437 ]\n",
      " [-0.27980524 -0.2849716 ]\n",
      " [-0.27992725 -0.28498667]\n",
      " [-0.27990133 -0.28498125]\n",
      " [-0.2798531  -0.28495473]]\n",
      "logits_ce:\n",
      "tensor([[-0.0499, -0.0188],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0500, -0.0188],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0501, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2789, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6934, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1934, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0499, -0.0188],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0500, -0.0188],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0501, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2789, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "[[-0.2789051  -0.2849191 ]\n",
      " [-0.27930152 -0.28493685]\n",
      " [-0.2792347  -0.28493002]\n",
      " [-0.2795267  -0.28497022]\n",
      " [-0.27899724 -0.2849095 ]\n",
      " [-0.27942675 -0.28496864]\n",
      " [-0.27950245 -0.28497344]\n",
      " [-0.27908692 -0.28493932]]\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0516, -0.0180],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0508, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6975, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3225, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0516, -0.0180],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0508, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.27919948 -0.28494856]\n",
      " [-0.27937198 -0.2849683 ]\n",
      " [-0.2793079  -0.28496295]\n",
      " [-0.2793823  -0.28496575]\n",
      " [-0.27980304 -0.28497514]\n",
      " [-0.28037435 -0.28500122]\n",
      " [-0.27982318 -0.28498435]\n",
      " [-0.27974045 -0.28498292]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0516, -0.0181],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0512, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0516, -0.0181],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0512, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "[[-0.27973765 -0.28497228]\n",
      " [-0.2796666  -0.28495055]\n",
      " [-0.2803258  -0.2850072 ]\n",
      " [-0.27983782 -0.28498387]\n",
      " [-0.27972382 -0.28496146]\n",
      " [-0.27941233 -0.28493455]\n",
      " [-0.27916205 -0.28490567]\n",
      " [-0.28005195 -0.28502095]]\n",
      "logits_ce:\n",
      "tensor([[-0.0509, -0.0183],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2799, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0509, -0.0183],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2799, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "[[-0.279856   -0.2850076 ]\n",
      " [-0.27911568 -0.2849219 ]\n",
      " [-0.27948362 -0.28495556]\n",
      " [-0.27949452 -0.28495508]\n",
      " [-0.27982002 -0.2850039 ]\n",
      " [-0.27951068 -0.2849512 ]\n",
      " [-0.2794103  -0.2849594 ]\n",
      " [-0.2795191  -0.28496578]]\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7013, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.7500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.4513, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "[[-0.27939427 -0.28495193]\n",
      " [-0.2794931  -0.28497142]\n",
      " [-0.2795577  -0.28498173]\n",
      " [-0.2793735  -0.28494984]\n",
      " [-0.27949363 -0.2849739 ]\n",
      " [-0.27955627 -0.28497624]\n",
      " [-0.27941677 -0.28495574]\n",
      " [-0.27958375 -0.2849751 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6973, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3223, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27970976 -0.28499657]\n",
      " [-0.2795785  -0.28497213]\n",
      " [-0.2793793  -0.2849607 ]\n",
      " [-0.27969435 -0.28499264]\n",
      " [-0.2795324  -0.28496647]\n",
      " [-0.27926403 -0.28495407]\n",
      " [-0.27968594 -0.2849967 ]\n",
      " [-0.27975142 -0.28501487]]\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6974, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3224, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.2796067  -0.28498176]\n",
      " [-0.27950197 -0.2849687 ]\n",
      " [-0.2795137  -0.28497216]\n",
      " [-0.2795875  -0.28498393]\n",
      " [-0.27980435 -0.2850126 ]\n",
      " [-0.27985936 -0.28501266]\n",
      " [-0.27972966 -0.2850027 ]\n",
      " [-0.27966315 -0.28498983]]\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7095, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.0000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.7095, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27974123 -0.28499228]\n",
      " [-0.27935833 -0.28494948]\n",
      " [-0.27979377 -0.2850131 ]\n",
      " [-0.27973437 -0.2850088 ]\n",
      " [-0.2796703  -0.28499314]\n",
      " [-0.27975482 -0.28500307]\n",
      " [-0.27990547 -0.28502744]\n",
      " [-0.27977765 -0.28499705]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7054, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.8750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.5804, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "[[-0.27966785 -0.28500122]\n",
      " [-0.27969277 -0.28498107]\n",
      " [-0.27975976 -0.2849939 ]\n",
      " [-0.2795133  -0.28496945]\n",
      " [-0.27963    -0.28496975]\n",
      " [-0.27971715 -0.28498682]\n",
      " [-0.27964658 -0.28498328]\n",
      " [-0.27954143 -0.2849785 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6894, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0644, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.27914393 -0.28494364]\n",
      " [-0.27934742 -0.28494763]\n",
      " [-0.28005713 -0.28503725]\n",
      " [-0.27966112 -0.28498727]\n",
      " [-0.27974093 -0.28500116]\n",
      " [-0.27973807 -0.2849947 ]\n",
      " [-0.27967346 -0.2849724 ]\n",
      " [-0.27965558 -0.28500712]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-70908a0f3daf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#     experiments()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mevaluation_with_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-f78e1a5e62df>\u001b[0m in \u001b[0;36mevaluation_with_pretrained\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m## v3: multiply\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdata_dir_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"D:/Projects/Stance/Evaluation/bert_dummy_output/cos_emb\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain_and_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dir_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mrpc\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-c3347218546b>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[1;34m(data_dir, bert_model, task_name, output_dir, max_seq_length, do_train, do_eval, do_lower_case, train_batch_size, eval_batch_size, learning_rate, num_train_epochs, warmup_proportion, no_cuda, local_rank, seed, gradient_accumulation_steps, optimize_on_cpu, fp16, loss_scale, saved_model)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;31m#             print(\"end\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                 \u001b[0mtmp_eval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_segment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_label_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_segment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-29d3ae39e15c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, input_ids2, attention_mask2, token_type_ids2, position_ids2, head_mask2, inputs_embeds2, labels2)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;31m#             position_ids=position_ids,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m#             head_mask=head_mask,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[0;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[0;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[0;32m    734\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_tensor, attention_mask)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[0mself_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\dropout.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m    805\u001b[0m     return (_VF.dropout_(input, p, training)\n\u001b[0;32m    806\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m             else _VF.dropout(input, p, training))\n\u001b[0m\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     experiments()\n",
    "    evaluation_with_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

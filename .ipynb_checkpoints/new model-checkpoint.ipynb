{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "train_file = \"D:/Jupyter/data/dataset/perspective_stances/train.tsv\"\n",
    "\n",
    "df = pd.read_csv(train_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7007"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"lower\")\n",
    "matcher.add(\"not\", None, nlp(\"not\"), nlp(\"n't\"))\n",
    "matcher.add(\"can't\", None, nlp(\"can't\"))\n",
    "\n",
    "\n",
    "matcher_positive = PhraseMatcher(nlp.vocab, attr=\"ORTH\")\n",
    "matcher_positive.add(\"type\", None, nlp(\"is a type of\"), nlp(\"are a type of\") )\n",
    "matcher_positive.add(\"imply\", None, nlp(\"implies\") )\n",
    "matcher_positive.add(\"same\", None, nlp(\"is the same as \"), nlp(\"are the same as \") )\n",
    "matcher_positive.add(\"rephrase\", None, nlp(\" is a rephrasing of\") )\n",
    "matcher_positive.add(\"form\", None, nlp(\"is a another form of\"))\n",
    "matcher_positive.add(\"synonym\", None, nlp(\" is synonymous with\"))\n",
    "matcher_positive.add(\"can_be\", None, nlp(\"can be\"))\n",
    "\n",
    "\n",
    "matcher_positive.add(\"much\", None, nlp(\"much\"), nlp(\"Much\"))\n",
    "matcher_positive.add(\"little\", None, nlp(\"little\"), nlp(\"Little\"))\n",
    "matcher_positive.add(\"more\", None, nlp(\"more\"), nlp(\"More\"))\n",
    "matcher_positive.add(\"less\", None, nlp(\"less\"), nlp(\"Less\"))\n",
    "\n",
    "\n",
    "matcher_positive.add(\"fore_synonym\", None, nlp(\"are synonyms\"), nlp(\"are synonymous\"), nlp(\"is the same thing\"), nlp(\"are the same thing\") )\n",
    "matcher_positive.add(\"then\", None, nlp(\"then\") )\n",
    "matcher_positive.add(\"so\", None, nlp(\"so\") )\n",
    "matcher_positive.add(\"must_be\", None, nlp(\"must be\"))\n",
    "matcher_positive.add(\"hasto\", None, nlp(\"has to be\"))\n",
    "matcher_positive.add(\"is_are\", None, nlp(\"is\"), nlp(\"are\"), nlp(\"Are\"), nlp(\"ARE\"))\n",
    "\n",
    "matcher_positive.add(\"to\", None, nlp(\"to\"))\n",
    "matcher_positive.add(\"To\", None, nlp(\"To\"))\n",
    "matcher_positive.add(\"increase\", None, nlp(\"increase\"), nlp(\"increases\"), nlp(\"Increase\"))\n",
    "\n",
    "matcher_positive.add(\"should\", None, nlp(\"should\"), nlp(\"Should\") )\n",
    "matcher_positive.add(\"would\", None, nlp(\"would\"), nlp(\"Would\"))\n",
    "matcher_positive.add(\"could\", None, nlp(\"could\"), nlp(\"Could\"))\n",
    "matcher_positive.add(\"may\", None, nlp(\"may\"), nlp(\"May\"))\n",
    "matcher_positive.add(\"will\", None, nlp(\"will\"), nlp(\"Will\"))\n",
    "matcher_positive.add(\"can\", None, nlp(\"can\"), nlp(\"Can\"))\n",
    "matcher_positive.add(\"might\", None, nlp(\"might\"), nlp(\"Might\"))\n",
    "matcher_positive.add(\"must\", None, nlp(\"must\"), nlp(\"Must\"), nlp(\"MUST\"))\n",
    "\n",
    "matcher_positive.add(\"encourage\", None, nlp(\"encourage\"), nlp(\"encourages\"), nlp(\"Encourage\"), nlp(\"Encourages\"))\n",
    "\n",
    "matcher_positive.add(\"n’t\", None, nlp(\"n’t\"))\n",
    "matcher_positive.add(\"was_were\", None, nlp(\"was\"), nlp(\"were\"))\n",
    "matcher_positive.add(\"raise\", None, nlp(\"raise\"), nlp(\"raises\"), nlp(\"Raise\"), nlp(\"raising\"), nlp(\"Raising\"))\n",
    "matcher_positive.add(\"better\", None, nlp(\"better\"), nlp(\"Better\"))\n",
    "matcher_positive.add(\"benefit\", None, nlp(\"benefit\"), nlp(\"benefits\"), nlp(\"Benefit\"), nlp(\"Benefits\"))\n",
    "matcher_positive.add(\"lack\", None, nlp(\"lack\"), nlp(\"lacks\"), nlp(\"Lack\"), nlp(\"Lacks\"))\n",
    "matcher_positive.add(\"nothing\", None, nlp(\"nothing\"), nlp(\"Nothing\"))\n",
    "matcher_positive.add(\"positive\", None, nlp(\"positive\"),nlp(\"Positive\"))\n",
    "matcher_positive.add(\"negative\", None, nlp(\"negative\"), nlp(\"Negative\"))\n",
    "matcher_positive.add(\"have\", None, nlp(\"have\"),nlp(\"Have\"))\n",
    "matcher_positive.add(\"has\", None, nlp(\"has\"), nlp(\"Has\"))\n",
    "matcher_positive.add(\"reduce\", None, nlp(\"reduce\"), nlp(\"Reduce\"), nlp(\"reduces\"), nlp(\"Reduces\"), nlp(\"Reduced\"), nlp(\"reduced\"))\n",
    "matcher_positive.add(\"increase\", None, nlp(\"increase\"), nlp(\"Increase\"), nlp(\"increases\"), nlp(\"Increases\"), nlp(\"increased\"), nlp(\"Increased\"))\n",
    "matcher_positive.add(\"without\", None, nlp(\"without\"), nlp(\"Without\"))\n",
    "matcher_positive.add(\"against\", None, nlp(\"against\"), nlp(\"Against\"))\n",
    "matcher_positive.add(\"need\", None, nlp(\"need\"), nlp(\"Need\"), nlp(\"needs\"), nlp(\"Needs\"), nlp(\"needed\"), nlp(\"Needed\"))\n",
    "matcher_positive.add(\"needed\", None, nlp(\"needed\"), nlp(\"Needed\"))\n",
    "matcher_positive.add(\"good\", None, nlp(\"good\"), nlp(\"Good\"))\n",
    "matcher_positive.add(\"bad\", None, nlp(\"bad\"), nlp(\"Bad\"))\n",
    "matcher_positive.add(\"support\", None, nlp(\"support\"), nlp(\"Support\"), nlp(\"supports\"), nlp(\"Supports\"), nlp(\"supported\"), nlp(\"Supported\"))\n",
    "matcher_positive.add(\"hurt_harm_damage\", None, nlp(\"hurt\"), nlp(\"hurts\"), nlp(\"harm\"), nlp(\"harms\"), nlp(\"Hurt\"), nlp(\"Hurts\"), nlp(\"Harm\"), nlp(\"Harms\"), nlp(\"HARM\"), nlp(\"damage\"), nlp(\"damages\"), nlp(\"Damage\"), nlp(\"Damages\"))\n",
    "matcher_positive.add(\"help\", None, nlp(\"help\"), nlp(\"Help\"), nlp(\"helps\"), nlp(\"Helps\"))\n",
    "matcher_positive.add(\"protect\", None, nlp(\"protect\"), nlp(\"Protect\"), nlp(\"protects\"), nlp(\"Protects\"), nlp(\"protecting\"), nlp(\"protected\"), nlp(\"Protecting\"), nlp(\"Protected\"))\n",
    "matcher_positive.add(\"cause\", None, nlp(\"cause\"), nlp(\"Cause\"), nlp(\"causes\"), nlp(\"Causes\"))\n",
    "matcher_positive.add(\"allow\", None, nlp(\"allow\"), nlp(\"Allow\"), nlp(\"allows\"), nlp(\"Allows\"))\n",
    "matcher_positive.add(\"everyone\", None, nlp(\"everyone\"), nlp(\"Everyone\"))\n",
    "matcher_positive.add(\"deserve\", None, nlp(\"deserve\"), nlp(\"Deserve\"), nlp(\"deserves\"), nlp(\"Deserves\"), nlp(\"deserved\"), nlp(\"Deserved\"))\n",
    "\n",
    "\n",
    "opposite = []\n",
    "for perspective in df.perspective:\n",
    "    doc = nlp(perspective)\n",
    "    matches = matcher(doc)\n",
    "    positive_matches = matcher_positive(doc)\n",
    "    if matches:\n",
    "        for match_id, start, end in matches:\n",
    "            rule_id = nlp.vocab.strings[match_id]\n",
    "            if rule_id == \"can't\":\n",
    "                new_seq = str(doc[0:start-1])+\" can \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"not\":\n",
    "                if str(doc[start-1:start]) == \"ca\":\n",
    "                    continue\n",
    "                else:\n",
    "                    new_seq = str(doc[0:start])+\" \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "    elif positive_matches:\n",
    "        for match_id, start, end in positive_matches:\n",
    "            rule_id = nlp.vocab.strings[match_id]\n",
    "            if rule_id == \"type\":\n",
    "                if doc[start:end][0] == \"is\":\n",
    "                    new_seq = str(doc[0:start])+\" is not a type of \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "                elif doc[start:end][0] == \"are\":\n",
    "                    new_seq = str(doc[0:start])+\" are not a type of \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "            elif rule_id == \"imply\":\n",
    "                if doc[start:end][0] == \"implies\":\n",
    "                    new_seq = str(doc[0:start])+\" does not imply \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "                elif doc[start:end][0] == \"imply\":\n",
    "                    new_seq = str(doc[0:start])+\" do not imply \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "            elif rule_id == \"same\":\n",
    "                if doc[start:end][0] == \"is\":\n",
    "                    new_seq = str(doc[0:start])+\" is not the same as \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "                if doc[start:end][0] == \"are\":\n",
    "                    new_seq = str(doc[0:start])+\" are not the same as \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "            elif rule_id == \"rephrase\":\n",
    "                new_seq = str(doc[0:start])+\" is not a rephrasing of \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break \n",
    "            elif rule_id == \"form\":\n",
    "                new_seq = str(doc[0:start])+\" is a another form of \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break \n",
    "            elif rule_id == \"synonym\":\n",
    "                new_seq = str(doc[0:start])+\" is not synonymous with \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break \n",
    "            elif rule_id == \"can_be\":\n",
    "                new_seq = str(doc[0:start])+\" can't be \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break \n",
    "            elif rule_id == \"fore_synonym\":\n",
    "                new_seq = str(doc[0:start])+\" are not synonymous\"\n",
    "                opposite.append(new_seq)\n",
    "                break \n",
    "            elif rule_id == \"then\":\n",
    "                new_seq = str(doc[0:start])+\" doesn't mean \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break \n",
    "            elif rule_id == \"so\":\n",
    "                new_seq = str(doc[0:start])+\" does not mean \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break \n",
    "            elif rule_id == \"must_be\":\n",
    "                new_seq = str(doc[0:start])+\" needn't be \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break \n",
    "            elif rule_id == \"hasto\":\n",
    "                new_seq = str(doc[0:start])+\" doesn't have to be\"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"much\":\n",
    "                if str(doc[start:end][0]) == \"Much\":\n",
    "                    new_seq = str(\"Little \"+str(doc[end:]))\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "                if str(doc[start:end][0]) == \"much\":\n",
    "                    new_seq = str(doc[0:start])+\" little \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "            elif rule_id == \"little\":\n",
    "                if str(doc[start:end][0]) == \"Little\":\n",
    "                    new_seq = str(\"Much \"+str(doc[end:]))\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "                if str(doc[start:end][0]) == \"little\":\n",
    "                    new_seq = str(doc[0:start])+\" much \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "            elif rule_id == \"more\":\n",
    "                if str(doc[start:end][0]) == \"More\":\n",
    "                    new_seq = str(\"Less \"+str(doc[end:]))\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "                if str(doc[start:end][0]) == \"more\":\n",
    "                    new_seq = str(doc[0:start])+\" less \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "            elif rule_id == \"less\":\n",
    "                if str(doc[start:end][0]) == \"Less\":\n",
    "                    new_seq = str(\"More \"+str(doc[end:]))\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "                if str(doc[start:end][0]) == \"less\":\n",
    "                    new_seq = str(doc[0:start])+\" more \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "            elif rule_id == \"is_are\":\n",
    "                if str(doc[start:end][0]) == \"is\":\n",
    "                    new_seq = str(doc[0:start])+\" is not \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "                if str(doc[start:end][0]) == \"are\":\n",
    "                    new_seq = str(doc[0:start])+\" are not \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "                if str(doc[start:end][0]) == \"Are\":\n",
    "                    new_seq = str(doc[0:start])+\" are not \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "                if str(doc[start:end][0]) == \"ARE\":\n",
    "                    new_seq = str(doc[0:start])+\" are not \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "            elif rule_id == \"to\":\n",
    "                new_seq = str(doc[0:start])+\" not to \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"To\":\n",
    "                new_seq = str(doc[0:start])+\" Not to \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"increase\":\n",
    "                new_seq = str(doc[0:start])+\" decrease \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"should\":\n",
    "                new_seq = str(doc[0:start])+\" should not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"would\":\n",
    "                new_seq = str(doc[0:start])+\" would not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"could\":\n",
    "                new_seq = str(doc[0:start])+\" could not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"may\":\n",
    "                new_seq = str(doc[0:start])+\" may not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"will\":\n",
    "                new_seq = str(doc[0:start])+\" will not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"can\":\n",
    "                new_seq = str(doc[0:start])+\" can not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"might\":\n",
    "                new_seq = str(doc[0:start])+\" might not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"must\":\n",
    "                new_seq = str(doc[0:start])+\" must not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"encourage\":\n",
    "                new_seq = str(doc[0:start])+\" discourage \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"n’t\":\n",
    "                new_seq = str(doc[0:start])+\" \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"was_were\":\n",
    "                if str(doc[start:end][0]) == \"was\":\n",
    "                    new_seq = str(doc[0:start])+\" was not \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "                if str(doc[start:end][0]) == \"were\":\n",
    "                    new_seq = str(doc[0:start])+\" were not \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    break\n",
    "            elif rule_id == \"raise\":\n",
    "                new_seq = str(doc[0:start])+\" lower \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"better\":\n",
    "                new_seq = str(doc[0:start])+\" worse \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"benefit\":\n",
    "                new_seq = str(doc[0:start])+\" harm \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"lack\":\n",
    "                new_seq = str(doc[0:start])+\" glut \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"nothing\":\n",
    "                new_seq = str(doc[0:start])+\" something \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"positive\":\n",
    "                new_seq = str(doc[0:start])+\" negative \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"negative\":\n",
    "                new_seq = str(doc[0:start])+\" positive \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"have\":\n",
    "                new_seq = str(doc[0:start])+\" don't have \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"has\":\n",
    "                new_seq = str(doc[0:start])+\" doesn't have \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"reduce\":\n",
    "                new_seq = str(doc[0:start])+\" increase \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"increase\":\n",
    "                new_seq = str(doc[0:start])+\" decrease \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"without\":\n",
    "                new_seq = str(doc[0:start])+\" with \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"against\":\n",
    "                new_seq = str(doc[0:start])+\" for \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"needed\":\n",
    "                new_seq = str(doc[0:start])+\" not needed \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"need\":\n",
    "                new_seq = str(doc[0:start])+\" don't need \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"good\":\n",
    "                new_seq = str(doc[0:start])+\" bad \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"bad\":\n",
    "                new_seq = str(doc[0:start])+\" good \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"support\":\n",
    "                new_seq = str(doc[0:start])+\" oppose \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"hurt_harm_damage\":\n",
    "                new_seq = str(doc[0:start])+\" protect \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"help\":\n",
    "                new_seq = str(doc[0:start])+\" spoil \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"protect\":\n",
    "                new_seq = str(doc[0:start])+\" destroy \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"cause\":\n",
    "                new_seq = str(doc[0:start])+\" casue no \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"allow\":\n",
    "                new_seq = str(doc[0:start])+\" disallow \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"everyone\":\n",
    "                new_seq = str(doc[0:start])+\" noone \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "            elif rule_id == \"deserve\":\n",
    "                new_seq = str(doc[0:start])+\" deserve no \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                break\n",
    "    else:\n",
    "        new_seq = None\n",
    "        opposite.append(new_seq)\n",
    "len(opposite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>claim</th>\n",
       "      <th>perspective</th>\n",
       "      <th>opposite_auto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male infant circumcision is tantamount to chil...</td>\n",
       "      <td>Parents have the right to use their best judgm...</td>\n",
       "      <td>Parents don't have the right to use their best...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male infant circumcision is tantamount to chil...</td>\n",
       "      <td>Parents know what best for thier child</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male infant circumcision is tantamount to chil...</td>\n",
       "      <td>Parents have the right to make the decisions f...</td>\n",
       "      <td>Parents don't have the right to make the decis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>punishment should fit the criminal</td>\n",
       "      <td>It will cause less re-offenders.</td>\n",
       "      <td>It will not cause less re-offenders.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>punishment should fit the criminal</td>\n",
       "      <td>Adequate punishment reduces future offenses.</td>\n",
       "      <td>Adequate punishment increase future offenses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Internet access is a human right</td>\n",
       "      <td>Piracy is unlikely to be stopped without cutti...</td>\n",
       "      <td>Piracy is not unlikely to be stopped without c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Internet access is a human right</td>\n",
       "      <td>These people are breaking the law and need to ...</td>\n",
       "      <td>These people are not breaking the law and need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Internet access is a human right</td>\n",
       "      <td>Criminals deserve to be punished.</td>\n",
       "      <td>Criminals deserve no to be punished.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7005</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Internet access is a human right</td>\n",
       "      <td>Illegal downloaders are breaking the law and d...</td>\n",
       "      <td>Illegal downloaders are not breaking the law a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7006</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Internet access is a human right</td>\n",
       "      <td>It is a big problem, too many people are file-...</td>\n",
       "      <td>It is not a big problem, too many people are f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7007 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  x  y                                              claim  \\\n",
       "0         0  0  0  Male infant circumcision is tantamount to chil...   \n",
       "1         0  0  0  Male infant circumcision is tantamount to chil...   \n",
       "2         0  0  0  Male infant circumcision is tantamount to chil...   \n",
       "3         1  0  0                 punishment should fit the criminal   \n",
       "4         1  0  0                 punishment should fit the criminal   \n",
       "...     ... .. ..                                                ...   \n",
       "7002      0  0  0                   Internet access is a human right   \n",
       "7003      0  0  0                   Internet access is a human right   \n",
       "7004      0  0  0                   Internet access is a human right   \n",
       "7005      0  0  0                   Internet access is a human right   \n",
       "7006      0  0  0                   Internet access is a human right   \n",
       "\n",
       "                                            perspective  \\\n",
       "0     Parents have the right to use their best judgm...   \n",
       "1               Parents know what best for thier child    \n",
       "2     Parents have the right to make the decisions f...   \n",
       "3                      It will cause less re-offenders.   \n",
       "4          Adequate punishment reduces future offenses.   \n",
       "...                                                 ...   \n",
       "7002  Piracy is unlikely to be stopped without cutti...   \n",
       "7003  These people are breaking the law and need to ...   \n",
       "7004                  Criminals deserve to be punished.   \n",
       "7005  Illegal downloaders are breaking the law and d...   \n",
       "7006  It is a big problem, too many people are file-...   \n",
       "\n",
       "                                          opposite_auto  \n",
       "0     Parents don't have the right to use their best...  \n",
       "1                                                  None  \n",
       "2     Parents don't have the right to make the decis...  \n",
       "3                  It will not cause less re-offenders.  \n",
       "4         Adequate punishment increase future offenses.  \n",
       "...                                                 ...  \n",
       "7002  Piracy is not unlikely to be stopped without c...  \n",
       "7003  These people are not breaking the law and need...  \n",
       "7004               Criminals deserve no to be punished.  \n",
       "7005  Illegal downloaders are not breaking the law a...  \n",
       "7006  It is not a big problem, too many people are f...  \n",
       "\n",
       "[7007 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"opposite_auto\"] = opposite\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel(\"train_adversary_beta.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.insert(4,'opposite',df_new[\"opposite_auto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opposite_train = df_new.reset_index(drop=True).drop(\"opposite_auto\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(\"D:/Projects/Stance/Dataset/BertForOppositeCueClassification/train.tsv\",sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_excel(\"adversary_beta.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>claim</th>\n",
       "      <th>perspective</th>\n",
       "      <th>opposite_auto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School Day Should Be Extended</td>\n",
       "      <td>Lessons would feel less broken.</td>\n",
       "      <td>Lessons would not feel less broken.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School Day Should Be Extended</td>\n",
       "      <td>Not enough funding...</td>\n",
       "      <td>enough funding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School Day Should Be Extended</td>\n",
       "      <td>So much easier for parents!</td>\n",
       "      <td>So little easier for parents!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School Day Should Be Extended</td>\n",
       "      <td>Less need for homework.</td>\n",
       "      <td>More need for homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School Day Should Be Extended</td>\n",
       "      <td>Time to finish activities</td>\n",
       "      <td>Time not to finish activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Illegal downloaders should be cut off from the...</td>\n",
       "      <td>Cutting off internet capability is against hum...</td>\n",
       "      <td>Cutting off internet capability is not against...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Illegal downloaders should be cut off from the...</td>\n",
       "      <td>All humans deserve internet access.</td>\n",
       "      <td>All humans deserve no internet access.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Illegal downloaders should be cut off from the...</td>\n",
       "      <td>Internet access is a commodity not a human right.</td>\n",
       "      <td>Internet access is a commodity a human right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Illegal downloaders should be cut off from the...</td>\n",
       "      <td>The internet is a utility not a human right.</td>\n",
       "      <td>The internet is a utility a human right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Illegal downloaders should be cut off from the...</td>\n",
       "      <td>Just as electricity is not a human right, the ...</td>\n",
       "      <td>Just as electricity is a human right, the inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2527 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  x  y                                              claim  \\\n",
       "0         1  0  0                      School Day Should Be Extended   \n",
       "1         0  0  0                      School Day Should Be Extended   \n",
       "2         1  0  0                      School Day Should Be Extended   \n",
       "3         1  0  0                      School Day Should Be Extended   \n",
       "4         1  0  0                      School Day Should Be Extended   \n",
       "...     ... .. ..                                                ...   \n",
       "2768      0  0  0  Illegal downloaders should be cut off from the...   \n",
       "2769      0  0  0  Illegal downloaders should be cut off from the...   \n",
       "2770      1  0  0  Illegal downloaders should be cut off from the...   \n",
       "2771      1  0  0  Illegal downloaders should be cut off from the...   \n",
       "2772      1  0  0  Illegal downloaders should be cut off from the...   \n",
       "\n",
       "                                            perspective  \\\n",
       "0                       Lessons would feel less broken.   \n",
       "1                                 Not enough funding...   \n",
       "2                           So much easier for parents!   \n",
       "3                               Less need for homework.   \n",
       "4                             Time to finish activities   \n",
       "...                                                 ...   \n",
       "2768  Cutting off internet capability is against hum...   \n",
       "2769                All humans deserve internet access.   \n",
       "2770  Internet access is a commodity not a human right.   \n",
       "2771       The internet is a utility not a human right.   \n",
       "2772  Just as electricity is not a human right, the ...   \n",
       "\n",
       "                                          opposite_auto  \n",
       "0                   Lessons would not feel less broken.  \n",
       "1                                     enough funding...  \n",
       "2                         So little easier for parents!  \n",
       "3                               More need for homework.  \n",
       "4                         Time not to finish activities  \n",
       "...                                                 ...  \n",
       "2768  Cutting off internet capability is not against...  \n",
       "2769             All humans deserve no internet access.  \n",
       "2770      Internet access is a commodity a human right.  \n",
       "2771           The internet is a utility a human right.  \n",
       "2772  Just as electricity is a human right, the inte...  \n",
       "\n",
       "[2527 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_new.insert(4,'opposite',df_test_new[\"opposite_auto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opposite_test = df_test_new.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>claim</th>\n",
       "      <th>perspective</th>\n",
       "      <th>opposite_auto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School Day Should Be Extended</td>\n",
       "      <td>Lessons would feel less broken.</td>\n",
       "      <td>Lessons would not feel less broken.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School Day Should Be Extended</td>\n",
       "      <td>Not enough funding...</td>\n",
       "      <td>enough funding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School Day Should Be Extended</td>\n",
       "      <td>So much easier for parents!</td>\n",
       "      <td>So little easier for parents!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School Day Should Be Extended</td>\n",
       "      <td>Less need for homework.</td>\n",
       "      <td>More need for homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School Day Should Be Extended</td>\n",
       "      <td>Time to finish activities</td>\n",
       "      <td>Time not to finish activities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Illegal downloaders should be cut off from the...</td>\n",
       "      <td>Cutting off internet capability is against hum...</td>\n",
       "      <td>Cutting off internet capability is not against...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Illegal downloaders should be cut off from the...</td>\n",
       "      <td>All humans deserve internet access.</td>\n",
       "      <td>All humans deserve no internet access.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Illegal downloaders should be cut off from the...</td>\n",
       "      <td>Internet access is a commodity not a human right.</td>\n",
       "      <td>Internet access is a commodity a human right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Illegal downloaders should be cut off from the...</td>\n",
       "      <td>The internet is a utility not a human right.</td>\n",
       "      <td>The internet is a utility a human right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Illegal downloaders should be cut off from the...</td>\n",
       "      <td>Just as electricity is not a human right, the ...</td>\n",
       "      <td>Just as electricity is a human right, the inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2527 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  x  y                                              claim  \\\n",
       "0         1  0  0                      School Day Should Be Extended   \n",
       "1         0  0  0                      School Day Should Be Extended   \n",
       "2         1  0  0                      School Day Should Be Extended   \n",
       "3         1  0  0                      School Day Should Be Extended   \n",
       "4         1  0  0                      School Day Should Be Extended   \n",
       "...     ... .. ..                                                ...   \n",
       "2522      0  0  0  Illegal downloaders should be cut off from the...   \n",
       "2523      0  0  0  Illegal downloaders should be cut off from the...   \n",
       "2524      1  0  0  Illegal downloaders should be cut off from the...   \n",
       "2525      1  0  0  Illegal downloaders should be cut off from the...   \n",
       "2526      1  0  0  Illegal downloaders should be cut off from the...   \n",
       "\n",
       "                                            perspective  \\\n",
       "0                       Lessons would feel less broken.   \n",
       "1                                 Not enough funding...   \n",
       "2                           So much easier for parents!   \n",
       "3                               Less need for homework.   \n",
       "4                             Time to finish activities   \n",
       "...                                                 ...   \n",
       "2522  Cutting off internet capability is against hum...   \n",
       "2523                All humans deserve internet access.   \n",
       "2524  Internet access is a commodity not a human right.   \n",
       "2525       The internet is a utility not a human right.   \n",
       "2526  Just as electricity is not a human right, the ...   \n",
       "\n",
       "                                          opposite_auto  \n",
       "0                   Lessons would not feel less broken.  \n",
       "1                                     enough funding...  \n",
       "2                         So little easier for parents!  \n",
       "3                               More need for homework.  \n",
       "4                         Time not to finish activities  \n",
       "...                                                 ...  \n",
       "2522  Cutting off internet capability is not against...  \n",
       "2523             All humans deserve no internet access.  \n",
       "2524      Internet access is a commodity a human right.  \n",
       "2525           The internet is a utility a human right.  \n",
       "2526  Just as electricity is a human right, the inte...  \n",
       "\n",
       "[2527 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opposite_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opposite_test.to_csv(\"D:/Projects/Stance/Dataset/BertForOppositeCueClassification/test.tsv\",sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "# torch.cuda.empty_cache()\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "# from pytorch_pretrained_bert.tokenization import BertTokenizer, WordpieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_classifier import ColaProcessor, MrpcProcessor, logger, convert_examples_to_features,\\\n",
    "    set_optimizer_params_grad, copy_optimizer_params_to_model, accuracy, p_r_f1, tp_pcount_gcount, convert_claims_to_features, convert_opposite_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "#     device = torch.device(\"cuda\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('There are %d GPU(s) available.' % n_gpu)\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 16:06:59 - INFO - transformers.file_utils -   PyTorch version 1.4.0 available.\n",
      "05/13/2020 16:07:00 - INFO - transformers.file_utils -   TensorFlow version 2.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertPreTrainedModel, BertModel, BertConfig\n",
    "from torch.nn import BCEWithLogitsLoss, CosineEmbeddingLoss,CrossEntropyLoss, MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class BertForOppositeCueClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_labels=2):\n",
    "        super(BertForOppositeCueClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size+1, num_labels)\n",
    "        self.classifier2 = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "        self.apply(self.init_bert_weights)\n",
    "#         self.init_weights()\n",
    "\n",
    "#     @add_start_docstrings_to_callable(BERT_INPUTS_DOCSTRING)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        input_ids2=None,\n",
    "        attention_mask2=None,\n",
    "        token_type_ids2=None,\n",
    "        position_ids2=None,\n",
    "        head_mask2=None,\n",
    "        inputs_embeds2=None,\n",
    "        labels2=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n",
    "            Labels for computing the sequence classification/regression loss.\n",
    "            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n",
    "            If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "\n",
    "    Returns:\n",
    "        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.BertConfig`) and inputs:\n",
    "        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n",
    "            Classification (or regression if config.num_labels==1) loss.\n",
    "        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`):\n",
    "            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
    "        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
    "            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
    "\n",
    "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n",
    "            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n",
    "\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        from transformers import BertTokenizer, BertForSequenceClassification\n",
    "        import torch\n",
    "\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "\n",
    "        loss, logits = outputs[:2]\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        _, outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "#             position_ids=position_ids,\n",
    "#             head_mask=head_mask,\n",
    "#             inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        _, outputsC = self.bert(\n",
    "            input_ids2,\n",
    "            attention_mask=attention_mask2,\n",
    "            token_type_ids=token_type_ids2,\n",
    "#             position_ids=position_ids2,\n",
    "#             head_mask=head_mask2,\n",
    "#             inputs_embeds=inputs_embeds2,\n",
    "        )\n",
    "#         print(\"Careful, outputs:\")\n",
    "#         print(outputs)\n",
    "#         print(outputsC)\n",
    "        pooled_output = outputs\n",
    "        pooled_outputC = outputsC\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_outputC = self.dropout(pooled_outputC)\n",
    "        \n",
    "#         cos_pooled_outputs = torch.cosine_similarity(pooled_output, pooled_outputC, dim=1)\n",
    "        euclidean_distance = F.pairwise_distance(pooled_output, pooled_outputC)\n",
    "        print(\"euclidean_distance\")\n",
    "        print(euclidean_distance)\n",
    "        print(euclidean_distance.unsqueeze(1))\n",
    "        print('pooled_output size:')\n",
    "        print(pooled_output.size())\n",
    "        print(pooled_output)\n",
    "#         print('cos_pooled_outputs size:')\n",
    "#         print(cos_pooled_outputs.size())\n",
    "#         print(cos_pooled_outputs)\n",
    "        batch_size = list(pooled_output.size())[0]\n",
    "        hidden_size = list(pooled_output.size())[1]\n",
    "\n",
    "        logits_ce = self.classifier2(pooled_output)\n",
    "        print('logits_ce:')\n",
    "        print(logits_ce)\n",
    "        \n",
    "        logits_ce_opp = self.classifier2(pooled_outputC)\n",
    "        print('logits_ce_opp:')\n",
    "        print(logits_ce_opp)\n",
    "        \n",
    "    \n",
    "        ## v2: concat\n",
    "        ## v3: multiply\n",
    "        ## v4: v2 & ce_cos_similarity\n",
    "        ## v5: v3 & ce_cos_similarity\n",
    "        print('pooled_output'+str(pooled_output))\n",
    "        print('euc_output'+str(torch.cat((pooled_output, euclidean_distance.unsqueeze(1)),1)))\n",
    "#         print(torch.cat((pooled_output, cos_pooled_outputs.unsqueeze(1)),1))\n",
    "#         print((pooled_output*cos_pooled_outputs.unsqueeze(1)))\n",
    "        logits_pairwise = self.classifier(torch.cat((pooled_output, euclidean_distance.unsqueeze(1)),1))\n",
    "#         logits_cos = self.classifier2((pooled_output*cos_pooled_outputs.unsqueeze(1)))\n",
    "#         self.classifier = torch.nn.Linear(hidden_size+batch_size, 2).to(device)\n",
    "#         logits_cos = self.classifier(torch.cat((pooled_output, cos_pooled_outputs.repeat(batch_size,1)),1))\n",
    "        print('logits_pairwise:')\n",
    "        print(logits_pairwise)\n",
    "        \n",
    "        \n",
    "        logits_pairwise_opp = self.classifier(torch.cat((pooled_outputC, euclidean_distance.unsqueeze(1)),1))\n",
    "        print('logits_pairwise_opp:')\n",
    "        print(logits_pairwise_opp)\n",
    "#         final_logits = [1.5*logits_ce[0]+0.5*logits_cos[1],1.5*logits_ce[1]+0.5*logits_cos[0]]\n",
    "#         print(final_logits)\n",
    "#         logits = self.classifier(pooled_output)\n",
    "#         logitsC = self.classifier(pooled_outputC)\n",
    "\n",
    "#         outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "#         print(logits)\n",
    "#         print('xd')\n",
    "#         print(outputs[2:])\n",
    "#         outputs = (logits,) + outputs[2:]\n",
    "        print(\"labels:\"+ labels)\n",
    "        print(labels)\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "#                 loss_fct_ce = CrossEntropyLoss()\n",
    "#                 loss_ce = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "                loss_fct_ce = CrossEntropyLoss()\n",
    "#                 print('pooled_output size:')\n",
    "#                 print(pooled_output.size())\n",
    "#                 loss_ce = loss_fct_ce(logits_ce.view(-1, self.num_labels), labels.view(-1))\n",
    "                loss_ce = loss_fct_ce(logits_pairwise.view(-1, self.num_labels), labels.view(-1))\n",
    "#                 loss_ce = loss_fct_ce(pooled_output.view(-1), labels.view(-1))\n",
    "#                 print('loss_ce:')\n",
    "#                 print(loss_ce)\n",
    "                \n",
    "                criterion = ContrastiveLoss()\n",
    "                labels2[labels2==1] = 0\n",
    "                print(\"labels2\")\n",
    "                print(labels2)\n",
    "                loss_contrastive = criterion(logits_ce,logits_ce_opp,labels2)\n",
    "                print(\"loss_contrastive\")\n",
    "                print(loss_contrastive)\n",
    "#                 loss_fct_cos = CosineEmbeddingLoss()\n",
    "#                 print(labels)\n",
    "#                 print(pooled_outputC)\n",
    "\n",
    "\n",
    "#                 labels2[labels2==0] = -1\n",
    "#                 loss_cos = loss_fct_cos(pooled_output, pooled_outputC, labels2)\n",
    "        \n",
    "        \n",
    "#                 loss_cos = loss_fct_cos(logits_ce, logits_cos, labels2)\n",
    "#                 loss_cos = loss_fct_ce(logits_cos.view(-1, self.num_labels), labels2.view(-1))\n",
    "#                 print('loss_cos:')\n",
    "#                 print(loss_cos)\n",
    "            \n",
    "#                 loss = loss_ce + loss_contrastive\n",
    "                loss = loss_contrastive\n",
    "\n",
    "#                 print('final loss:')\n",
    "#                 print(loss)\n",
    "#                 logits = self.classifier(loss)\n",
    "#             outputs = (loss,) + outputs\n",
    "#             outputs = (loss,) + logits_cos \n",
    "                outputs = loss\n",
    "                return outputs\n",
    "        else:\n",
    "            return logits_ce, logits_ce_opp, logits_pairwise, logits_pairwise_opp\n",
    "        \n",
    "          # (loss), logits, (hidden_states), (attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labe = torch.ones(8)\n",
    "# print(labe )\n",
    "# labe[labe==1] = -1\n",
    "# labe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.tensor([[4.2,5,6,7,8],[9,10,11,12,13]])\n",
    "# b = torch.tensor([[3.4,5,6,7,8],[9,10,11,12,13]])\n",
    "\n",
    "# # a = torch.tensor([[4,5,6,7,8],[9,10,11,12,13]])\n",
    "# # b = torch.tensor([1,2])\n",
    "# c= torch.cosine_similarity(a,b,dim=1)\n",
    "# # b.unsqueeze(1)\n",
    "# # # a.size()\n",
    "# # torch.cat((a,c.unsqueeze(1)),1)\n",
    "# a*c.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input1 = torch.randn(100, 128)\n",
    "# input2 = torch.randn(100, 128)\n",
    "# output = torch.cosine_similarity(input1, input2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 20:28:07 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\arsen\\.cache\\torch\\transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 20:28:23 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\arsen\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "05/13/2020 20:28:23 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file C:\\Users\\arsen\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\arsen\\AppData\\Local\\Temp\\tmp7zz8iha3\n",
      "05/13/2020 20:28:26 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/13/2020 20:28:29 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForOppositeCueClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias', 'classifier2.weight', 'classifier2.bias']\n",
      "05/13/2020 20:28:29 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForOppositeCueClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForOppositeCueClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=769, out_features=2, bias=True)\n",
       "  (classifier2): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare model \n",
    "model = BertForOppositeCueClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 203 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "classifier.weight                                           (2, 769)\n",
      "classifier.bias                                                 (2,)\n",
      "classifier2.weight                                          (2, 768)\n",
      "classifier2.bias                                                (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "    \n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 20:28:29 - INFO - run_classifier -   LOOKING AT D:/Projects/Stance/Dataset/BertForOppositeCueClassification/train.tsv\n"
     ]
    }
   ],
   "source": [
    "# data_dir = \"D:/Jupyter/data/dataset/perspective_stances/\"\n",
    "data_dir = \"D:/Projects/Stance/Dataset/BertForOppositeCueClassification/\"\n",
    "data_dir_output = \"D:/Projects/Stance/Models/BertForOppositeCueClassification/\"\n",
    "output_dir=data_dir_output\n",
    "max_seq_length=32\n",
    "max_grad_norm = 1.0\n",
    "num_training_steps = 1000\n",
    "num_warmup_steps = 100\n",
    "warmup_proportion = float(num_warmup_steps) / float(num_training_steps)  # 0.1\n",
    "# warmup_proportion = 0.1\n",
    "train_batch_size=32\n",
    "eval_batch_size=8\n",
    "learning_rate=5e-5\n",
    "num_train_epochs=3\n",
    "local_rank=-1\n",
    "seed=42\n",
    "gradient_accumulation_steps=1\n",
    "loss_scale=128\n",
    "train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "\n",
    "processors = {\n",
    "        \"mrpc\": MrpcProcessor,\n",
    "    }\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "processor = processors['mrpc']()\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)\n",
    "# print('label list')\n",
    "# print(label_list)\n",
    "\n",
    "train_examples = processor.get_train_examples(data_dir)\n",
    "# train_examples = opposite_train\n",
    "num_train_steps = int(\n",
    "    len(train_examples) / train_batch_size / gradient_accumulation_steps * num_train_epochs)\n",
    "\n",
    "##preprare optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "t_total = num_train_steps\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=learning_rate,\n",
    "                         warmup=warmup_proportion,\n",
    "                         t_total=t_total)\n",
    "# optimizer = AdamW(optimizer_grouped_parameters,\n",
    "#                   lr = learning_rate, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "#                   eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n",
    "#                   correct_bias=False\n",
    "#                 )\n",
    "\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)  # PyTorch scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 20:28:30 - INFO - run_classifier -   *** Example ***\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   guid: train-1\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP] parents have the right to use their best judgment , in the light of medical advice [SEP]\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 3008 2031 1996 2157 2000 2224 2037 2190 8689 1010 1999 1996 2422 1997 2966 6040 102\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   *** Example ***\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   guid: train-2\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP] parents have the right to make the decisions for their child [SEP]\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 3008 2031 1996 2157 2000 2191 1996 6567 2005 2037 2775 102 0 0 0 0 0\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   *** Example ***\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   guid: train-3\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   tokens: [CLS] punishment should fit the criminal [SEP] it will cause less re - offenders . [SEP]\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   input_ids: 101 7750 2323 4906 1996 4735 102 2009 2097 3426 2625 2128 1011 19591 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   *** Example ***\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   guid: train-4\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   tokens: [CLS] punishment should fit the criminal [SEP] adequate punishment reduces future offenses . [SEP]\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   input_ids: 101 7750 2323 4906 1996 4735 102 11706 7750 13416 2925 25173 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   *** Example ***\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   guid: train-5\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   tokens: [CLS] punishment should fit the criminal [SEP] just punishment will lead to less criminals re - off ##ending . [SEP]\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   input_ids: 101 7750 2323 4906 1996 4735 102 2074 7750 2097 2599 2000 2625 12290 2128 1011 2125 18537 1012 102 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:30 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   *** Opposite Example ***\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   guid: train-1\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP] parents don ' t have the right to use their best judgment , in the light [SEP]\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 3008 2123 1005 1056 2031 1996 2157 2000 2224 2037 2190 8689 1010 1999 1996 2422 102\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   *** Opposite Example ***\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   guid: train-2\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP] parents don ' t have the right to make the decisions for their child [SEP]\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 3008 2123 1005 1056 2031 1996 2157 2000 2191 1996 6567 2005 2037 2775 102 0 0\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   *** Opposite Example ***\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   guid: train-3\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   tokens: [CLS] punishment should fit the criminal [SEP] it will not cause less re - offenders . [SEP]\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   input_ids: 101 7750 2323 4906 1996 4735 102 2009 2097 2025 3426 2625 2128 1011 19591 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   *** Opposite Example ***\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   guid: train-4\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   tokens: [CLS] punishment should fit the criminal [SEP] adequate punishment increase future offenses . [SEP]\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   input_ids: 101 7750 2323 4906 1996 4735 102 11706 7750 3623 2925 25173 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   *** Opposite Example ***\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   guid: train-5\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   tokens: [CLS] punishment should fit the criminal [SEP] just punishment will not lead to less criminals re - off ##ending . [SEP]\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   input_ids: 101 7750 2323 4906 1996 4735 102 2074 7750 2097 2025 2599 2000 2625 12290 2128 1011 2125 18537 1012 102 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:28:33 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:28:36 - INFO - run_classifier -   ***** Running training *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 20:28:36 - INFO - run_classifier -     Num examples = 6270\n",
      "05/13/2020 20:28:36 - INFO - run_classifier -     Batch size = 32\n",
      "05/13/2020 20:28:36 - INFO - run_classifier -     Num steps = 587\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "train_features = convert_examples_to_features(train_examples, label_list, max_seq_length, tokenizer)\n",
    "claim_features = convert_opposite_to_features(train_examples, label_list, max_seq_length, tokenizer)\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "\n",
    "claims_input_ids = torch.tensor([f.input_ids for f in claim_features], dtype=torch.long)\n",
    "claims_input_mask = torch.tensor([f.input_mask for f in claim_features], dtype=torch.long)\n",
    "claims_segment_ids = torch.tensor([f.segment_ids for f in claim_features], dtype=torch.long)\n",
    "claims_label_ids = torch.tensor([f.label_id for f in claim_features], dtype=torch.long)\n",
    "\n",
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, claims_input_ids, claims_input_mask, claims_segment_ids, claims_label_ids)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
    "\n",
    "# claims_data = TensorDataset(claims_input_ids, claims_input_mask, claims_segment_ids, claims_label_ids)\n",
    "# claims_sampler = RandomSampler(claims_data)\n",
    "# claims_dataloader = DataLoader(claims_data, sampler=train_sampler, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                                                               | 0/196 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean_distance\n",
      "tensor([12.7194, 12.3745, 11.0939,  9.4765, 12.3384, 11.8043, 12.3196, 12.2199,\n",
      "        11.4680, 11.6769, 11.9150, 11.0933, 11.6156, 10.8868, 11.6597, 10.7240,\n",
      "        11.9314, 10.8695, 11.8920,  9.4473, 12.0135, 12.2085, 12.0006, 12.2887,\n",
      "        12.1261, 10.8682, 12.3208, 11.2677, 11.8122, 11.6547, 11.1110, 11.3643],\n",
      "       grad_fn=<NormBackward1>)\n",
      "tensor([[12.7194],\n",
      "        [12.3745],\n",
      "        [11.0939],\n",
      "        [ 9.4765],\n",
      "        [12.3384],\n",
      "        [11.8043],\n",
      "        [12.3196],\n",
      "        [12.2199],\n",
      "        [11.4680],\n",
      "        [11.6769],\n",
      "        [11.9150],\n",
      "        [11.0933],\n",
      "        [11.6156],\n",
      "        [10.8868],\n",
      "        [11.6597],\n",
      "        [10.7240],\n",
      "        [11.9314],\n",
      "        [10.8695],\n",
      "        [11.8920],\n",
      "        [ 9.4473],\n",
      "        [12.0135],\n",
      "        [12.2085],\n",
      "        [12.0006],\n",
      "        [12.2887],\n",
      "        [12.1261],\n",
      "        [10.8682],\n",
      "        [12.3208],\n",
      "        [11.2677],\n",
      "        [11.8122],\n",
      "        [11.6547],\n",
      "        [11.1110],\n",
      "        [11.3643]], grad_fn=<UnsqueezeBackward0>)\n",
      "pooled_output size:\n",
      "torch.Size([32, 768])\n",
      "tensor([[-1.0993, -1.0208, -0.0000,  ..., -1.1096, -1.0629,  1.0833],\n",
      "        [-1.0981, -0.9849, -1.1105,  ..., -1.1013, -1.0425,  1.0978],\n",
      "        [-1.0884, -0.9929, -1.1106,  ..., -1.1007, -1.0341,  1.0732],\n",
      "        ...,\n",
      "        [-1.0768, -0.9994, -0.0000,  ..., -1.1092, -1.0204,  1.0686],\n",
      "        [-1.0609, -0.8388, -1.1005,  ..., -1.0205, -0.9926,  1.0070],\n",
      "        [-0.0000, -0.8896, -1.1098,  ..., -1.0906, -0.9938,  0.9868]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "logits_ce:\n",
      "tensor([[-0.2140,  0.2348],\n",
      "        [-0.3367, -0.0052],\n",
      "        [-0.2842,  0.1734],\n",
      "        [-0.1865, -0.0714],\n",
      "        [ 0.1283,  0.0458],\n",
      "        [ 0.1406,  0.4572],\n",
      "        [-0.1743,  0.4626],\n",
      "        [-0.2096, -0.1434],\n",
      "        [-0.0869,  0.1006],\n",
      "        [ 0.0323,  0.3467],\n",
      "        [-0.2525,  0.1366],\n",
      "        [-0.3025,  0.0763],\n",
      "        [-0.1937,  0.0071],\n",
      "        [-0.0253, -0.0186],\n",
      "        [ 0.1661,  0.4732],\n",
      "        [-0.3408,  0.4457],\n",
      "        [-0.3021,  0.1543],\n",
      "        [-0.2860,  0.2198],\n",
      "        [-0.3200,  0.2005],\n",
      "        [-0.2763, -0.0725],\n",
      "        [-0.2736, -0.0032],\n",
      "        [-0.2752,  0.3583],\n",
      "        [-0.2753,  0.2208],\n",
      "        [-0.1589,  0.2409],\n",
      "        [-0.2002,  0.0300],\n",
      "        [-0.3874,  0.1776],\n",
      "        [-0.2874,  0.1730],\n",
      "        [-0.2462,  0.0734],\n",
      "        [-0.1031,  0.3997],\n",
      "        [-0.2577,  0.1215],\n",
      "        [-0.4288,  0.1236],\n",
      "        [-0.4339,  0.1199]], grad_fn=<AddmmBackward>)\n",
      "logits_ce_opp:\n",
      "tensor([[-0.3358,  0.1037],\n",
      "        [ 0.0200,  0.2910],\n",
      "        [-0.1481, -0.0146],\n",
      "        [-0.3706,  0.0379],\n",
      "        [ 0.1575,  0.3842],\n",
      "        [-0.1280,  0.2638],\n",
      "        [-0.5594,  0.2139],\n",
      "        [-0.4229,  0.0428],\n",
      "        [-0.2046,  0.1745],\n",
      "        [-0.2327,  0.0094],\n",
      "        [ 0.0689,  0.1973],\n",
      "        [-0.4059,  0.3044],\n",
      "        [-0.2508,  0.1617],\n",
      "        [-0.0325,  0.2027],\n",
      "        [-0.2225,  0.0680],\n",
      "        [-0.4429,  0.0809],\n",
      "        [-0.4768,  0.5515],\n",
      "        [-0.4065,  0.3268],\n",
      "        [-0.3483,  0.2662],\n",
      "        [-0.2343,  0.2591],\n",
      "        [-0.2384, -0.1788],\n",
      "        [-0.1134, -0.0027],\n",
      "        [-0.4770, -0.0554],\n",
      "        [-0.3019,  0.1880],\n",
      "        [-0.0404,  0.0877],\n",
      "        [-0.3172, -0.0289],\n",
      "        [-0.3400,  0.2110],\n",
      "        [-0.2536,  0.0818],\n",
      "        [-0.1467,  0.0802],\n",
      "        [-0.5000,  0.3128],\n",
      "        [-0.3749,  0.1831],\n",
      "        [-0.3736,  0.0539]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|                                                                               | 0/196 [00:02<?, ?it/s]\n",
      "Epoch:   0%|                                                                                     | 0/3 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"Tensor\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-7b329c402b96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#         print(\"end\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mout_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_segment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_label_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;31m#         loss = ce_loss + cos_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"out_results:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-7df455f9d9dd>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, input_ids2, attention_mask2, token_type_ids2, position_ids2, head_mask2, inputs_embeds2, labels2)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;31m## v4: v2 & ce_cos_similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m## v5: v3 & ce_cos_similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pooled_output'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'euc_output'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;31m#         print(torch.cat((pooled_output, cos_pooled_outputs.unsqueeze(1)),1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"Tensor\") to str"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids, claim_input_ids, claim_input_mask, claim_segment_ids, claim_label_ids = batch\n",
    "#         ce_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "#         cos_loss = model(claim_input_ids, claim_segment_ids, claim_input_mask, claim_label_ids)\n",
    "        \n",
    "#         print(\"start\")\n",
    "#         print(input_ids)\n",
    "#         print(input_mask)\n",
    "#         print(segment_ids)\n",
    "#         print(label_ids)\n",
    "#         print(claim_input_ids)\n",
    "#         print(claim_input_mask)\n",
    "#         print(claim_segment_ids)\n",
    "#         print(claim_label_ids)\n",
    "#         print(\"end\")\n",
    "    \n",
    "        out_results = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, labels=label_ids, input_ids2=claim_input_ids, token_type_ids2=claim_segment_ids, attention_mask2=claim_input_mask, labels2=claim_label_ids)\n",
    "#         loss = ce_loss + cos_loss\n",
    "        print(\"out_results:\")\n",
    "        print(out_results)\n",
    "        loss = out_results\n",
    "#         print(cos_loss)\n",
    "#         print(loss.item())\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "#         if fp16 and loss_scale != 1.0:\n",
    "#             # rescale loss for fp16 training\n",
    "#             # see https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html\n",
    "#             loss = loss * loss_scale\n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "#             if fp16 or optimize_on_cpu:\n",
    "#                 if fp16 and loss_scale != 1.0:\n",
    "#                     # scale down gradients for fp16 training\n",
    "#                     for param in model.parameters():\n",
    "#                         if param.grad is not None:\n",
    "#                             param.grad.data = param.grad.data / loss_scale           \n",
    "#                 is_nan = set_optimizer_params_grad(param_optimizer, model.named_parameters(), test_nan=True)\n",
    "#                 if is_nan:\n",
    "#                     logger.info(\"FP16 TRAINING: Nan in gradients, reducing loss scaling\")\n",
    "#                     loss_scale = loss_scale / 2\n",
    "#                     model.zero_grad()\n",
    "#                     continue \n",
    "#                 optimizer.step()\n",
    "# #                 scheduler.step()\n",
    "#                 copy_optimizer_params_to_model(model.named_parameters(), param_optimizer)\n",
    "#             else:\n",
    "#                 torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "#                 scheduler.step()\n",
    "            model.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "        \n",
    "## v2: concat\n",
    "## v3: multiply\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "torch.save(model.state_dict(), output_dir + \"BertForOppositeClassification.pth\")\n",
    "torch.save(model_to_save.state_dict(), output_dir + \"finetuned_BertForOppositeClassification.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "def train_and_test(data_dir, bert_model=\"bert-base-uncased\", task_name=None,\n",
    "                   output_dir=None, max_seq_length=32, do_train=False, do_eval=False, do_lower_case=False,\n",
    "                   train_batch_size=32, eval_batch_size=8, learning_rate=5e-5, num_train_epochs=3,\n",
    "                   warmup_proportion=0.1,no_cuda=False, local_rank=-1, seed=42, gradient_accumulation_steps=1,\n",
    "                   optimize_on_cpu=False, fp16=False, loss_scale=128, saved_model=\"\"):\n",
    "\n",
    "\n",
    "    # ## Required parameters\n",
    "    # parser.add_argument(\"--data_dir\",\n",
    "    #                     default=None,\n",
    "    #                     type=str,\n",
    "    #                     required=True,\n",
    "    #                     help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n",
    "    # parser.add_argument(\"--bert_model\", default=None, type=str, required=True,\n",
    "    #                     help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
    "    #                          \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\")\n",
    "    # parser.add_argument(\"--task_name\",\n",
    "    #                     default=None,\n",
    "    #                     type=str,\n",
    "    #                     required=True,\n",
    "    #                     help=\"The name of the task to train.\")\n",
    "    # parser.add_argument(\"--output_dir\",\n",
    "    #                     default=None,\n",
    "    #                     type=str,\n",
    "    #                     required=True,\n",
    "    #                     help=\"The output directory where the model checkpoints will be written.\")\n",
    "\n",
    "    ## Other parameters\n",
    "    # parser.add_argument(\"--max_seq_length\",\n",
    "    #                     default=128,\n",
    "    #                     type=int,\n",
    "    #                     help=\"The maximum total input sequence length after WordPiece tokenization. \\n\"\n",
    "    #                          \"Sequences longer than this will be truncated, and sequences shorter \\n\"\n",
    "    #                          \"than this will be padded.\")\n",
    "    # parser.add_argument(\"--do_train\",\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to run training.\")\n",
    "    # parser.add_argument(\"--do_eval\",\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to run eval on the dev set.\")\n",
    "    # parser.add_argument(\"--do_lower_case\",\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Set this flag if you are using an uncased model.\")\n",
    "    # parser.add_argument(\"--train_batch_size\",\n",
    "    #                     default=32,\n",
    "    #                     type=int,\n",
    "    #                     help=\"Total batch size for training.\")\n",
    "    # parser.add_argument(\"--eval_batch_size\",\n",
    "    #                     default=8,\n",
    "    #                     type=int,\n",
    "    #                     help=\"Total batch size for eval.\")\n",
    "    # parser.add_argument(\"--learning_rate\",\n",
    "    #                     default=5e-5,\n",
    "    #                     type=float,\n",
    "    #                     help=\"The initial learning rate for Adam.\")\n",
    "    # parser.add_argument(\"--num_train_epochs\",\n",
    "    #                     default=3.0,\n",
    "    #                     type=float,\n",
    "    #                     help=\"Total number of training epochs to perform.\")\n",
    "    # parser.add_argument(\"--warmup_proportion\",\n",
    "    #                     default=0.1,\n",
    "    #                     type=float,\n",
    "    #                     help=\"Proportion of training to perform linear learning rate warmup for. \"\n",
    "    #                          \"E.g., 0.1 = 10%% of training.\")\n",
    "    # parser.add_argument(\"--no_cuda\",\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether not to use CUDA when available\")\n",
    "    # parser.add_argument(\"--local_rank\",\n",
    "    #                     type=int,\n",
    "    #                     default=-1,\n",
    "    #                     help=\"local_rank for distributed training on gpus\")\n",
    "    # parser.add_argument('--seed',\n",
    "    #                     type=int,\n",
    "    #                     default=42,\n",
    "    #                     help=\"random seed for initialization\")\n",
    "    # parser.add_argument('--gradient_accumulation_steps',\n",
    "    #                     type=int,\n",
    "    #                     default=1,\n",
    "    #                     help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "    # parser.add_argument('--optimize_on_cpu',\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to perform optimization and keep the optimizer averages on CPU\")\n",
    "    # parser.add_argument('--fp16',\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to use 16-bit float precision instead of 32-bit\")\n",
    "    # parser.add_argument('--loss_scale',\n",
    "    #                     type=float, default=128,\n",
    "    #                     help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    processors = {\n",
    "#         \"cola\": ColaProcessor,\n",
    "#         \"mnli\": MnliProcessor,\n",
    "        \"mrpc\": MrpcProcessor,\n",
    "    }\n",
    "\n",
    "    if local_rank == -1 or no_cuda:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "    else:\n",
    "        device = torch.device(\"cuda\", local_rank)\n",
    "        n_gpu = 1\n",
    "        # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "        torch.distributed.init_process_group(backend='nccl')\n",
    "        if fp16:\n",
    "            logger.info(\"16-bits training currently not supported in distributed training\")\n",
    "            fp16 = False # (see https://github.com/pytorch/pytorch/pull/13496)\n",
    "    logger.info(\"device %s n_gpu %d distributed training %r\", device, n_gpu, bool(local_rank != -1))\n",
    "\n",
    "    if gradient_accumulation_steps < 1:\n",
    "        raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(\n",
    "                            gradient_accumulation_steps))\n",
    "\n",
    "    train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    if not do_train and not do_eval:\n",
    "        raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "    if do_train:\n",
    "        if os.path.exists(output_dir) and os.listdir(output_dir):\n",
    "            raise ValueError(\"Output directory ({}) already exists and is not emp1ty.\".format(output_dir))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    task_name = task_name.lower()\n",
    "\n",
    "    if task_name not in processors:\n",
    "        raise ValueError(\"Task not found: %s\" % (task_name))\n",
    "\n",
    "    processor = processors[task_name]()\n",
    "    label_list = processor.get_labels()\n",
    "\n",
    "#     tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=do_lower_case)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    train_examples = None\n",
    "    num_train_steps = None\n",
    "    if do_train:\n",
    "        train_examples = processor.get_train_examples(data_dir)\n",
    "        num_train_steps = int(\n",
    "            len(train_examples) / train_batch_size / gradient_accumulation_steps * num_train_epochs)\n",
    "\n",
    "    # Prepare model\n",
    "#     model = BertForSequenceClassification.from_pretrained(bert_model,\n",
    "#                 cache_dir=PYTORCH_PRETRAINED_BERT_CACHE / 'distributed_{}'.format(local_rank), num_labels = 2)\n",
    "\n",
    "        model = BertForOppositeCueClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "        model.to(device)\n",
    "        if fp16:\n",
    "            model.half()\n",
    "\n",
    "        if local_rank != -1:\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank],\n",
    "                                                              output_device=local_rank)\n",
    "        elif n_gpu > 1:\n",
    "            model = torch.nn.DataParallel(model)\n",
    "\n",
    "        # Prepare optimizer\n",
    "        if fp16:\n",
    "            param_optimizer = [(n, param.clone().detach().to('cpu').float().requires_grad_()) \\\n",
    "                                for n, param in model.named_parameters()]\n",
    "        elif optimize_on_cpu:\n",
    "            param_optimizer = [(n, param.clone().detach().to('cpu').requires_grad_()) \\\n",
    "                                for n, param in model.named_parameters()]\n",
    "        else:\n",
    "            param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "            ]\n",
    "        t_total = num_train_steps\n",
    "#     print(t_total)\n",
    "    if local_rank != -1:\n",
    "        t_total = t_total // torch.distributed.get_world_size()\n",
    "    if do_train:\n",
    "        optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=learning_rate,\n",
    "                         warmup=warmup_proportion,\n",
    "                         t_total=t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    if do_train:\n",
    "        train_features = convert_examples_to_features(\n",
    "            train_examples, label_list, max_seq_length, tokenizer)\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "        logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "        logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "        train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "        if local_rank == -1:\n",
    "            train_sampler = RandomSampler(train_data)\n",
    "        else:\n",
    "            train_sampler = DistributedSampler(train_data)\n",
    "        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
    "\n",
    "        model.train()\n",
    "        for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
    "            tr_loss = 0\n",
    "            nb_tr_examples, nb_tr_steps = 0, 0\n",
    "            for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids, input_mask, segment_ids, label_ids, = batch\n",
    "                loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "                if n_gpu > 1:\n",
    "                    loss = loss.mean() # mean() to average on multi-gpu.\n",
    "                if fp16 and loss_scale != 1.0:\n",
    "                    # rescale loss for fp16 training\n",
    "                    # see https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html\n",
    "                    loss = loss * loss_scale\n",
    "                if gradient_accumulation_steps > 1:\n",
    "                    loss = loss / gradient_accumulation_steps\n",
    "                loss.backward()\n",
    "                tr_loss += loss.item()\n",
    "                nb_tr_examples += input_ids.size(0)\n",
    "                nb_tr_steps += 1\n",
    "                if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                    if fp16 or optimize_on_cpu:\n",
    "                        if fp16 and loss_scale != 1.0:\n",
    "                            # scale down gradients for fp16 training\n",
    "                            for param in model.parameters():\n",
    "                                if param.grad is not None:\n",
    "                                    param.grad.data = param.grad.data / loss_scale\n",
    "                        is_nan = set_optimizer_params_grad(param_optimizer, model.named_parameters(), test_nan=True)\n",
    "                        if is_nan:\n",
    "                            logger.info(\"FP16 TRAINING: Nan in gradients, reducing loss scaling\")\n",
    "                            loss_scale = loss_scale / 2\n",
    "                            model.zero_grad()\n",
    "                            continue\n",
    "                        optimizer.step()\n",
    "                        copy_optimizer_params_to_model(model.named_parameters(), param_optimizer)\n",
    "                    else:\n",
    "                        optimizer.step()\n",
    "                    model.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "        torch.save(model.state_dict(), output_dir + \"output.pth\")\n",
    "\n",
    "\n",
    "    if do_eval and (local_rank == -1 or torch.distributed.get_rank() == 0):\n",
    "        eval_examples = processor.get_test_examples(data_dir)\n",
    "#         eval_examples = processor.get_dev_examples(data_dir)\n",
    "        eval_features = convert_examples_to_features(\n",
    "            eval_examples, label_list, max_seq_length, tokenizer)\n",
    "        claim_features = convert_opposite_to_features(eval_examples, label_list, max_seq_length, tokenizer)    \n",
    "    \n",
    "        logger.info(\"***** Running evaluation *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "        logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "        \n",
    "        claims_input_ids = torch.tensor([f.input_ids for f in claim_features], dtype=torch.long)\n",
    "        claims_input_mask = torch.tensor([f.input_mask for f in claim_features], dtype=torch.long)\n",
    "        claims_segment_ids = torch.tensor([f.segment_ids for f in claim_features], dtype=torch.long)\n",
    "        claims_label_ids = torch.tensor([f.label_id for f in claim_features], dtype=torch.long)\n",
    "        \n",
    "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, claims_input_ids, claims_input_mask, claims_segment_ids, claims_label_ids)\n",
    "        # Run prediction for full data\n",
    "#         eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "#         print('all_input_ids:')\n",
    "#         print(all_input_ids)\n",
    "        \n",
    "        \n",
    "\n",
    "#         model.load_state_dict(torch.load(saved_model))\n",
    "        model_state_dict = torch.load(saved_model)\n",
    "        model = BertForOppositeCueClassification.from_pretrained('bert-base-uncased', num_labels=2, state_dict=model_state_dict)\n",
    "        model.to(device)\n",
    "        \n",
    "        model.eval()\n",
    "        # eval_loss, eval_accuracy = 0, 0\n",
    "\n",
    "        eval_tp, eval_pred_c, eval_gold_c = 0, 0, 0\n",
    "        eval_loss, eval_macro_p, eval_macro_r = 0, 0, 0\n",
    "\n",
    "        raw_score = []\n",
    "\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "        for input_ids, input_mask, segment_ids, label_ids, claim_input_ids, claim_input_mask, claim_segment_ids, claim_label_ids in eval_dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "            claim_input_ids = claim_input_ids.to(device)\n",
    "            claim_input_mask = claim_input_mask.to(device)\n",
    "            claim_segment_ids = claim_segment_ids.to(device)\n",
    "            claim_label_ids = claim_label_ids.to(device)\n",
    "\n",
    "#             print(\"start\")\n",
    "#             print(input_ids)\n",
    "#             print(input_mask)\n",
    "#             print(segment_ids)\n",
    "#             print(label_ids)\n",
    "#             print(claim_input_ids)\n",
    "#             print(claim_input_mask)\n",
    "#             print(claim_segment_ids)\n",
    "#             print(claim_label_ids)\n",
    "#             print(\"end\")\n",
    "            with torch.no_grad():\n",
    "                tmp_eval_loss = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, labels=label_ids, input_ids2=claim_input_ids, token_type_ids2=claim_segment_ids, attention_mask2=claim_input_mask, labels2=claim_label_ids)\n",
    "                \n",
    "                logits,_,_,_ = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, input_ids2=claim_input_ids, token_type_ids2=claim_segment_ids, attention_mask2=claim_input_mask)\n",
    "            \n",
    "#             print(logits)\n",
    "#             print(logits[0])\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            print('logits:')\n",
    "            print(logits)\n",
    "            \n",
    "            claim_label_ids[claim_label_ids==0] = -1\n",
    "            claim_label_ids[claim_label_ids==1] = 2\n",
    "            claim_label_ids[claim_label_ids==-1] = 1\n",
    "            claim_label_ids[claim_label_ids==2] = 0\n",
    "            \n",
    "            \n",
    "#             print(label_ids)\n",
    "#             label_ids[label_ids==0] = -1\n",
    "#             label_ids[label_ids==1] = 2\n",
    "#             label_ids[label_ids==-1] = 1\n",
    "#             label_ids[label_ids==2] = 0\n",
    "            label_ids = label_ids.to('cpu').numpy()\n",
    "            claim_label_ids = claim_label_ids.to('cpu').numpy()\n",
    "            print(label_ids)\n",
    "            print(claim_label_ids)\n",
    "            # Micro F1 (aggregated tp, fp, fn counts across all examples)\n",
    "            tmp_tp, tmp_pred_c, tmp_gold_c = tp_pcount_gcount(logits, label_ids)\n",
    "            eval_tp += tmp_tp\n",
    "            eval_pred_c += tmp_pred_c\n",
    "            eval_gold_c += tmp_gold_c\n",
    "            \n",
    "            pred_label = np.argmax(logits, axis=1)\n",
    "            raw_score += zip(logits, pred_label, label_ids)\n",
    "            \n",
    "            # Macro F1 (averaged P, R across mini batches)\n",
    "            tmp_eval_p, tmp_eval_r, tmp_eval_f1 = p_r_f1(logits, label_ids)\n",
    "\n",
    "            eval_macro_p += tmp_eval_p\n",
    "            eval_macro_r += tmp_eval_r\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_examples += input_ids.size(0)\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "\n",
    "        # Micro F1 (aggregated tp, fp, fn counts across all examples)\n",
    "        eval_micro_p = eval_tp / eval_pred_c\n",
    "        eval_micro_r = eval_tp / eval_gold_c\n",
    "        eval_micro_f1 = 2 * eval_micro_p * eval_micro_r / (eval_micro_p + eval_micro_r)\n",
    "\n",
    "        # Macro F1 (averaged P, R across mini batches)\n",
    "        eval_macro_p = eval_macro_p / nb_eval_steps\n",
    "        eval_macro_r = eval_macro_r / nb_eval_steps\n",
    "        eval_macro_f1 = 2 * eval_macro_p * eval_macro_r / (eval_macro_p + eval_macro_r)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        result = {\n",
    "                  'eval_loss': eval_loss,\n",
    "                  'eval_micro_p': eval_micro_p,\n",
    "                  'eval_micro_r': eval_micro_r,\n",
    "                  'eval_micro_f1': eval_micro_f1,\n",
    "                  'eval_macro_p': eval_macro_p,\n",
    "                  'eval_macro_r': eval_macro_r,\n",
    "                  'eval_macro_f1': eval_macro_f1,\n",
    "#                   'global_step': global_step,\n",
    "#                   'loss': tr_loss/nb_tr_steps\n",
    "                  }\n",
    "\n",
    "        output_eval_file = os.path.join(output_dir, \"BertForOppositeCueClassification_eval_results.txt\")\n",
    "        output_raw_score = os.path.join(output_dir, \"BertForOppositeCueClassification_raw_score.csv\")\n",
    "        with open(output_eval_file, \"w\") as writer:\n",
    "            logger.info(\"***** Eval results *****\")\n",
    "            for key in sorted(result.keys()):\n",
    "                logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "        with open(output_raw_score, 'w') as fout:\n",
    "            fields = [\"undermine_score\", \"support_score\",\"predict_label\", \"gold\"]\n",
    "            writer = csv.DictWriter(fout, fieldnames=fields)\n",
    "            writer.writeheader()\n",
    "            for score, pred, gold in raw_score:\n",
    "                writer.writerow({\n",
    "                    \"undermine_score\": str(score[0]),\n",
    "                    \"support_score\": str(score[1]),\n",
    "                    \"predict_label\": str(pred),\n",
    "                    \"gold\": str(gold)\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiments():\n",
    "    data_dir = \"D:/Jupyter/data/dataset/perspective_stances/\"\n",
    "    \n",
    "#     data_dir = \"/home/syg340/Dataset/\"\n",
    "\n",
    "    # data_dir_output = data_dir + \"output2/\"\n",
    "    data_dir_output = \"D:/Projects/Stance/Models/\"\n",
    "    train_and_test(data_dir=data_dir, do_train=True, do_eval=True, output_dir=data_dir_output,task_name=\"Mrpc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_with_pretrained():\n",
    "    bert_model = \"D:/Projects/Stance/Models/BertForOppositeCueClassification/BertForOppositeClassification.pth\"\n",
    "#     data_dir = \"D:/Jupyter/data/dataset/perspective_stances/\"\n",
    "    data_dir = \"D:/Projects/Stance/Dataset/BertForOppositeCueClassification/\"\n",
    "    # data_dir_output = data_dir + \"output2/\"\n",
    "    ## v2: concat\n",
    "    ## v3: multiply\n",
    "    data_dir_output = \"D:/Projects/Stance/Evaluation/bert_dummy_output/BertForOppositeClassification\"\n",
    "    train_and_test(data_dir=data_dir, do_train=False, do_eval=True, output_dir=data_dir_output,task_name=\"mrpc\",saved_model=bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 20:05:32 - INFO - run_classifier -   device cuda n_gpu 1 distributed training False\n",
      "05/13/2020 20:05:41 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\arsen\\.cache\\torch\\transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   *** Example ***\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   guid: test-1\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] lessons would feel less broken . [SEP]\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 8220 2052 2514 2625 3714 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   *** Example ***\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   guid: test-2\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] not enough funding . . . [SEP]\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2025 2438 4804 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   *** Example ***\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   guid: test-3\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] so much easier for parents ! [SEP]\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2061 2172 6082 2005 3008 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   *** Example ***\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   guid: test-4\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] less need for homework . [SEP]\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2625 2342 2005 19453 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   *** Example ***\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   guid: test-5\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] time to finish activities [SEP]\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2051 2000 3926 3450 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:41 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   *** Opposite Example ***\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   guid: test-1\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] lessons would not feel less broken . [SEP]\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 8220 2052 2025 2514 2625 3714 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   *** Opposite Example ***\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   guid: test-2\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] enough funding . . . [SEP]\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2438 4804 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   *** Opposite Example ***\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   guid: test-3\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] so little easier for parents ! [SEP]\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2061 2210 6082 2005 3008 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   *** Opposite Example ***\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   guid: test-4\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] more need for homework . [SEP]\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2062 2342 2005 19453 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   *** Opposite Example ***\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   guid: test-5\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] time not to finish activities [SEP]\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2051 2025 2000 3926 3450 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/13/2020 20:05:42 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/13/2020 20:05:44 - INFO - run_classifier -   ***** Running evaluation *****\n",
      "05/13/2020 20:05:44 - INFO - run_classifier -     Num examples = 2527\n",
      "05/13/2020 20:05:44 - INFO - run_classifier -     Batch size = 8\n",
      "05/13/2020 20:05:50 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\arsen\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/13/2020 20:05:50 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file C:\\Users\\arsen\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\arsen\\AppData\\Local\\Temp\\tmp4wj3sc_0\n",
      "05/13/2020 20:05:54 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean_distance\n",
      "tensor([0.0143, 0.0122, 0.0211, 0.0064, 0.0129, 0.0049, 0.0048, 0.0046],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0143],\n",
      "        [0.0122],\n",
      "        [0.0211],\n",
      "        [0.0064],\n",
      "        [0.0129],\n",
      "        [0.0049],\n",
      "        [0.0048],\n",
      "        [0.0046]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[-1.2044e-03,  7.8306e-04, -2.7737e-03,  ...,  1.6791e-03,\n",
      "         -1.4439e-03,  8.6810e-04],\n",
      "        [-1.1190e-03,  2.4284e-04, -2.3417e-04,  ...,  2.7013e-03,\n",
      "         -1.7279e-03,  6.4885e-04],\n",
      "        [-5.9809e-04,  4.8669e-05, -2.8662e-03,  ...,  2.2880e-03,\n",
      "         -1.5161e-03, -1.4056e-03],\n",
      "        ...,\n",
      "        [ 1.6916e-03, -2.8957e-04, -3.0504e-03,  ...,  8.7748e-04,\n",
      "         -2.2042e-04,  2.5687e-04],\n",
      "        [ 2.1673e-03, -1.0221e-03, -2.7509e-03,  ...,  6.5991e-04,\n",
      "          2.2526e-04,  3.2253e-04],\n",
      "        [ 1.8750e-03, -3.7672e-07, -2.0544e-03,  ...,  1.4068e-03,\n",
      "         -3.0051e-04,  7.4410e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 1.8016e-03, -1.0716e-03],\n",
      "        [ 1.9309e-03, -6.6127e-04],\n",
      "        [ 1.4659e-03, -8.4498e-04],\n",
      "        [ 1.7607e-03, -6.6850e-04],\n",
      "        [ 2.9383e-04, -4.7000e-05],\n",
      "        [ 4.2398e-04, -9.0728e-04],\n",
      "        [-7.5335e-05, -1.0755e-03],\n",
      "        [-1.3609e-04, -2.3063e-04]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 1.8960e-03, -1.1664e-03],\n",
      "        [ 1.6195e-03, -5.2717e-04],\n",
      "        [ 1.6030e-03, -6.8864e-04],\n",
      "        [ 1.8282e-03, -4.7881e-04],\n",
      "        [ 5.7971e-04, -4.1831e-04],\n",
      "        [ 4.0855e-04, -9.5946e-04],\n",
      "        [-6.0086e-05, -1.1442e-03],\n",
      "        [-8.9921e-05, -3.2506e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0118,  0.0127],\n",
      "        [-0.0121,  0.0122],\n",
      "        [-0.0117,  0.0135],\n",
      "        [-0.0116,  0.0128],\n",
      "        [-0.0119,  0.0129],\n",
      "        [-0.0126,  0.0151],\n",
      "        [-0.0124,  0.0153],\n",
      "        [-0.0129,  0.0150]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0119,  0.0129],\n",
      "        [-0.0122,  0.0122],\n",
      "        [-0.0114,  0.0132],\n",
      "        [-0.0115,  0.0127],\n",
      "        [-0.0117,  0.0131],\n",
      "        [-0.0127,  0.0151],\n",
      "        [-0.0125,  0.0153],\n",
      "        [-0.0130,  0.0150]], device='cuda:0')\n",
      "labels:\n",
      "tensor([1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0001, device='cuda:0')\n",
      "euclidean_distance\n",
      "tensor([0.0143, 0.0122, 0.0211, 0.0064, 0.0129, 0.0049, 0.0048, 0.0046],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0143],\n",
      "        [0.0122],\n",
      "        [0.0211],\n",
      "        [0.0064],\n",
      "        [0.0129],\n",
      "        [0.0049],\n",
      "        [0.0048],\n",
      "        [0.0046]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[-1.2044e-03,  7.8306e-04, -2.7737e-03,  ...,  1.6791e-03,\n",
      "         -1.4439e-03,  8.6810e-04],\n",
      "        [-1.1190e-03,  2.4284e-04, -2.3417e-04,  ...,  2.7013e-03,\n",
      "         -1.7279e-03,  6.4885e-04],\n",
      "        [-5.9809e-04,  4.8669e-05, -2.8662e-03,  ...,  2.2880e-03,\n",
      "         -1.5161e-03, -1.4056e-03],\n",
      "        ...,\n",
      "        [ 1.6916e-03, -2.8957e-04, -3.0504e-03,  ...,  8.7748e-04,\n",
      "         -2.2042e-04,  2.5687e-04],\n",
      "        [ 2.1673e-03, -1.0221e-03, -2.7509e-03,  ...,  6.5991e-04,\n",
      "          2.2526e-04,  3.2253e-04],\n",
      "        [ 1.8750e-03, -3.7672e-07, -2.0544e-03,  ...,  1.4068e-03,\n",
      "         -3.0051e-04,  7.4410e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 1.8016e-03, -1.0716e-03],\n",
      "        [ 1.9309e-03, -6.6127e-04],\n",
      "        [ 1.4659e-03, -8.4498e-04],\n",
      "        [ 1.7607e-03, -6.6850e-04],\n",
      "        [ 2.9383e-04, -4.7000e-05],\n",
      "        [ 4.2398e-04, -9.0728e-04],\n",
      "        [-7.5335e-05, -1.0755e-03],\n",
      "        [-1.3609e-04, -2.3063e-04]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 1.8960e-03, -1.1664e-03],\n",
      "        [ 1.6195e-03, -5.2717e-04],\n",
      "        [ 1.6030e-03, -6.8864e-04],\n",
      "        [ 1.8282e-03, -4.7881e-04],\n",
      "        [ 5.7971e-04, -4.1831e-04],\n",
      "        [ 4.0855e-04, -9.5946e-04],\n",
      "        [-6.0086e-05, -1.1442e-03],\n",
      "        [-8.9921e-05, -3.2506e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0118,  0.0127],\n",
      "        [-0.0121,  0.0122],\n",
      "        [-0.0117,  0.0135],\n",
      "        [-0.0116,  0.0128],\n",
      "        [-0.0119,  0.0129],\n",
      "        [-0.0126,  0.0151],\n",
      "        [-0.0124,  0.0153],\n",
      "        [-0.0129,  0.0150]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0119,  0.0129],\n",
      "        [-0.0122,  0.0122],\n",
      "        [-0.0114,  0.0132],\n",
      "        [-0.0115,  0.0127],\n",
      "        [-0.0117,  0.0131],\n",
      "        [-0.0127,  0.0151],\n",
      "        [-0.0125,  0.0153],\n",
      "        [-0.0130,  0.0150]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 1.8015896e-03 -1.0715901e-03]\n",
      " [ 1.9308670e-03 -6.6126866e-04]\n",
      " [ 1.4659276e-03 -8.4497704e-04]\n",
      " [ 1.7606551e-03 -6.6849723e-04]\n",
      " [ 2.9382715e-04 -4.6999892e-05]\n",
      " [ 4.2397983e-04 -9.0728007e-04]\n",
      " [-7.5334625e-05 -1.0755494e-03]\n",
      " [-1.3608742e-04 -2.3063483e-04]]\n",
      "[1 0 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "euclidean_distance\n",
      "tensor([0.0048, 0.0188, 0.0056, 0.0067, 0.0069, 0.0165, 0.0052, 0.0080],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0048],\n",
      "        [0.0188],\n",
      "        [0.0056],\n",
      "        [0.0067],\n",
      "        [0.0069],\n",
      "        [0.0165],\n",
      "        [0.0052],\n",
      "        [0.0080]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 2.1673e-03, -1.0221e-03, -2.7509e-03,  ...,  6.5991e-04,\n",
      "          2.2526e-04,  3.2253e-04],\n",
      "        [ 1.9225e-03, -1.9939e-05, -2.3108e-03,  ...,  3.8006e-04,\n",
      "         -2.7429e-04, -1.3240e-04],\n",
      "        [ 1.5414e-03, -2.4855e-04, -2.6020e-03,  ..., -5.6230e-04,\n",
      "         -7.6650e-04,  7.4086e-04],\n",
      "        ...,\n",
      "        [ 1.1023e-03,  2.9951e-04, -1.2201e-03,  ...,  5.6074e-04,\n",
      "          4.9109e-04, -8.7465e-04],\n",
      "        [ 1.4174e-03, -5.5395e-04, -2.1260e-03,  ...,  4.8280e-04,\n",
      "          2.1987e-04, -4.7348e-05],\n",
      "        [ 8.1172e-04,  2.6173e-04, -3.0819e-03,  ...,  3.0780e-04,\n",
      "         -5.5957e-04,  1.3419e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-7.5335e-05, -1.0755e-03],\n",
      "        [ 1.9639e-04, -9.3958e-04],\n",
      "        [ 6.8412e-04, -5.1927e-04],\n",
      "        [-4.9068e-04, -5.9871e-04],\n",
      "        [-4.2038e-04, -5.7957e-04],\n",
      "        [ 6.3511e-04, -5.1294e-04],\n",
      "        [-5.4291e-05, -9.4016e-04],\n",
      "        [ 8.3388e-04, -1.1883e-03]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[-6.0086e-05, -1.1442e-03],\n",
      "        [ 2.6856e-04, -7.5497e-04],\n",
      "        [ 9.5042e-04, -7.1747e-04],\n",
      "        [ 2.5366e-05, -4.7962e-04],\n",
      "        [ 1.2468e-04, -4.8346e-04],\n",
      "        [ 7.5529e-04, -7.3890e-04],\n",
      "        [-7.5300e-05, -8.7427e-04],\n",
      "        [ 9.5452e-04, -1.4316e-03]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0124,  0.0153],\n",
      "        [-0.0127,  0.0149],\n",
      "        [-0.0133,  0.0146],\n",
      "        [-0.0126,  0.0156],\n",
      "        [-0.0127,  0.0152],\n",
      "        [-0.0128,  0.0143],\n",
      "        [-0.0128,  0.0145],\n",
      "        [-0.0132,  0.0145]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0125,  0.0153],\n",
      "        [-0.0126,  0.0148],\n",
      "        [-0.0133,  0.0146],\n",
      "        [-0.0126,  0.0156],\n",
      "        [-0.0127,  0.0151],\n",
      "        [-0.0125,  0.0141],\n",
      "        [-0.0130,  0.0145],\n",
      "        [-0.0133,  0.0147]], device='cuda:0')\n",
      "labels:\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0001, device='cuda:0')\n",
      "euclidean_distance\n",
      "tensor([0.0048, 0.0188, 0.0056, 0.0067, 0.0069, 0.0165, 0.0052, 0.0080],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0048],\n",
      "        [0.0188],\n",
      "        [0.0056],\n",
      "        [0.0067],\n",
      "        [0.0069],\n",
      "        [0.0165],\n",
      "        [0.0052],\n",
      "        [0.0080]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 2.1673e-03, -1.0221e-03, -2.7509e-03,  ...,  6.5991e-04,\n",
      "          2.2526e-04,  3.2253e-04],\n",
      "        [ 1.9225e-03, -1.9939e-05, -2.3108e-03,  ...,  3.8006e-04,\n",
      "         -2.7429e-04, -1.3240e-04],\n",
      "        [ 1.5414e-03, -2.4855e-04, -2.6020e-03,  ..., -5.6230e-04,\n",
      "         -7.6650e-04,  7.4086e-04],\n",
      "        ...,\n",
      "        [ 1.1023e-03,  2.9951e-04, -1.2201e-03,  ...,  5.6074e-04,\n",
      "          4.9109e-04, -8.7465e-04],\n",
      "        [ 1.4174e-03, -5.5395e-04, -2.1260e-03,  ...,  4.8280e-04,\n",
      "          2.1987e-04, -4.7348e-05],\n",
      "        [ 8.1172e-04,  2.6173e-04, -3.0819e-03,  ...,  3.0780e-04,\n",
      "         -5.5957e-04,  1.3419e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-7.5335e-05, -1.0755e-03],\n",
      "        [ 1.9639e-04, -9.3958e-04],\n",
      "        [ 6.8412e-04, -5.1927e-04],\n",
      "        [-4.9068e-04, -5.9871e-04],\n",
      "        [-4.2038e-04, -5.7957e-04],\n",
      "        [ 6.3511e-04, -5.1294e-04],\n",
      "        [-5.4291e-05, -9.4016e-04],\n",
      "        [ 8.3388e-04, -1.1883e-03]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[-6.0086e-05, -1.1442e-03],\n",
      "        [ 2.6856e-04, -7.5497e-04],\n",
      "        [ 9.5042e-04, -7.1747e-04],\n",
      "        [ 2.5366e-05, -4.7962e-04],\n",
      "        [ 1.2468e-04, -4.8346e-04],\n",
      "        [ 7.5529e-04, -7.3890e-04],\n",
      "        [-7.5300e-05, -8.7427e-04],\n",
      "        [ 9.5452e-04, -1.4316e-03]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0124,  0.0153],\n",
      "        [-0.0127,  0.0149],\n",
      "        [-0.0133,  0.0146],\n",
      "        [-0.0126,  0.0156],\n",
      "        [-0.0127,  0.0152],\n",
      "        [-0.0128,  0.0143],\n",
      "        [-0.0128,  0.0145],\n",
      "        [-0.0132,  0.0145]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0125,  0.0153],\n",
      "        [-0.0126,  0.0148],\n",
      "        [-0.0133,  0.0146],\n",
      "        [-0.0126,  0.0156],\n",
      "        [-0.0127,  0.0151],\n",
      "        [-0.0125,  0.0141],\n",
      "        [-0.0130,  0.0145],\n",
      "        [-0.0133,  0.0147]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[-7.5334625e-05 -1.0755494e-03]\n",
      " [ 1.9639358e-04 -9.3957700e-04]\n",
      " [ 6.8411627e-04 -5.1926513e-04]\n",
      " [-4.9068476e-04 -5.9870619e-04]\n",
      " [-4.2038050e-04 -5.7956984e-04]\n",
      " [ 6.3511188e-04 -5.1294349e-04]\n",
      " [-5.4291275e-05 -9.4015559e-04]\n",
      " [ 8.3388388e-04 -1.1883122e-03]]\n",
      "[1 1 1 1 1 0 0 0]\n",
      "[1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean_distance\n",
      "tensor([0.0061, 0.0367, 0.0072, 0.0061, 0.0059, 0.0069, 0.0059, 0.0066],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0061],\n",
      "        [0.0367],\n",
      "        [0.0072],\n",
      "        [0.0061],\n",
      "        [0.0059],\n",
      "        [0.0069],\n",
      "        [0.0059],\n",
      "        [0.0066]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 9.0162e-04, -5.2385e-05, -2.3583e-03,  ...,  6.4370e-05,\n",
      "          1.9092e-04, -1.0393e-04],\n",
      "        [ 1.4174e-03, -5.5395e-04, -2.1260e-03,  ...,  4.8280e-04,\n",
      "          2.1987e-04, -4.7348e-05],\n",
      "        [ 7.8787e-04,  4.6361e-04, -3.9120e-03,  ..., -5.0546e-04,\n",
      "         -5.4320e-04,  6.7108e-04],\n",
      "        ...,\n",
      "        [ 1.1076e-03,  1.2713e-04, -1.7374e-03,  ...,  1.1060e-03,\n",
      "         -4.4733e-04, -2.2719e-04],\n",
      "        [ 1.4080e-03,  1.9733e-04, -6.2458e-04,  ...,  1.2906e-03,\n",
      "          3.0735e-04,  5.3727e-04],\n",
      "        [ 2.2351e-04,  3.3563e-05, -9.5652e-04,  ...,  1.0802e-03,\n",
      "          4.1159e-04,  6.4306e-05]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 8.2145e-04, -1.0030e-03],\n",
      "        [-5.4291e-05, -9.4016e-04],\n",
      "        [ 8.8859e-04, -5.5321e-04],\n",
      "        [ 1.5080e-03, -3.3632e-04],\n",
      "        [ 1.0117e-03, -5.9742e-04],\n",
      "        [ 5.1994e-04, -9.1516e-04],\n",
      "        [ 4.9405e-04, -6.2236e-04],\n",
      "        [ 3.8483e-04, -9.0762e-04]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 8.2608e-04, -1.1927e-03],\n",
      "        [-7.5378e-05,  3.4324e-05],\n",
      "        [ 6.2441e-04, -3.1971e-04],\n",
      "        [ 1.6404e-03, -5.7783e-04],\n",
      "        [ 7.4110e-04, -3.7442e-04],\n",
      "        [ 9.9440e-04, -8.6801e-04],\n",
      "        [ 5.7883e-04, -7.0296e-04],\n",
      "        [ 8.6483e-04, -8.6858e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0130,  0.0142],\n",
      "        [-0.0125,  0.0147],\n",
      "        [-0.0131,  0.0149],\n",
      "        [-0.0129,  0.0143],\n",
      "        [-0.0134,  0.0145],\n",
      "        [-0.0131,  0.0148],\n",
      "        [-0.0131,  0.0149],\n",
      "        [-0.0130,  0.0144]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0130,  0.0142],\n",
      "        [-0.0122,  0.0141],\n",
      "        [-0.0132,  0.0150],\n",
      "        [-0.0130,  0.0143],\n",
      "        [-0.0133,  0.0145],\n",
      "        [-0.0131,  0.0148],\n",
      "        [-0.0131,  0.0148],\n",
      "        [-0.0130,  0.0145]], device='cuda:0')\n",
      "labels:\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0002, device='cuda:0')\n",
      "euclidean_distance\n",
      "tensor([0.0061, 0.0367, 0.0072, 0.0061, 0.0059, 0.0069, 0.0059, 0.0066],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0061],\n",
      "        [0.0367],\n",
      "        [0.0072],\n",
      "        [0.0061],\n",
      "        [0.0059],\n",
      "        [0.0069],\n",
      "        [0.0059],\n",
      "        [0.0066]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 9.0162e-04, -5.2385e-05, -2.3583e-03,  ...,  6.4370e-05,\n",
      "          1.9092e-04, -1.0393e-04],\n",
      "        [ 1.4174e-03, -5.5395e-04, -2.1260e-03,  ...,  4.8280e-04,\n",
      "          2.1987e-04, -4.7348e-05],\n",
      "        [ 7.8787e-04,  4.6361e-04, -3.9120e-03,  ..., -5.0546e-04,\n",
      "         -5.4320e-04,  6.7108e-04],\n",
      "        ...,\n",
      "        [ 1.1076e-03,  1.2713e-04, -1.7374e-03,  ...,  1.1060e-03,\n",
      "         -4.4733e-04, -2.2719e-04],\n",
      "        [ 1.4080e-03,  1.9733e-04, -6.2458e-04,  ...,  1.2906e-03,\n",
      "          3.0735e-04,  5.3727e-04],\n",
      "        [ 2.2351e-04,  3.3563e-05, -9.5652e-04,  ...,  1.0802e-03,\n",
      "          4.1159e-04,  6.4306e-05]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 8.2145e-04, -1.0030e-03],\n",
      "        [-5.4291e-05, -9.4016e-04],\n",
      "        [ 8.8859e-04, -5.5321e-04],\n",
      "        [ 1.5080e-03, -3.3632e-04],\n",
      "        [ 1.0117e-03, -5.9742e-04],\n",
      "        [ 5.1994e-04, -9.1516e-04],\n",
      "        [ 4.9405e-04, -6.2236e-04],\n",
      "        [ 3.8483e-04, -9.0762e-04]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 8.2608e-04, -1.1927e-03],\n",
      "        [-7.5378e-05,  3.4324e-05],\n",
      "        [ 6.2441e-04, -3.1971e-04],\n",
      "        [ 1.6404e-03, -5.7783e-04],\n",
      "        [ 7.4110e-04, -3.7442e-04],\n",
      "        [ 9.9440e-04, -8.6801e-04],\n",
      "        [ 5.7883e-04, -7.0296e-04],\n",
      "        [ 8.6483e-04, -8.6858e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0130,  0.0142],\n",
      "        [-0.0125,  0.0147],\n",
      "        [-0.0131,  0.0149],\n",
      "        [-0.0129,  0.0143],\n",
      "        [-0.0134,  0.0145],\n",
      "        [-0.0131,  0.0148],\n",
      "        [-0.0131,  0.0149],\n",
      "        [-0.0130,  0.0144]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0130,  0.0142],\n",
      "        [-0.0122,  0.0141],\n",
      "        [-0.0132,  0.0150],\n",
      "        [-0.0130,  0.0143],\n",
      "        [-0.0133,  0.0145],\n",
      "        [-0.0131,  0.0148],\n",
      "        [-0.0131,  0.0148],\n",
      "        [-0.0130,  0.0145]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 8.2144944e-04 -1.0030096e-03]\n",
      " [-5.4291275e-05 -9.4015559e-04]\n",
      " [ 8.8858663e-04 -5.5320654e-04]\n",
      " [ 1.5080423e-03 -3.3631557e-04]\n",
      " [ 1.0117162e-03 -5.9741875e-04]\n",
      " [ 5.1993795e-04 -9.1515982e-04]\n",
      " [ 4.9405388e-04 -6.2235660e-04]\n",
      " [ 3.8483352e-04 -9.0762478e-04]]\n",
      "[0 0 0 0 0 1 1 1]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "euclidean_distance\n",
      "tensor([0.0060, 0.0037, 0.0051, 0.0130, 0.0133, 0.0138, 0.0093, 0.0172],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0060],\n",
      "        [0.0037],\n",
      "        [0.0051],\n",
      "        [0.0130],\n",
      "        [0.0133],\n",
      "        [0.0138],\n",
      "        [0.0093],\n",
      "        [0.0172]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 1.1654e-03,  9.3785e-05, -1.2303e-03,  ...,  1.6276e-03,\n",
      "         -4.3703e-04, -1.4587e-04],\n",
      "        [ 1.1991e-03,  3.1229e-04, -2.1627e-03,  ...,  1.7968e-03,\n",
      "         -5.9503e-04,  7.0535e-04],\n",
      "        [ 1.1681e-03,  4.9021e-04, -2.7210e-03,  ...,  1.1847e-03,\n",
      "         -1.0169e-03,  1.4766e-03],\n",
      "        ...,\n",
      "        [ 1.5914e-03,  1.2667e-04, -1.6141e-03,  ..., -2.2734e-04,\n",
      "          1.8422e-04, -7.7987e-04],\n",
      "        [ 1.0506e-03,  1.5385e-04, -7.8271e-04,  ..., -2.0780e-04,\n",
      "          2.1121e-05,  5.7369e-04],\n",
      "        [ 1.0510e-03,  4.0217e-04, -2.4727e-03,  ...,  9.1264e-04,\n",
      "         -5.1538e-04,  7.8852e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 2.4911e-04, -9.6133e-04],\n",
      "        [ 2.0789e-04, -3.5831e-04],\n",
      "        [ 8.0758e-04, -3.4932e-04],\n",
      "        [ 7.9222e-04, -4.5321e-04],\n",
      "        [-5.6843e-05, -5.9669e-04],\n",
      "        [ 1.0904e-03, -9.3038e-04],\n",
      "        [ 5.2614e-05, -1.2894e-04],\n",
      "        [ 3.8339e-04, -2.3926e-04]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 7.1267e-04, -8.7901e-04],\n",
      "        [ 2.0200e-04, -4.4911e-04],\n",
      "        [ 1.0450e-03, -5.2655e-04],\n",
      "        [ 8.6641e-04, -4.7898e-04],\n",
      "        [ 4.6329e-05, -1.0580e-03],\n",
      "        [ 1.3421e-03, -1.0038e-03],\n",
      "        [ 1.8073e-04, -3.2452e-04],\n",
      "        [ 2.7720e-04, -4.7515e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0132,  0.0150],\n",
      "        [-0.0134,  0.0152],\n",
      "        [-0.0133,  0.0147],\n",
      "        [-0.0134,  0.0154],\n",
      "        [-0.0132,  0.0154],\n",
      "        [-0.0127,  0.0148],\n",
      "        [-0.0133,  0.0149],\n",
      "        [-0.0125,  0.0149]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0131,  0.0149],\n",
      "        [-0.0134,  0.0152],\n",
      "        [-0.0134,  0.0147],\n",
      "        [-0.0133,  0.0146],\n",
      "        [-0.0130,  0.0152],\n",
      "        [-0.0128,  0.0146],\n",
      "        [-0.0134,  0.0147],\n",
      "        [-0.0127,  0.0148]], device='cuda:0')\n",
      "labels:\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0001, device='cuda:0')\n",
      "euclidean_distance\n",
      "tensor([0.0060, 0.0037, 0.0051, 0.0130, 0.0133, 0.0138, 0.0093, 0.0172],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0060],\n",
      "        [0.0037],\n",
      "        [0.0051],\n",
      "        [0.0130],\n",
      "        [0.0133],\n",
      "        [0.0138],\n",
      "        [0.0093],\n",
      "        [0.0172]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 1.1654e-03,  9.3785e-05, -1.2303e-03,  ...,  1.6276e-03,\n",
      "         -4.3703e-04, -1.4587e-04],\n",
      "        [ 1.1991e-03,  3.1229e-04, -2.1627e-03,  ...,  1.7968e-03,\n",
      "         -5.9503e-04,  7.0535e-04],\n",
      "        [ 1.1681e-03,  4.9021e-04, -2.7210e-03,  ...,  1.1847e-03,\n",
      "         -1.0169e-03,  1.4766e-03],\n",
      "        ...,\n",
      "        [ 1.5914e-03,  1.2667e-04, -1.6141e-03,  ..., -2.2734e-04,\n",
      "          1.8422e-04, -7.7987e-04],\n",
      "        [ 1.0506e-03,  1.5385e-04, -7.8271e-04,  ..., -2.0780e-04,\n",
      "          2.1121e-05,  5.7369e-04],\n",
      "        [ 1.0510e-03,  4.0217e-04, -2.4727e-03,  ...,  9.1264e-04,\n",
      "         -5.1538e-04,  7.8852e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 2.4911e-04, -9.6133e-04],\n",
      "        [ 2.0789e-04, -3.5831e-04],\n",
      "        [ 8.0758e-04, -3.4932e-04],\n",
      "        [ 7.9222e-04, -4.5321e-04],\n",
      "        [-5.6843e-05, -5.9669e-04],\n",
      "        [ 1.0904e-03, -9.3038e-04],\n",
      "        [ 5.2614e-05, -1.2894e-04],\n",
      "        [ 3.8339e-04, -2.3926e-04]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 7.1267e-04, -8.7901e-04],\n",
      "        [ 2.0200e-04, -4.4911e-04],\n",
      "        [ 1.0450e-03, -5.2655e-04],\n",
      "        [ 8.6641e-04, -4.7898e-04],\n",
      "        [ 4.6329e-05, -1.0580e-03],\n",
      "        [ 1.3421e-03, -1.0038e-03],\n",
      "        [ 1.8073e-04, -3.2452e-04],\n",
      "        [ 2.7720e-04, -4.7515e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0132,  0.0150],\n",
      "        [-0.0134,  0.0152],\n",
      "        [-0.0133,  0.0147],\n",
      "        [-0.0134,  0.0154],\n",
      "        [-0.0132,  0.0154],\n",
      "        [-0.0127,  0.0148],\n",
      "        [-0.0133,  0.0149],\n",
      "        [-0.0125,  0.0149]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0131,  0.0149],\n",
      "        [-0.0134,  0.0152],\n",
      "        [-0.0134,  0.0147],\n",
      "        [-0.0133,  0.0146],\n",
      "        [-0.0130,  0.0152],\n",
      "        [-0.0128,  0.0146],\n",
      "        [-0.0134,  0.0147],\n",
      "        [-0.0127,  0.0148]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 2.4911389e-04 -9.6133247e-04]\n",
      " [ 2.0789358e-04 -3.5830712e-04]\n",
      " [ 8.0757617e-04 -3.4932393e-04]\n",
      " [ 7.9221791e-04 -4.5321154e-04]\n",
      " [-5.6843273e-05 -5.9668743e-04]\n",
      " [ 1.0903523e-03 -9.3037920e-04]\n",
      " [ 5.2614254e-05 -1.2893748e-04]\n",
      " [ 3.8338749e-04 -2.3925729e-04]]\n",
      "[1 1 1 1 1 1 1 0]\n",
      "[1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean_distance\n",
      "tensor([0.0051, 0.0140, 0.0129, 0.0072, 0.0114, 0.0127, 0.0065, 0.0069],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0051],\n",
      "        [0.0140],\n",
      "        [0.0129],\n",
      "        [0.0072],\n",
      "        [0.0114],\n",
      "        [0.0127],\n",
      "        [0.0065],\n",
      "        [0.0069]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 7.1768e-04, -4.0891e-04, -1.6945e-03,  ..., -7.0332e-04,\n",
      "          3.0284e-04,  1.1917e-03],\n",
      "        [ 7.2133e-04,  4.5462e-05, -3.2900e-03,  ..., -4.9348e-04,\n",
      "         -5.7398e-04,  5.7042e-04],\n",
      "        [ 1.1774e-03, -7.4175e-05, -3.0757e-04,  ...,  1.8822e-03,\n",
      "          7.9359e-04, -3.8958e-04],\n",
      "        ...,\n",
      "        [ 1.5146e-03, -1.7472e-04, -6.1549e-04,  ...,  1.4303e-03,\n",
      "          9.2239e-04, -3.9332e-04],\n",
      "        [ 7.7368e-04, -3.4967e-04, -1.1897e-03,  ...,  1.6495e-03,\n",
      "          7.7228e-04, -2.2195e-05],\n",
      "        [ 7.2671e-04,  1.7031e-04, -7.3097e-04,  ...,  6.5916e-04,\n",
      "          4.6280e-04, -7.8032e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 5.3710e-04, -5.2954e-04],\n",
      "        [ 1.0711e-03, -1.3052e-03],\n",
      "        [ 4.6159e-04, -7.6476e-04],\n",
      "        [ 1.3341e-03, -3.3962e-04],\n",
      "        [ 1.5631e-03, -1.0792e-03],\n",
      "        [ 4.6940e-04, -2.9537e-04],\n",
      "        [ 1.2043e-03, -5.6986e-04],\n",
      "        [-7.1048e-05, -5.4264e-04]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 7.8456e-04, -7.3633e-04],\n",
      "        [ 1.1340e-03, -1.2267e-03],\n",
      "        [ 2.1530e-04, -6.6060e-04],\n",
      "        [ 1.6277e-03, -5.7892e-04],\n",
      "        [ 1.3830e-03, -6.7762e-04],\n",
      "        [ 2.3206e-04, -5.9088e-05],\n",
      "        [ 9.7610e-04, -3.6471e-04],\n",
      "        [-7.5054e-06, -6.5301e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0131,  0.0147],\n",
      "        [-0.0128,  0.0147],\n",
      "        [-0.0125,  0.0147],\n",
      "        [-0.0131,  0.0142],\n",
      "        [-0.0128,  0.0143],\n",
      "        [-0.0129,  0.0148],\n",
      "        [-0.0125,  0.0145],\n",
      "        [-0.0128,  0.0152]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0131,  0.0146],\n",
      "        [-0.0130,  0.0145],\n",
      "        [-0.0124,  0.0148],\n",
      "        [-0.0130,  0.0141],\n",
      "        [-0.0129,  0.0143],\n",
      "        [-0.0128,  0.0150],\n",
      "        [-0.0125,  0.0146],\n",
      "        [-0.0128,  0.0150]], device='cuda:0')\n",
      "labels:\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0001, device='cuda:0')\n",
      "euclidean_distance\n",
      "tensor([0.0051, 0.0140, 0.0129, 0.0072, 0.0114, 0.0127, 0.0065, 0.0069],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0051],\n",
      "        [0.0140],\n",
      "        [0.0129],\n",
      "        [0.0072],\n",
      "        [0.0114],\n",
      "        [0.0127],\n",
      "        [0.0065],\n",
      "        [0.0069]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 7.1768e-04, -4.0891e-04, -1.6945e-03,  ..., -7.0332e-04,\n",
      "          3.0284e-04,  1.1917e-03],\n",
      "        [ 7.2133e-04,  4.5462e-05, -3.2900e-03,  ..., -4.9348e-04,\n",
      "         -5.7398e-04,  5.7042e-04],\n",
      "        [ 1.1774e-03, -7.4175e-05, -3.0757e-04,  ...,  1.8822e-03,\n",
      "          7.9359e-04, -3.8958e-04],\n",
      "        ...,\n",
      "        [ 1.5146e-03, -1.7472e-04, -6.1549e-04,  ...,  1.4303e-03,\n",
      "          9.2239e-04, -3.9332e-04],\n",
      "        [ 7.7368e-04, -3.4967e-04, -1.1897e-03,  ...,  1.6495e-03,\n",
      "          7.7228e-04, -2.2195e-05],\n",
      "        [ 7.2671e-04,  1.7031e-04, -7.3097e-04,  ...,  6.5916e-04,\n",
      "          4.6280e-04, -7.8032e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 5.3710e-04, -5.2954e-04],\n",
      "        [ 1.0711e-03, -1.3052e-03],\n",
      "        [ 4.6159e-04, -7.6476e-04],\n",
      "        [ 1.3341e-03, -3.3962e-04],\n",
      "        [ 1.5631e-03, -1.0792e-03],\n",
      "        [ 4.6940e-04, -2.9537e-04],\n",
      "        [ 1.2043e-03, -5.6986e-04],\n",
      "        [-7.1048e-05, -5.4264e-04]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 7.8456e-04, -7.3633e-04],\n",
      "        [ 1.1340e-03, -1.2267e-03],\n",
      "        [ 2.1530e-04, -6.6060e-04],\n",
      "        [ 1.6277e-03, -5.7892e-04],\n",
      "        [ 1.3830e-03, -6.7762e-04],\n",
      "        [ 2.3206e-04, -5.9088e-05],\n",
      "        [ 9.7610e-04, -3.6471e-04],\n",
      "        [-7.5054e-06, -6.5301e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0131,  0.0147],\n",
      "        [-0.0128,  0.0147],\n",
      "        [-0.0125,  0.0147],\n",
      "        [-0.0131,  0.0142],\n",
      "        [-0.0128,  0.0143],\n",
      "        [-0.0129,  0.0148],\n",
      "        [-0.0125,  0.0145],\n",
      "        [-0.0128,  0.0152]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0131,  0.0146],\n",
      "        [-0.0130,  0.0145],\n",
      "        [-0.0124,  0.0148],\n",
      "        [-0.0130,  0.0141],\n",
      "        [-0.0129,  0.0143],\n",
      "        [-0.0128,  0.0150],\n",
      "        [-0.0125,  0.0146],\n",
      "        [-0.0128,  0.0150]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 5.3710246e-04 -5.2953721e-04]\n",
      " [ 1.0710633e-03 -1.3051584e-03]\n",
      " [ 4.6159039e-04 -7.6475920e-04]\n",
      " [ 1.3341432e-03 -3.3961728e-04]\n",
      " [ 1.5630976e-03 -1.0792378e-03]\n",
      " [ 4.6940445e-04 -2.9536599e-04]\n",
      " [ 1.2042645e-03 -5.6986086e-04]\n",
      " [-7.1048446e-05 -5.4264080e-04]]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "euclidean_distance\n",
      "tensor([0.0074, 0.0107, 0.0055, 0.0125, 0.0226, 0.0138, 0.0063, 0.0083],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0074],\n",
      "        [0.0107],\n",
      "        [0.0055],\n",
      "        [0.0125],\n",
      "        [0.0226],\n",
      "        [0.0138],\n",
      "        [0.0063],\n",
      "        [0.0083]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 0.0007, -0.0001, -0.0013,  ..., -0.0006,  0.0005,  0.0001],\n",
      "        [ 0.0008,  0.0006, -0.0017,  ...,  0.0011,  0.0005, -0.0008],\n",
      "        [ 0.0013, -0.0001, -0.0012,  ...,  0.0006,  0.0003, -0.0002],\n",
      "        ...,\n",
      "        [ 0.0004, -0.0012, -0.0005,  ...,  0.0006, -0.0006, -0.0010],\n",
      "        [ 0.0014,  0.0005, -0.0033,  ..., -0.0007,  0.0005, -0.0006],\n",
      "        [ 0.0008, -0.0007, -0.0015,  ..., -0.0007, -0.0016, -0.0022]],\n",
      "       device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0007, -0.0007],\n",
      "        [ 0.0005, -0.0008],\n",
      "        [ 0.0001, -0.0004],\n",
      "        [ 0.0005, -0.0018],\n",
      "        [ 0.0008, -0.0022],\n",
      "        [ 0.0004, -0.0023],\n",
      "        [ 0.0004, -0.0011],\n",
      "        [ 0.0002, -0.0014]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 0.0007, -0.0009],\n",
      "        [ 0.0005, -0.0010],\n",
      "        [ 0.0003, -0.0006],\n",
      "        [ 0.0006, -0.0016],\n",
      "        [ 0.0008, -0.0022],\n",
      "        [ 0.0006, -0.0022],\n",
      "        [ 0.0006, -0.0012],\n",
      "        [ 0.0004, -0.0015]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0127,  0.0153],\n",
      "        [-0.0126,  0.0149],\n",
      "        [-0.0128,  0.0151],\n",
      "        [-0.0122,  0.0136],\n",
      "        [-0.0119,  0.0136],\n",
      "        [-0.0123,  0.0137],\n",
      "        [-0.0125,  0.0134],\n",
      "        [-0.0124,  0.0142]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0126,  0.0151],\n",
      "        [-0.0125,  0.0149],\n",
      "        [-0.0128,  0.0151],\n",
      "        [-0.0122,  0.0137],\n",
      "        [-0.0123,  0.0132],\n",
      "        [-0.0123,  0.0135],\n",
      "        [-0.0126,  0.0134],\n",
      "        [-0.0124,  0.0141]], device='cuda:0')\n",
      "labels:\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0001, device='cuda:0')\n",
      "euclidean_distance\n",
      "tensor([0.0074, 0.0107, 0.0055, 0.0125, 0.0226, 0.0138, 0.0063, 0.0083],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0074],\n",
      "        [0.0107],\n",
      "        [0.0055],\n",
      "        [0.0125],\n",
      "        [0.0226],\n",
      "        [0.0138],\n",
      "        [0.0063],\n",
      "        [0.0083]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 0.0007, -0.0001, -0.0013,  ..., -0.0006,  0.0005,  0.0001],\n",
      "        [ 0.0008,  0.0006, -0.0017,  ...,  0.0011,  0.0005, -0.0008],\n",
      "        [ 0.0013, -0.0001, -0.0012,  ...,  0.0006,  0.0003, -0.0002],\n",
      "        ...,\n",
      "        [ 0.0004, -0.0012, -0.0005,  ...,  0.0006, -0.0006, -0.0010],\n",
      "        [ 0.0014,  0.0005, -0.0033,  ..., -0.0007,  0.0005, -0.0006],\n",
      "        [ 0.0008, -0.0007, -0.0015,  ..., -0.0007, -0.0016, -0.0022]],\n",
      "       device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0007, -0.0007],\n",
      "        [ 0.0005, -0.0008],\n",
      "        [ 0.0001, -0.0004],\n",
      "        [ 0.0005, -0.0018],\n",
      "        [ 0.0008, -0.0022],\n",
      "        [ 0.0004, -0.0023],\n",
      "        [ 0.0004, -0.0011],\n",
      "        [ 0.0002, -0.0014]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 0.0007, -0.0009],\n",
      "        [ 0.0005, -0.0010],\n",
      "        [ 0.0003, -0.0006],\n",
      "        [ 0.0006, -0.0016],\n",
      "        [ 0.0008, -0.0022],\n",
      "        [ 0.0006, -0.0022],\n",
      "        [ 0.0006, -0.0012],\n",
      "        [ 0.0004, -0.0015]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0127,  0.0153],\n",
      "        [-0.0126,  0.0149],\n",
      "        [-0.0128,  0.0151],\n",
      "        [-0.0122,  0.0136],\n",
      "        [-0.0119,  0.0136],\n",
      "        [-0.0123,  0.0137],\n",
      "        [-0.0125,  0.0134],\n",
      "        [-0.0124,  0.0142]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0126,  0.0151],\n",
      "        [-0.0125,  0.0149],\n",
      "        [-0.0128,  0.0151],\n",
      "        [-0.0122,  0.0137],\n",
      "        [-0.0123,  0.0132],\n",
      "        [-0.0123,  0.0135],\n",
      "        [-0.0126,  0.0134],\n",
      "        [-0.0124,  0.0141]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 0.00065597 -0.00065845]\n",
      " [ 0.00049527 -0.0007836 ]\n",
      " [ 0.00012587 -0.00042627]\n",
      " [ 0.00049477 -0.0018307 ]\n",
      " [ 0.00084164 -0.00219228]\n",
      " [ 0.00042876 -0.00233627]\n",
      " [ 0.00043065 -0.00108037]\n",
      " [ 0.00021197 -0.00140314]]\n",
      "[0 0 0 1 1 1 0 0]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "euclidean_distance\n",
      "tensor([0.0086, 0.0058, 0.0091, 0.0069, 0.0164, 0.0095, 0.0147, 0.0125],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0086],\n",
      "        [0.0058],\n",
      "        [0.0091],\n",
      "        [0.0069],\n",
      "        [0.0164],\n",
      "        [0.0095],\n",
      "        [0.0147],\n",
      "        [0.0125]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 8.9041e-04,  8.4948e-04, -4.7816e-03,  ..., -1.3333e-03,\n",
      "         -2.1557e-04,  4.6226e-04],\n",
      "        [ 1.2044e-03, -7.8433e-05, -2.9014e-03,  ..., -1.0839e-03,\n",
      "         -9.0145e-04, -1.0702e-03],\n",
      "        [ 1.1482e-03, -5.6381e-04, -2.6177e-03,  ..., -1.3634e-03,\n",
      "         -9.1461e-04, -7.1906e-04],\n",
      "        ...,\n",
      "        [ 1.4499e-03, -3.6990e-04, -2.5077e-03,  ...,  5.4284e-04,\n",
      "         -3.2875e-04, -9.5164e-04],\n",
      "        [ 5.8633e-04,  8.6518e-05, -1.1789e-03,  ...,  6.7630e-04,\n",
      "         -1.5287e-04, -9.7672e-04],\n",
      "        [ 1.1552e-04,  7.4067e-04, -4.4651e-03,  ..., -1.6391e-03,\n",
      "          7.9164e-04, -2.8471e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 4.3363e-04, -5.7734e-04],\n",
      "        [-2.2336e-04, -9.8287e-04],\n",
      "        [ 4.0188e-05, -1.3104e-03],\n",
      "        [ 4.6307e-04, -1.0220e-03],\n",
      "        [ 3.6538e-04, -1.3066e-03],\n",
      "        [-7.3616e-04, -1.1216e-03],\n",
      "        [ 1.0348e-03, -1.5206e-03],\n",
      "        [ 8.3191e-04, -1.2702e-03]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 7.1416e-05, -1.6533e-04],\n",
      "        [-1.6906e-05, -1.2682e-03],\n",
      "        [ 2.8438e-04, -1.5686e-03],\n",
      "        [ 5.7673e-04, -1.0384e-03],\n",
      "        [ 4.2894e-04, -1.4994e-03],\n",
      "        [-6.8519e-04, -9.7926e-04],\n",
      "        [ 1.5086e-03, -1.4383e-03],\n",
      "        [ 6.8741e-04, -1.3974e-03]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0129,  0.0133],\n",
      "        [-0.0123,  0.0138],\n",
      "        [-0.0128,  0.0140],\n",
      "        [-0.0131,  0.0136],\n",
      "        [-0.0116,  0.0137],\n",
      "        [-0.0116,  0.0136],\n",
      "        [-0.0123,  0.0129],\n",
      "        [-0.0126,  0.0136]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0132,  0.0133],\n",
      "        [-0.0123,  0.0140],\n",
      "        [-0.0128,  0.0141],\n",
      "        [-0.0130,  0.0138],\n",
      "        [-0.0116,  0.0137],\n",
      "        [-0.0117,  0.0132],\n",
      "        [-0.0124,  0.0131],\n",
      "        [-0.0125,  0.0137]], device='cuda:0')\n",
      "labels:\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0001, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean_distance\n",
      "tensor([0.0086, 0.0058, 0.0091, 0.0069, 0.0164, 0.0095, 0.0147, 0.0125],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0086],\n",
      "        [0.0058],\n",
      "        [0.0091],\n",
      "        [0.0069],\n",
      "        [0.0164],\n",
      "        [0.0095],\n",
      "        [0.0147],\n",
      "        [0.0125]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 8.9041e-04,  8.4948e-04, -4.7816e-03,  ..., -1.3333e-03,\n",
      "         -2.1557e-04,  4.6226e-04],\n",
      "        [ 1.2044e-03, -7.8433e-05, -2.9014e-03,  ..., -1.0839e-03,\n",
      "         -9.0145e-04, -1.0702e-03],\n",
      "        [ 1.1482e-03, -5.6381e-04, -2.6177e-03,  ..., -1.3634e-03,\n",
      "         -9.1461e-04, -7.1906e-04],\n",
      "        ...,\n",
      "        [ 1.4499e-03, -3.6990e-04, -2.5077e-03,  ...,  5.4284e-04,\n",
      "         -3.2875e-04, -9.5164e-04],\n",
      "        [ 5.8633e-04,  8.6518e-05, -1.1789e-03,  ...,  6.7630e-04,\n",
      "         -1.5287e-04, -9.7672e-04],\n",
      "        [ 1.1552e-04,  7.4067e-04, -4.4651e-03,  ..., -1.6391e-03,\n",
      "          7.9164e-04, -2.8471e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 4.3363e-04, -5.7734e-04],\n",
      "        [-2.2336e-04, -9.8287e-04],\n",
      "        [ 4.0188e-05, -1.3104e-03],\n",
      "        [ 4.6307e-04, -1.0220e-03],\n",
      "        [ 3.6538e-04, -1.3066e-03],\n",
      "        [-7.3616e-04, -1.1216e-03],\n",
      "        [ 1.0348e-03, -1.5206e-03],\n",
      "        [ 8.3191e-04, -1.2702e-03]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 7.1416e-05, -1.6533e-04],\n",
      "        [-1.6906e-05, -1.2682e-03],\n",
      "        [ 2.8438e-04, -1.5686e-03],\n",
      "        [ 5.7673e-04, -1.0384e-03],\n",
      "        [ 4.2894e-04, -1.4994e-03],\n",
      "        [-6.8519e-04, -9.7926e-04],\n",
      "        [ 1.5086e-03, -1.4383e-03],\n",
      "        [ 6.8741e-04, -1.3974e-03]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0129,  0.0133],\n",
      "        [-0.0123,  0.0138],\n",
      "        [-0.0128,  0.0140],\n",
      "        [-0.0131,  0.0136],\n",
      "        [-0.0116,  0.0137],\n",
      "        [-0.0116,  0.0136],\n",
      "        [-0.0123,  0.0129],\n",
      "        [-0.0126,  0.0136]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0132,  0.0133],\n",
      "        [-0.0123,  0.0140],\n",
      "        [-0.0128,  0.0141],\n",
      "        [-0.0130,  0.0138],\n",
      "        [-0.0116,  0.0137],\n",
      "        [-0.0117,  0.0132],\n",
      "        [-0.0124,  0.0131],\n",
      "        [-0.0125,  0.0137]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 4.3362600e-04 -5.7734473e-04]\n",
      " [-2.2335502e-04 -9.8286686e-04]\n",
      " [ 4.0188024e-05 -1.3103831e-03]\n",
      " [ 4.6307046e-04 -1.0219763e-03]\n",
      " [ 3.6537566e-04 -1.3065911e-03]\n",
      " [-7.3616090e-04 -1.1216484e-03]\n",
      " [ 1.0347709e-03 -1.5206460e-03]\n",
      " [ 8.3190523e-04 -1.2701640e-03]]\n",
      "[0 1 1 1 1 1 1 0]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "euclidean_distance\n",
      "tensor([0.0060, 0.0081, 0.0138, 0.0114, 0.0153, 0.0050, 0.0163, 0.0088],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0060],\n",
      "        [0.0081],\n",
      "        [0.0138],\n",
      "        [0.0114],\n",
      "        [0.0153],\n",
      "        [0.0050],\n",
      "        [0.0163],\n",
      "        [0.0088]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[-5.1742e-04, -5.5601e-04, -2.8726e-03,  ..., -1.3775e-03,\n",
      "          4.9503e-04,  2.5697e-03],\n",
      "        [ 6.4410e-04, -7.8844e-04, -1.8283e-03,  ..., -1.2771e-04,\n",
      "         -6.8264e-04,  6.8117e-04],\n",
      "        [ 2.4680e-04,  2.7596e-04, -2.8210e-03,  ...,  5.7664e-04,\n",
      "         -1.9188e-03,  1.1223e-03],\n",
      "        ...,\n",
      "        [ 2.6132e-04, -1.3997e-04, -1.0855e-03,  ...,  2.2718e-03,\n",
      "         -6.6019e-04,  5.4095e-04],\n",
      "        [-9.6399e-05, -1.5933e-03, -2.0653e-03,  ...,  5.7646e-04,\n",
      "         -7.3496e-04,  1.6188e-03],\n",
      "        [ 6.8062e-04, -5.6194e-04, -2.9254e-03,  ...,  5.8861e-05,\n",
      "         -9.5803e-04, -2.1901e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 4.1519e-04, -9.9802e-04],\n",
      "        [ 2.5073e-04,  1.0645e-04],\n",
      "        [ 9.6722e-04, -2.9763e-04],\n",
      "        [ 1.5881e-03, -7.6291e-04],\n",
      "        [ 1.1608e-03,  7.4688e-05],\n",
      "        [ 4.9368e-04, -1.9115e-04],\n",
      "        [ 6.5877e-04,  8.0209e-05],\n",
      "        [ 7.6098e-05, -2.1676e-04]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 4.4466e-04, -7.4925e-04],\n",
      "        [ 6.5178e-04, -1.8464e-04],\n",
      "        [ 1.0606e-03, -2.7912e-04],\n",
      "        [ 1.5935e-03, -6.9572e-04],\n",
      "        [ 9.2099e-04, -4.4806e-04],\n",
      "        [ 6.1509e-04, -3.8045e-04],\n",
      "        [ 1.9921e-04,  4.1993e-05],\n",
      "        [ 2.8372e-04, -3.4817e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0131,  0.0136],\n",
      "        [-0.0133,  0.0140],\n",
      "        [-0.0134,  0.0134],\n",
      "        [-0.0129,  0.0140],\n",
      "        [-0.0130,  0.0139],\n",
      "        [-0.0137,  0.0143],\n",
      "        [-0.0137,  0.0139],\n",
      "        [-0.0132,  0.0144]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0130,  0.0133],\n",
      "        [-0.0131,  0.0139],\n",
      "        [-0.0135,  0.0137],\n",
      "        [-0.0129,  0.0138],\n",
      "        [-0.0127,  0.0142],\n",
      "        [-0.0137,  0.0143],\n",
      "        [-0.0133,  0.0142],\n",
      "        [-0.0131,  0.0143]], device='cuda:0')\n",
      "labels:\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0001, device='cuda:0')\n",
      "euclidean_distance\n",
      "tensor([0.0060, 0.0081, 0.0138, 0.0114, 0.0153, 0.0050, 0.0163, 0.0088],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0060],\n",
      "        [0.0081],\n",
      "        [0.0138],\n",
      "        [0.0114],\n",
      "        [0.0153],\n",
      "        [0.0050],\n",
      "        [0.0163],\n",
      "        [0.0088]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[-5.1742e-04, -5.5601e-04, -2.8726e-03,  ..., -1.3775e-03,\n",
      "          4.9503e-04,  2.5697e-03],\n",
      "        [ 6.4410e-04, -7.8844e-04, -1.8283e-03,  ..., -1.2771e-04,\n",
      "         -6.8264e-04,  6.8117e-04],\n",
      "        [ 2.4680e-04,  2.7596e-04, -2.8210e-03,  ...,  5.7664e-04,\n",
      "         -1.9188e-03,  1.1223e-03],\n",
      "        ...,\n",
      "        [ 2.6132e-04, -1.3997e-04, -1.0855e-03,  ...,  2.2718e-03,\n",
      "         -6.6019e-04,  5.4095e-04],\n",
      "        [-9.6399e-05, -1.5933e-03, -2.0653e-03,  ...,  5.7646e-04,\n",
      "         -7.3496e-04,  1.6188e-03],\n",
      "        [ 6.8062e-04, -5.6194e-04, -2.9254e-03,  ...,  5.8861e-05,\n",
      "         -9.5803e-04, -2.1901e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 4.1519e-04, -9.9802e-04],\n",
      "        [ 2.5073e-04,  1.0645e-04],\n",
      "        [ 9.6722e-04, -2.9763e-04],\n",
      "        [ 1.5881e-03, -7.6291e-04],\n",
      "        [ 1.1608e-03,  7.4688e-05],\n",
      "        [ 4.9368e-04, -1.9115e-04],\n",
      "        [ 6.5877e-04,  8.0209e-05],\n",
      "        [ 7.6098e-05, -2.1676e-04]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 4.4466e-04, -7.4925e-04],\n",
      "        [ 6.5178e-04, -1.8464e-04],\n",
      "        [ 1.0606e-03, -2.7912e-04],\n",
      "        [ 1.5935e-03, -6.9572e-04],\n",
      "        [ 9.2099e-04, -4.4806e-04],\n",
      "        [ 6.1509e-04, -3.8045e-04],\n",
      "        [ 1.9921e-04,  4.1993e-05],\n",
      "        [ 2.8372e-04, -3.4817e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0131,  0.0136],\n",
      "        [-0.0133,  0.0140],\n",
      "        [-0.0134,  0.0134],\n",
      "        [-0.0129,  0.0140],\n",
      "        [-0.0130,  0.0139],\n",
      "        [-0.0137,  0.0143],\n",
      "        [-0.0137,  0.0139],\n",
      "        [-0.0132,  0.0144]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0130,  0.0133],\n",
      "        [-0.0131,  0.0139],\n",
      "        [-0.0135,  0.0137],\n",
      "        [-0.0129,  0.0138],\n",
      "        [-0.0127,  0.0142],\n",
      "        [-0.0137,  0.0143],\n",
      "        [-0.0133,  0.0142],\n",
      "        [-0.0131,  0.0143]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 4.1518785e-04 -9.9802122e-04]\n",
      " [ 2.5073235e-04  1.0644790e-04]\n",
      " [ 9.6722465e-04 -2.9763044e-04]\n",
      " [ 1.5880698e-03 -7.6290680e-04]\n",
      " [ 1.1608186e-03  7.4688345e-05]\n",
      " [ 4.9368071e-04 -1.9115282e-04]\n",
      " [ 6.5876939e-04  8.0209458e-05]\n",
      " [ 7.6098077e-05 -2.1676047e-04]]\n",
      "[1 1 1 1 1 0 0 0]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "euclidean_distance\n",
      "tensor([0.0133, 0.0140, 0.0108, 0.0076, 0.0063, 0.0056, 0.0146, 0.0067],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0133],\n",
      "        [0.0140],\n",
      "        [0.0108],\n",
      "        [0.0076],\n",
      "        [0.0063],\n",
      "        [0.0056],\n",
      "        [0.0146],\n",
      "        [0.0067]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 2.0480e-04,  4.5394e-04, -2.4364e-03,  ...,  2.2444e-03,\n",
      "         -1.4753e-03,  3.3780e-04],\n",
      "        [ 1.4929e-04,  2.4381e-04, -2.4704e-03,  ...,  2.2754e-03,\n",
      "         -1.7895e-03,  3.6076e-04],\n",
      "        [ 5.7497e-04, -2.2559e-05, -2.0115e-03,  ...,  2.4369e-03,\n",
      "         -1.3690e-03,  4.2496e-04],\n",
      "        ...,\n",
      "        [ 3.9373e-04, -1.0239e-03, -9.8212e-04,  ...,  9.5395e-04,\n",
      "         -2.3491e-04,  1.8513e-03],\n",
      "        [ 7.0080e-04, -2.9298e-04, -1.8089e-03,  ...,  4.3977e-04,\n",
      "         -1.0266e-03,  1.7340e-04],\n",
      "        [ 4.7333e-04, -8.0946e-04, -1.7320e-03,  ..., -5.7395e-05,\n",
      "         -8.6447e-04,  1.4359e-03]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 8.2061e-04, -5.3461e-04],\n",
      "        [ 8.6478e-04, -2.2570e-04],\n",
      "        [ 9.8499e-04, -3.9596e-04],\n",
      "        [-2.5913e-04, -4.0064e-04],\n",
      "        [ 2.0457e-04, -5.8681e-04],\n",
      "        [ 9.7862e-04, -3.1723e-04],\n",
      "        [ 8.0166e-04, -4.1428e-05],\n",
      "        [ 5.7048e-04, -4.5005e-04]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 1.0220e-03, -1.0924e-03],\n",
      "        [ 1.3248e-03, -9.2754e-04],\n",
      "        [ 1.0505e-03, -6.3034e-04],\n",
      "        [ 9.0796e-05, -6.7141e-04],\n",
      "        [ 1.5198e-04, -4.0719e-04],\n",
      "        [ 1.1947e-03, -6.8072e-04],\n",
      "        [ 1.0390e-03, -6.2284e-04],\n",
      "        [ 1.0016e-03, -7.6228e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0135,  0.0132],\n",
      "        [-0.0133,  0.0139],\n",
      "        [-0.0130,  0.0142],\n",
      "        [-0.0137,  0.0140],\n",
      "        [-0.0131,  0.0137],\n",
      "        [-0.0133,  0.0139],\n",
      "        [-0.0138,  0.0134],\n",
      "        [-0.0137,  0.0139]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0132,  0.0136],\n",
      "        [-0.0130,  0.0141],\n",
      "        [-0.0132,  0.0140],\n",
      "        [-0.0136,  0.0139],\n",
      "        [-0.0130,  0.0138],\n",
      "        [-0.0133,  0.0139],\n",
      "        [-0.0136,  0.0133],\n",
      "        [-0.0136,  0.0139]], device='cuda:0')\n",
      "labels:\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0001, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean_distance\n",
      "tensor([0.0133, 0.0140, 0.0108, 0.0076, 0.0063, 0.0056, 0.0146, 0.0067],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0133],\n",
      "        [0.0140],\n",
      "        [0.0108],\n",
      "        [0.0076],\n",
      "        [0.0063],\n",
      "        [0.0056],\n",
      "        [0.0146],\n",
      "        [0.0067]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 2.0480e-04,  4.5394e-04, -2.4364e-03,  ...,  2.2444e-03,\n",
      "         -1.4753e-03,  3.3780e-04],\n",
      "        [ 1.4929e-04,  2.4381e-04, -2.4704e-03,  ...,  2.2754e-03,\n",
      "         -1.7895e-03,  3.6076e-04],\n",
      "        [ 5.7497e-04, -2.2559e-05, -2.0115e-03,  ...,  2.4369e-03,\n",
      "         -1.3690e-03,  4.2496e-04],\n",
      "        ...,\n",
      "        [ 3.9373e-04, -1.0239e-03, -9.8212e-04,  ...,  9.5395e-04,\n",
      "         -2.3491e-04,  1.8513e-03],\n",
      "        [ 7.0080e-04, -2.9298e-04, -1.8089e-03,  ...,  4.3977e-04,\n",
      "         -1.0266e-03,  1.7340e-04],\n",
      "        [ 4.7333e-04, -8.0946e-04, -1.7320e-03,  ..., -5.7395e-05,\n",
      "         -8.6447e-04,  1.4359e-03]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 8.2061e-04, -5.3461e-04],\n",
      "        [ 8.6478e-04, -2.2570e-04],\n",
      "        [ 9.8499e-04, -3.9596e-04],\n",
      "        [-2.5913e-04, -4.0064e-04],\n",
      "        [ 2.0457e-04, -5.8681e-04],\n",
      "        [ 9.7862e-04, -3.1723e-04],\n",
      "        [ 8.0166e-04, -4.1428e-05],\n",
      "        [ 5.7048e-04, -4.5005e-04]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 1.0220e-03, -1.0924e-03],\n",
      "        [ 1.3248e-03, -9.2754e-04],\n",
      "        [ 1.0505e-03, -6.3034e-04],\n",
      "        [ 9.0796e-05, -6.7141e-04],\n",
      "        [ 1.5198e-04, -4.0719e-04],\n",
      "        [ 1.1947e-03, -6.8072e-04],\n",
      "        [ 1.0390e-03, -6.2284e-04],\n",
      "        [ 1.0016e-03, -7.6228e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0135,  0.0132],\n",
      "        [-0.0133,  0.0139],\n",
      "        [-0.0130,  0.0142],\n",
      "        [-0.0137,  0.0140],\n",
      "        [-0.0131,  0.0137],\n",
      "        [-0.0133,  0.0139],\n",
      "        [-0.0138,  0.0134],\n",
      "        [-0.0137,  0.0139]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0132,  0.0136],\n",
      "        [-0.0130,  0.0141],\n",
      "        [-0.0132,  0.0140],\n",
      "        [-0.0136,  0.0139],\n",
      "        [-0.0130,  0.0138],\n",
      "        [-0.0133,  0.0139],\n",
      "        [-0.0136,  0.0133],\n",
      "        [-0.0136,  0.0139]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 8.2060689e-04 -5.3461239e-04]\n",
      " [ 8.6478307e-04 -2.2570431e-04]\n",
      " [ 9.8498573e-04 -3.9596268e-04]\n",
      " [-2.5913154e-04 -4.0064214e-04]\n",
      " [ 2.0456611e-04 -5.8681192e-04]\n",
      " [ 9.7862026e-04 -3.1723091e-04]\n",
      " [ 8.0165541e-04 -4.1428255e-05]\n",
      " [ 5.7048036e-04 -4.5005223e-04]]\n",
      "[1 1 1 1 0 1 1 1]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "euclidean_distance\n",
      "tensor([0.0245, 0.0224, 0.0136, 0.0060, 0.0161, 0.0018, 0.0075, 0.0119],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0245],\n",
      "        [0.0224],\n",
      "        [0.0136],\n",
      "        [0.0060],\n",
      "        [0.0161],\n",
      "        [0.0018],\n",
      "        [0.0075],\n",
      "        [0.0119]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 0.0002, -0.0015, -0.0010,  ..., -0.0014,  0.0009, -0.0011],\n",
      "        [ 0.0002, -0.0008, -0.0022,  ..., -0.0023,  0.0020, -0.0009],\n",
      "        [-0.0005, -0.0011, -0.0023,  ..., -0.0018,  0.0027, -0.0004],\n",
      "        ...,\n",
      "        [ 0.0003, -0.0012, -0.0018,  ..., -0.0024,  0.0020,  0.0005],\n",
      "        [-0.0002, -0.0012, -0.0028,  ..., -0.0027,  0.0022, -0.0021],\n",
      "        [-0.0008,  0.0004, -0.0019,  ..., -0.0004,  0.0009, -0.0010]],\n",
      "       device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0027, -0.0023],\n",
      "        [ 0.0034, -0.0022],\n",
      "        [ 0.0037, -0.0022],\n",
      "        [ 0.0024, -0.0018],\n",
      "        [ 0.0027, -0.0021],\n",
      "        [ 0.0032, -0.0025],\n",
      "        [ 0.0028, -0.0022],\n",
      "        [ 0.0006, -0.0004]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 3.2535e-03, -2.4027e-03],\n",
      "        [ 3.4606e-03, -2.5198e-03],\n",
      "        [ 3.2896e-03, -2.1588e-03],\n",
      "        [ 2.2808e-03, -1.7415e-03],\n",
      "        [ 3.1779e-03, -2.4099e-03],\n",
      "        [ 3.1480e-03, -2.5432e-03],\n",
      "        [ 2.9832e-03, -2.4211e-03],\n",
      "        [ 9.6100e-05,  1.1249e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0126,  0.0156],\n",
      "        [-0.0120,  0.0159],\n",
      "        [-0.0122,  0.0153],\n",
      "        [-0.0129,  0.0163],\n",
      "        [-0.0124,  0.0162],\n",
      "        [-0.0122,  0.0143],\n",
      "        [-0.0123,  0.0165],\n",
      "        [-0.0134,  0.0150]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0122,  0.0157],\n",
      "        [-0.0121,  0.0153],\n",
      "        [-0.0122,  0.0147],\n",
      "        [-0.0130,  0.0159],\n",
      "        [-0.0123,  0.0158],\n",
      "        [-0.0122,  0.0144],\n",
      "        [-0.0123,  0.0163],\n",
      "        [-0.0137,  0.0150]], device='cuda:0')\n",
      "labels:\n",
      "tensor([1, 1, 0, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0002, device='cuda:0')\n",
      "euclidean_distance\n",
      "tensor([0.0245, 0.0224, 0.0136, 0.0060, 0.0161, 0.0018, 0.0075, 0.0119],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0245],\n",
      "        [0.0224],\n",
      "        [0.0136],\n",
      "        [0.0060],\n",
      "        [0.0161],\n",
      "        [0.0018],\n",
      "        [0.0075],\n",
      "        [0.0119]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 0.0002, -0.0015, -0.0010,  ..., -0.0014,  0.0009, -0.0011],\n",
      "        [ 0.0002, -0.0008, -0.0022,  ..., -0.0023,  0.0020, -0.0009],\n",
      "        [-0.0005, -0.0011, -0.0023,  ..., -0.0018,  0.0027, -0.0004],\n",
      "        ...,\n",
      "        [ 0.0003, -0.0012, -0.0018,  ..., -0.0024,  0.0020,  0.0005],\n",
      "        [-0.0002, -0.0012, -0.0028,  ..., -0.0027,  0.0022, -0.0021],\n",
      "        [-0.0008,  0.0004, -0.0019,  ..., -0.0004,  0.0009, -0.0010]],\n",
      "       device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0027, -0.0023],\n",
      "        [ 0.0034, -0.0022],\n",
      "        [ 0.0037, -0.0022],\n",
      "        [ 0.0024, -0.0018],\n",
      "        [ 0.0027, -0.0021],\n",
      "        [ 0.0032, -0.0025],\n",
      "        [ 0.0028, -0.0022],\n",
      "        [ 0.0006, -0.0004]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 3.2535e-03, -2.4027e-03],\n",
      "        [ 3.4606e-03, -2.5198e-03],\n",
      "        [ 3.2896e-03, -2.1588e-03],\n",
      "        [ 2.2808e-03, -1.7415e-03],\n",
      "        [ 3.1779e-03, -2.4099e-03],\n",
      "        [ 3.1480e-03, -2.5432e-03],\n",
      "        [ 2.9832e-03, -2.4211e-03],\n",
      "        [ 9.6100e-05,  1.1249e-04]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0126,  0.0156],\n",
      "        [-0.0120,  0.0159],\n",
      "        [-0.0122,  0.0153],\n",
      "        [-0.0129,  0.0163],\n",
      "        [-0.0124,  0.0162],\n",
      "        [-0.0122,  0.0143],\n",
      "        [-0.0123,  0.0165],\n",
      "        [-0.0134,  0.0150]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0122,  0.0157],\n",
      "        [-0.0121,  0.0153],\n",
      "        [-0.0122,  0.0147],\n",
      "        [-0.0130,  0.0159],\n",
      "        [-0.0123,  0.0158],\n",
      "        [-0.0122,  0.0144],\n",
      "        [-0.0123,  0.0163],\n",
      "        [-0.0137,  0.0150]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 0.00271019 -0.00230286]\n",
      " [ 0.00342848 -0.00218644]\n",
      " [ 0.00366642 -0.00215089]\n",
      " [ 0.00238161 -0.0018257 ]\n",
      " [ 0.00270676 -0.00214615]\n",
      " [ 0.00316734 -0.00248772]\n",
      " [ 0.00283631 -0.00221161]\n",
      " [ 0.00055569 -0.00036776]]\n",
      "[1 1 0 1 1 0 1 1]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "euclidean_distance\n",
      "tensor([0.0082, 0.0100, 0.0214, 0.0108, 0.0064, 0.0106, 0.0066, 0.0135],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0082],\n",
      "        [0.0100],\n",
      "        [0.0214],\n",
      "        [0.0108],\n",
      "        [0.0064],\n",
      "        [0.0106],\n",
      "        [0.0066],\n",
      "        [0.0135]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[-8.8317e-04,  2.4674e-04, -2.2672e-03,  ...,  1.2804e-03,\n",
      "          4.6929e-04, -2.8237e-04],\n",
      "        [-7.5220e-04,  6.7763e-04, -1.9872e-03,  ...,  1.3156e-04,\n",
      "          6.3877e-04, -4.7030e-04],\n",
      "        [-6.7000e-04,  7.3464e-04, -1.6366e-03,  ...,  6.3520e-04,\n",
      "          2.0475e-03, -1.9761e-03],\n",
      "        ...,\n",
      "        [ 2.6668e-04,  2.3121e-04, -3.1049e-03,  ..., -1.5907e-03,\n",
      "          9.8499e-04, -1.1862e-03],\n",
      "        [-2.0358e-03,  1.0062e-03, -1.7350e-03,  ...,  2.5597e-05,\n",
      "          9.8528e-04,  3.3607e-04],\n",
      "        [-6.0670e-04, -1.9759e-03, -4.2060e-03,  ..., -3.4759e-03,\n",
      "         -4.7859e-04, -1.9429e-03]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0011, -0.0012],\n",
      "        [ 0.0014, -0.0013],\n",
      "        [ 0.0004, -0.0014],\n",
      "        [ 0.0014, -0.0013],\n",
      "        [ 0.0015, -0.0012],\n",
      "        [ 0.0012, -0.0011],\n",
      "        [ 0.0005, -0.0010],\n",
      "        [ 0.0012, -0.0026]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 0.0008, -0.0009],\n",
      "        [ 0.0012, -0.0010],\n",
      "        [ 0.0004, -0.0016],\n",
      "        [ 0.0014, -0.0015],\n",
      "        [ 0.0015, -0.0012],\n",
      "        [ 0.0013, -0.0012],\n",
      "        [ 0.0005, -0.0010],\n",
      "        [ 0.0008, -0.0024]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0134,  0.0147],\n",
      "        [-0.0137,  0.0153],\n",
      "        [-0.0131,  0.0159],\n",
      "        [-0.0131,  0.0151],\n",
      "        [-0.0132,  0.0149],\n",
      "        [-0.0131,  0.0150],\n",
      "        [-0.0131,  0.0150],\n",
      "        [-0.0131,  0.0156]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0136,  0.0148],\n",
      "        [-0.0138,  0.0153],\n",
      "        [-0.0129,  0.0154],\n",
      "        [-0.0129,  0.0151],\n",
      "        [-0.0131,  0.0150],\n",
      "        [-0.0130,  0.0146],\n",
      "        [-0.0130,  0.0148],\n",
      "        [-0.0133,  0.0159]], device='cuda:0')\n",
      "labels:\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0001, device='cuda:0')\n",
      "euclidean_distance\n",
      "tensor([0.0082, 0.0100, 0.0214, 0.0108, 0.0064, 0.0106, 0.0066, 0.0135],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0082],\n",
      "        [0.0100],\n",
      "        [0.0214],\n",
      "        [0.0108],\n",
      "        [0.0064],\n",
      "        [0.0106],\n",
      "        [0.0066],\n",
      "        [0.0135]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[-8.8317e-04,  2.4674e-04, -2.2672e-03,  ...,  1.2804e-03,\n",
      "          4.6929e-04, -2.8237e-04],\n",
      "        [-7.5220e-04,  6.7763e-04, -1.9872e-03,  ...,  1.3156e-04,\n",
      "          6.3877e-04, -4.7030e-04],\n",
      "        [-6.7000e-04,  7.3464e-04, -1.6366e-03,  ...,  6.3520e-04,\n",
      "          2.0475e-03, -1.9761e-03],\n",
      "        ...,\n",
      "        [ 2.6668e-04,  2.3121e-04, -3.1049e-03,  ..., -1.5907e-03,\n",
      "          9.8499e-04, -1.1862e-03],\n",
      "        [-2.0358e-03,  1.0062e-03, -1.7350e-03,  ...,  2.5597e-05,\n",
      "          9.8528e-04,  3.3607e-04],\n",
      "        [-6.0670e-04, -1.9759e-03, -4.2060e-03,  ..., -3.4759e-03,\n",
      "         -4.7859e-04, -1.9429e-03]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0011, -0.0012],\n",
      "        [ 0.0014, -0.0013],\n",
      "        [ 0.0004, -0.0014],\n",
      "        [ 0.0014, -0.0013],\n",
      "        [ 0.0015, -0.0012],\n",
      "        [ 0.0012, -0.0011],\n",
      "        [ 0.0005, -0.0010],\n",
      "        [ 0.0012, -0.0026]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 0.0008, -0.0009],\n",
      "        [ 0.0012, -0.0010],\n",
      "        [ 0.0004, -0.0016],\n",
      "        [ 0.0014, -0.0015],\n",
      "        [ 0.0015, -0.0012],\n",
      "        [ 0.0013, -0.0012],\n",
      "        [ 0.0005, -0.0010],\n",
      "        [ 0.0008, -0.0024]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0134,  0.0147],\n",
      "        [-0.0137,  0.0153],\n",
      "        [-0.0131,  0.0159],\n",
      "        [-0.0131,  0.0151],\n",
      "        [-0.0132,  0.0149],\n",
      "        [-0.0131,  0.0150],\n",
      "        [-0.0131,  0.0150],\n",
      "        [-0.0131,  0.0156]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0136,  0.0148],\n",
      "        [-0.0138,  0.0153],\n",
      "        [-0.0129,  0.0154],\n",
      "        [-0.0129,  0.0151],\n",
      "        [-0.0131,  0.0150],\n",
      "        [-0.0130,  0.0146],\n",
      "        [-0.0130,  0.0148],\n",
      "        [-0.0133,  0.0159]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 0.00114663 -0.00115451]\n",
      " [ 0.00141074 -0.00125583]\n",
      " [ 0.00037389 -0.00142745]\n",
      " [ 0.00139873 -0.00126298]\n",
      " [ 0.00147395 -0.00117629]\n",
      " [ 0.00123943 -0.00109779]\n",
      " [ 0.00047542 -0.00100978]\n",
      " [ 0.00122581 -0.00255702]]\n",
      "[1 1 1 1 1 1 1 0]\n",
      "[1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean_distance\n",
      "tensor([0.0148, 0.0085, 0.0063, 0.0034, 0.0196, 0.0132, 0.0100, 0.0151],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0148],\n",
      "        [0.0085],\n",
      "        [0.0063],\n",
      "        [0.0034],\n",
      "        [0.0196],\n",
      "        [0.0132],\n",
      "        [0.0100],\n",
      "        [0.0151]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 8.2680e-04, -1.8615e-03, -2.7382e-03,  ..., -1.1483e-03,\n",
      "         -7.0013e-04, -8.7874e-04],\n",
      "        [ 3.9451e-06, -1.4951e-03, -5.2545e-03,  ..., -2.4684e-03,\n",
      "         -5.6932e-04, -1.2071e-03],\n",
      "        [ 3.5977e-04, -1.2160e-03, -5.3498e-03,  ..., -2.2545e-03,\n",
      "         -3.9490e-04, -1.5084e-03],\n",
      "        ...,\n",
      "        [ 1.1132e-03, -1.0965e-03, -4.9549e-03,  ..., -8.2848e-04,\n",
      "         -2.0427e-04, -1.2426e-03],\n",
      "        [ 4.4603e-04, -1.3632e-03, -3.3288e-03,  ..., -6.9938e-04,\n",
      "          4.9725e-04, -1.1517e-03],\n",
      "        [ 3.6735e-04, -1.7926e-03, -3.6559e-03,  ..., -1.7354e-03,\n",
      "         -1.2289e-04, -8.6268e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0020, -0.0026],\n",
      "        [ 0.0015, -0.0023],\n",
      "        [ 0.0017, -0.0020],\n",
      "        [ 0.0008, -0.0024],\n",
      "        [ 0.0021, -0.0024],\n",
      "        [ 0.0023, -0.0030],\n",
      "        [ 0.0024, -0.0023],\n",
      "        [ 0.0022, -0.0025]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 0.0020, -0.0023],\n",
      "        [ 0.0014, -0.0024],\n",
      "        [ 0.0014, -0.0018],\n",
      "        [ 0.0010, -0.0024],\n",
      "        [ 0.0022, -0.0030],\n",
      "        [ 0.0021, -0.0032],\n",
      "        [ 0.0020, -0.0022],\n",
      "        [ 0.0019, -0.0027]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0134,  0.0161],\n",
      "        [-0.0133,  0.0160],\n",
      "        [-0.0133,  0.0161],\n",
      "        [-0.0134,  0.0158],\n",
      "        [-0.0133,  0.0156],\n",
      "        [-0.0132,  0.0154],\n",
      "        [-0.0131,  0.0155],\n",
      "        [-0.0131,  0.0161]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0135,  0.0160],\n",
      "        [-0.0134,  0.0158],\n",
      "        [-0.0135,  0.0161],\n",
      "        [-0.0134,  0.0158],\n",
      "        [-0.0131,  0.0152],\n",
      "        [-0.0130,  0.0153],\n",
      "        [-0.0131,  0.0154],\n",
      "        [-0.0133,  0.0160]], device='cuda:0')\n",
      "labels:\n",
      "tensor([0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0002, device='cuda:0')\n",
      "euclidean_distance\n",
      "tensor([0.0148, 0.0085, 0.0063, 0.0034, 0.0196, 0.0132, 0.0100, 0.0151],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0148],\n",
      "        [0.0085],\n",
      "        [0.0063],\n",
      "        [0.0034],\n",
      "        [0.0196],\n",
      "        [0.0132],\n",
      "        [0.0100],\n",
      "        [0.0151]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 8.2680e-04, -1.8615e-03, -2.7382e-03,  ..., -1.1483e-03,\n",
      "         -7.0013e-04, -8.7874e-04],\n",
      "        [ 3.9451e-06, -1.4951e-03, -5.2545e-03,  ..., -2.4684e-03,\n",
      "         -5.6932e-04, -1.2071e-03],\n",
      "        [ 3.5977e-04, -1.2160e-03, -5.3498e-03,  ..., -2.2545e-03,\n",
      "         -3.9490e-04, -1.5084e-03],\n",
      "        ...,\n",
      "        [ 1.1132e-03, -1.0965e-03, -4.9549e-03,  ..., -8.2848e-04,\n",
      "         -2.0427e-04, -1.2426e-03],\n",
      "        [ 4.4603e-04, -1.3632e-03, -3.3288e-03,  ..., -6.9938e-04,\n",
      "          4.9725e-04, -1.1517e-03],\n",
      "        [ 3.6735e-04, -1.7926e-03, -3.6559e-03,  ..., -1.7354e-03,\n",
      "         -1.2289e-04, -8.6268e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0020, -0.0026],\n",
      "        [ 0.0015, -0.0023],\n",
      "        [ 0.0017, -0.0020],\n",
      "        [ 0.0008, -0.0024],\n",
      "        [ 0.0021, -0.0024],\n",
      "        [ 0.0023, -0.0030],\n",
      "        [ 0.0024, -0.0023],\n",
      "        [ 0.0022, -0.0025]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 0.0020, -0.0023],\n",
      "        [ 0.0014, -0.0024],\n",
      "        [ 0.0014, -0.0018],\n",
      "        [ 0.0010, -0.0024],\n",
      "        [ 0.0022, -0.0030],\n",
      "        [ 0.0021, -0.0032],\n",
      "        [ 0.0020, -0.0022],\n",
      "        [ 0.0019, -0.0027]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0134,  0.0161],\n",
      "        [-0.0133,  0.0160],\n",
      "        [-0.0133,  0.0161],\n",
      "        [-0.0134,  0.0158],\n",
      "        [-0.0133,  0.0156],\n",
      "        [-0.0132,  0.0154],\n",
      "        [-0.0131,  0.0155],\n",
      "        [-0.0131,  0.0161]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0135,  0.0160],\n",
      "        [-0.0134,  0.0158],\n",
      "        [-0.0135,  0.0161],\n",
      "        [-0.0134,  0.0158],\n",
      "        [-0.0131,  0.0152],\n",
      "        [-0.0130,  0.0153],\n",
      "        [-0.0131,  0.0154],\n",
      "        [-0.0133,  0.0160]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 0.00203137 -0.00264003]\n",
      " [ 0.00150336 -0.00229261]\n",
      " [ 0.00166865 -0.00202446]\n",
      " [ 0.00077222 -0.00238075]\n",
      " [ 0.0020988  -0.00235292]\n",
      " [ 0.00228275 -0.00298499]\n",
      " [ 0.00237446 -0.00226311]\n",
      " [ 0.00215894 -0.00248369]]\n",
      "[0 0 0 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "euclidean_distance\n",
      "tensor([0.0043, 0.0160, 0.0080, 0.0164, 0.0049, 0.0027, 0.0137, 0.0020],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0043],\n",
      "        [0.0160],\n",
      "        [0.0080],\n",
      "        [0.0164],\n",
      "        [0.0049],\n",
      "        [0.0027],\n",
      "        [0.0137],\n",
      "        [0.0020]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 9.0223e-05, -2.2273e-03, -4.2332e-03,  ..., -3.3705e-03,\n",
      "         -9.9521e-06, -5.2655e-04],\n",
      "        [-1.4574e-04, -2.0632e-03, -3.5734e-03,  ..., -3.5536e-03,\n",
      "         -7.0529e-04, -5.8720e-04],\n",
      "        [ 4.9424e-04, -2.1025e-03, -4.6986e-03,  ..., -3.8825e-03,\n",
      "         -2.9992e-04, -4.4268e-04],\n",
      "        ...,\n",
      "        [-1.2564e-04, -1.6327e-03, -4.2400e-03,  ..., -2.9896e-03,\n",
      "          1.4853e-04, -7.2319e-04],\n",
      "        [-1.2337e-04, -1.4133e-03, -3.3790e-03,  ..., -6.1362e-04,\n",
      "         -3.5146e-04, -1.7385e-03],\n",
      "        [ 4.6093e-04, -1.7868e-03, -2.5656e-03,  ..., -7.4749e-04,\n",
      "          2.1801e-04, -2.0988e-03]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0017, -0.0028],\n",
      "        [ 0.0019, -0.0024],\n",
      "        [ 0.0020, -0.0027],\n",
      "        [ 0.0018, -0.0027],\n",
      "        [ 0.0011, -0.0024],\n",
      "        [ 0.0009, -0.0025],\n",
      "        [ 0.0016, -0.0022],\n",
      "        [ 0.0025, -0.0019]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 0.0019, -0.0029],\n",
      "        [ 0.0016, -0.0024],\n",
      "        [ 0.0018, -0.0027],\n",
      "        [ 0.0015, -0.0026],\n",
      "        [ 0.0014, -0.0025],\n",
      "        [ 0.0010, -0.0026],\n",
      "        [ 0.0016, -0.0025],\n",
      "        [ 0.0025, -0.0019]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0138,  0.0159],\n",
      "        [-0.0138,  0.0156],\n",
      "        [-0.0136,  0.0156],\n",
      "        [-0.0136,  0.0154],\n",
      "        [-0.0132,  0.0163],\n",
      "        [-0.0130,  0.0159],\n",
      "        [-0.0136,  0.0151],\n",
      "        [-0.0128,  0.0149]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0137,  0.0157],\n",
      "        [-0.0136,  0.0153],\n",
      "        [-0.0136,  0.0153],\n",
      "        [-0.0135,  0.0156],\n",
      "        [-0.0132,  0.0162],\n",
      "        [-0.0131,  0.0158],\n",
      "        [-0.0133,  0.0153],\n",
      "        [-0.0128,  0.0150]], device='cuda:0')\n",
      "labels:\n",
      "tensor([1, 1, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0001, device='cuda:0')\n",
      "euclidean_distance\n",
      "tensor([0.0043, 0.0160, 0.0080, 0.0164, 0.0049, 0.0027, 0.0137, 0.0020],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0043],\n",
      "        [0.0160],\n",
      "        [0.0080],\n",
      "        [0.0164],\n",
      "        [0.0049],\n",
      "        [0.0027],\n",
      "        [0.0137],\n",
      "        [0.0020]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 9.0223e-05, -2.2273e-03, -4.2332e-03,  ..., -3.3705e-03,\n",
      "         -9.9521e-06, -5.2655e-04],\n",
      "        [-1.4574e-04, -2.0632e-03, -3.5734e-03,  ..., -3.5536e-03,\n",
      "         -7.0529e-04, -5.8720e-04],\n",
      "        [ 4.9424e-04, -2.1025e-03, -4.6986e-03,  ..., -3.8825e-03,\n",
      "         -2.9992e-04, -4.4268e-04],\n",
      "        ...,\n",
      "        [-1.2564e-04, -1.6327e-03, -4.2400e-03,  ..., -2.9896e-03,\n",
      "          1.4853e-04, -7.2319e-04],\n",
      "        [-1.2337e-04, -1.4133e-03, -3.3790e-03,  ..., -6.1362e-04,\n",
      "         -3.5146e-04, -1.7385e-03],\n",
      "        [ 4.6093e-04, -1.7868e-03, -2.5656e-03,  ..., -7.4749e-04,\n",
      "          2.1801e-04, -2.0988e-03]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0017, -0.0028],\n",
      "        [ 0.0019, -0.0024],\n",
      "        [ 0.0020, -0.0027],\n",
      "        [ 0.0018, -0.0027],\n",
      "        [ 0.0011, -0.0024],\n",
      "        [ 0.0009, -0.0025],\n",
      "        [ 0.0016, -0.0022],\n",
      "        [ 0.0025, -0.0019]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 0.0019, -0.0029],\n",
      "        [ 0.0016, -0.0024],\n",
      "        [ 0.0018, -0.0027],\n",
      "        [ 0.0015, -0.0026],\n",
      "        [ 0.0014, -0.0025],\n",
      "        [ 0.0010, -0.0026],\n",
      "        [ 0.0016, -0.0025],\n",
      "        [ 0.0025, -0.0019]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0138,  0.0159],\n",
      "        [-0.0138,  0.0156],\n",
      "        [-0.0136,  0.0156],\n",
      "        [-0.0136,  0.0154],\n",
      "        [-0.0132,  0.0163],\n",
      "        [-0.0130,  0.0159],\n",
      "        [-0.0136,  0.0151],\n",
      "        [-0.0128,  0.0149]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0137,  0.0157],\n",
      "        [-0.0136,  0.0153],\n",
      "        [-0.0136,  0.0153],\n",
      "        [-0.0135,  0.0156],\n",
      "        [-0.0132,  0.0162],\n",
      "        [-0.0131,  0.0158],\n",
      "        [-0.0133,  0.0153],\n",
      "        [-0.0128,  0.0150]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 0.00173843 -0.00280835]\n",
      " [ 0.00185068 -0.00243509]\n",
      " [ 0.0019749  -0.00272549]\n",
      " [ 0.00177526 -0.00274243]\n",
      " [ 0.00114695 -0.00239829]\n",
      " [ 0.00087514 -0.00253084]\n",
      " [ 0.00163554 -0.00224809]\n",
      " [ 0.00249089 -0.00186374]]\n",
      "[1 1 1 1 0 0 1 1]\n",
      "[1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean_distance\n",
      "tensor([0.0130, 0.0062, 0.0110, 0.0101, 0.0165, 0.0113, 0.0043, 0.0111],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0130],\n",
      "        [0.0062],\n",
      "        [0.0110],\n",
      "        [0.0101],\n",
      "        [0.0165],\n",
      "        [0.0113],\n",
      "        [0.0043],\n",
      "        [0.0111]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 1.0142e-03, -9.9100e-04, -4.5447e-03,  ..., -3.9338e-04,\n",
      "         -5.8377e-04, -2.2461e-03],\n",
      "        [ 1.8125e-03, -1.3317e-03, -7.9949e-04,  ..., -2.0181e-04,\n",
      "         -2.7191e-04, -4.8084e-04],\n",
      "        [ 2.6808e-04, -7.1446e-04, -8.5931e-05,  ...,  2.5326e-03,\n",
      "         -9.0737e-04, -3.0103e-04],\n",
      "        ...,\n",
      "        [ 1.1211e-03, -4.1811e-04, -1.8785e-03,  ...,  4.8194e-04,\n",
      "         -2.0311e-04, -6.5763e-04],\n",
      "        [ 8.1391e-04, -7.5884e-04, -1.0999e-03,  ...,  5.8307e-04,\n",
      "         -3.3498e-04,  5.2186e-04],\n",
      "        [ 4.0446e-04, -1.5836e-03, -1.0306e-03,  ...,  1.5041e-04,\n",
      "         -4.9870e-04,  9.2678e-05]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0011, -0.0026],\n",
      "        [ 0.0016, -0.0014],\n",
      "        [ 0.0018, -0.0020],\n",
      "        [ 0.0015, -0.0020],\n",
      "        [ 0.0013, -0.0020],\n",
      "        [ 0.0012, -0.0016],\n",
      "        [ 0.0019, -0.0020],\n",
      "        [ 0.0017, -0.0021]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 0.0012, -0.0025],\n",
      "        [ 0.0016, -0.0016],\n",
      "        [ 0.0020, -0.0022],\n",
      "        [ 0.0017, -0.0019],\n",
      "        [ 0.0011, -0.0021],\n",
      "        [ 0.0013, -0.0019],\n",
      "        [ 0.0018, -0.0019],\n",
      "        [ 0.0016, -0.0021]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0127,  0.0160],\n",
      "        [-0.0131,  0.0154],\n",
      "        [-0.0130,  0.0154],\n",
      "        [-0.0130,  0.0148],\n",
      "        [-0.0128,  0.0138],\n",
      "        [-0.0132,  0.0142],\n",
      "        [-0.0126,  0.0147],\n",
      "        [-0.0125,  0.0150]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0127,  0.0156],\n",
      "        [-0.0130,  0.0152],\n",
      "        [-0.0130,  0.0152],\n",
      "        [-0.0128,  0.0152],\n",
      "        [-0.0129,  0.0141],\n",
      "        [-0.0130,  0.0142],\n",
      "        [-0.0126,  0.0148],\n",
      "        [-0.0126,  0.0150]], device='cuda:0')\n",
      "labels:\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(0.0001, device='cuda:0')\n",
      "euclidean_distance\n",
      "tensor([0.0130, 0.0062, 0.0110, 0.0101, 0.0165, 0.0113, 0.0043, 0.0111],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0130],\n",
      "        [0.0062],\n",
      "        [0.0110],\n",
      "        [0.0101],\n",
      "        [0.0165],\n",
      "        [0.0113],\n",
      "        [0.0043],\n",
      "        [0.0111]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 1.0142e-03, -9.9100e-04, -4.5447e-03,  ..., -3.9338e-04,\n",
      "         -5.8377e-04, -2.2461e-03],\n",
      "        [ 1.8125e-03, -1.3317e-03, -7.9949e-04,  ..., -2.0181e-04,\n",
      "         -2.7191e-04, -4.8084e-04],\n",
      "        [ 2.6808e-04, -7.1446e-04, -8.5931e-05,  ...,  2.5326e-03,\n",
      "         -9.0737e-04, -3.0103e-04],\n",
      "        ...,\n",
      "        [ 1.1211e-03, -4.1811e-04, -1.8785e-03,  ...,  4.8194e-04,\n",
      "         -2.0311e-04, -6.5763e-04],\n",
      "        [ 8.1391e-04, -7.5884e-04, -1.0999e-03,  ...,  5.8307e-04,\n",
      "         -3.3498e-04,  5.2186e-04],\n",
      "        [ 4.0446e-04, -1.5836e-03, -1.0306e-03,  ...,  1.5041e-04,\n",
      "         -4.9870e-04,  9.2678e-05]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0011, -0.0026],\n",
      "        [ 0.0016, -0.0014],\n",
      "        [ 0.0018, -0.0020],\n",
      "        [ 0.0015, -0.0020],\n",
      "        [ 0.0013, -0.0020],\n",
      "        [ 0.0012, -0.0016],\n",
      "        [ 0.0019, -0.0020],\n",
      "        [ 0.0017, -0.0021]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 0.0012, -0.0025],\n",
      "        [ 0.0016, -0.0016],\n",
      "        [ 0.0020, -0.0022],\n",
      "        [ 0.0017, -0.0019],\n",
      "        [ 0.0011, -0.0021],\n",
      "        [ 0.0013, -0.0019],\n",
      "        [ 0.0018, -0.0019],\n",
      "        [ 0.0016, -0.0021]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0127,  0.0160],\n",
      "        [-0.0131,  0.0154],\n",
      "        [-0.0130,  0.0154],\n",
      "        [-0.0130,  0.0148],\n",
      "        [-0.0128,  0.0138],\n",
      "        [-0.0132,  0.0142],\n",
      "        [-0.0126,  0.0147],\n",
      "        [-0.0125,  0.0150]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0127,  0.0156],\n",
      "        [-0.0130,  0.0152],\n",
      "        [-0.0130,  0.0152],\n",
      "        [-0.0128,  0.0152],\n",
      "        [-0.0129,  0.0141],\n",
      "        [-0.0130,  0.0142],\n",
      "        [-0.0126,  0.0148],\n",
      "        [-0.0126,  0.0150]], device='cuda:0')\n",
      "labels:\n",
      "None\n",
      "logits:\n",
      "[[ 0.00111606 -0.00264017]\n",
      " [ 0.00158517 -0.00144033]\n",
      " [ 0.00181145 -0.00196356]\n",
      " [ 0.00153032 -0.00198999]\n",
      " [ 0.0013219  -0.00204693]\n",
      " [ 0.00120484 -0.00159307]\n",
      " [ 0.00194673 -0.00204875]\n",
      " [ 0.00167158 -0.00208272]]\n",
      "[1 1 1 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "euclidean_distance\n",
      "tensor([0.0118, 0.0058, 0.0066, 0.0091, 0.0076, 0.0074, 0.0041, 0.0079],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0118],\n",
      "        [0.0058],\n",
      "        [0.0066],\n",
      "        [0.0091],\n",
      "        [0.0076],\n",
      "        [0.0074],\n",
      "        [0.0041],\n",
      "        [0.0079]], device='cuda:0')\n",
      "pooled_output size:\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 1.6599e-03, -9.0276e-04, -1.4584e-03,  ...,  2.0113e-03,\n",
      "         -6.7249e-04, -7.9719e-04],\n",
      "        [ 2.1529e-03, -1.1441e-03, -3.9573e-04,  ..., -1.0409e-04,\n",
      "          8.2346e-05,  9.7938e-05],\n",
      "        [ 2.2434e-03, -2.3830e-04, -2.7645e-03,  ...,  2.1108e-05,\n",
      "         -9.8268e-04, -2.3938e-04],\n",
      "        ...,\n",
      "        [ 9.3232e-04, -7.4450e-04, -7.1223e-04,  ...,  3.6147e-04,\n",
      "         -4.7564e-04,  1.0110e-03],\n",
      "        [ 1.6838e-03, -1.5785e-04, -2.3336e-03,  ..., -1.6992e-04,\n",
      "         -1.1189e-03,  1.1720e-03],\n",
      "        [ 1.7431e-03, -2.7939e-04, -1.6113e-03,  ..., -1.8570e-04,\n",
      "         -4.2134e-04, -4.2555e-04]], device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[ 0.0020, -0.0021],\n",
      "        [ 0.0013, -0.0012],\n",
      "        [ 0.0009, -0.0008],\n",
      "        [ 0.0011, -0.0012],\n",
      "        [ 0.0014, -0.0020],\n",
      "        [ 0.0018, -0.0017],\n",
      "        [ 0.0007, -0.0013],\n",
      "        [ 0.0005, -0.0014]], device='cuda:0')\n",
      "logits_ce_opp:\n",
      "tensor([[ 0.0018, -0.0022],\n",
      "        [ 0.0015, -0.0013],\n",
      "        [ 0.0009, -0.0009],\n",
      "        [ 0.0012, -0.0012],\n",
      "        [ 0.0016, -0.0018],\n",
      "        [ 0.0020, -0.0019],\n",
      "        [ 0.0006, -0.0013],\n",
      "        [ 0.0006, -0.0017]], device='cuda:0')\n",
      "logits_pairwise:\n",
      "tensor([[-0.0130,  0.0147],\n",
      "        [-0.0130,  0.0157],\n",
      "        [-0.0140,  0.0151],\n",
      "        [-0.0134,  0.0151],\n",
      "        [-0.0130,  0.0146],\n",
      "        [-0.0128,  0.0139],\n",
      "        [-0.0140,  0.0148],\n",
      "        [-0.0132,  0.0152]], device='cuda:0')\n",
      "logits_pairwise_opp:\n",
      "tensor([[-0.0129,  0.0150],\n",
      "        [-0.0130,  0.0156],\n",
      "        [-0.0142,  0.0149],\n",
      "        [-0.0135,  0.0151],\n",
      "        [-0.0131,  0.0147],\n",
      "        [-0.0129,  0.0140],\n",
      "        [-0.0140,  0.0148],\n",
      "        [-0.0131,  0.0153]], device='cuda:0')\n",
      "labels:\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "labels2\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "loss_contrastive\n",
      "tensor(6.1415e-05, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-70908a0f3daf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#     experiments()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mevaluation_with_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-322bfa572b3b>\u001b[0m in \u001b[0;36mevaluation_with_pretrained\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m## v3: multiply\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdata_dir_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"D:/Projects/Stance/Evaluation/bert_dummy_output/BertForOppositeClassification\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtrain_and_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dir_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mrpc\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-ecad2bc4266c>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[1;34m(data_dir, bert_model, task_name, output_dir, max_seq_length, do_train, do_eval, do_lower_case, train_batch_size, eval_batch_size, learning_rate, num_train_epochs, warmup_proportion, no_cuda, local_rank, seed, gradient_accumulation_steps, optimize_on_cpu, fp16, loss_scale, saved_model)\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtmp_eval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_segment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_label_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m                 \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_segment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;31m#             print(logits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-479dd2b3afcc>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, input_ids2, attention_mask2, token_type_ids2, position_ids2, head_mask2, inputs_embeds2, labels2)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0minput_ids2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;31m#             position_ids=position_ids2,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m#             head_mask=head_mask2,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[0;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[0;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[0;32m    734\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     experiments()\n",
    "    evaluation_with_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "# torch.cuda.empty_cache()\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "# from pytorch_pretrained_bert.tokenization import BertTokenizer, WordpieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_classifier import ColaProcessor, MrpcProcessor, logger, convert_examples_to_features,\\\n",
    "    set_optimizer_params_grad, copy_optimizer_params_to_model, accuracy, p_r_f1, tp_pcount_gcount, convert_claims_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "#     device = torch.device(\"cuda\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('There are %d GPU(s) available.' % n_gpu)\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2020 18:53:51 - INFO - transformers.file_utils -   PyTorch version 1.4.0 available.\n",
      "05/04/2020 18:53:53 - INFO - transformers.file_utils -   TensorFlow version 2.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertPreTrainedModel, BertModel, BertConfig\n",
    "from torch.nn import BCEWithLogitsLoss, CosineEmbeddingLoss,CrossEntropyLoss, MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_and_test(data_dir, bert_model=\"bert-base-uncased\", task_name=None,\n",
    "#                    output_dir=None, max_seq_length=128, do_train=False, do_eval=False, do_lower_case=False,\n",
    "#                    train_batch_size=32, eval_batch_size=8, learning_rate=5e-5, num_train_epochs=3,\n",
    "#                    warmup_proportion=0.1,no_cuda=False, local_rank=-1, seed=42, gradient_accumulation_steps=1,\n",
    "#                    optimize_on_cpu=False, fp16=False, loss_scale=128, saved_model=\"\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertPreTrainedModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0dcdc7d8729e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mBertForConsistencyCueClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBertPreTrainedModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBertForConsistencyCueClassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BertPreTrainedModel' is not defined"
     ]
    }
   ],
   "source": [
    "class BertForConsistencyCueClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_labels=2):\n",
    "        super(BertForConsistencyCueClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size+1, num_labels)\n",
    "        self.classifier2 = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "        self.apply(self.init_bert_weights)\n",
    "#         self.init_weights()\n",
    "\n",
    "#     @add_start_docstrings_to_callable(BERT_INPUTS_DOCSTRING)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        input_ids2=None,\n",
    "        attention_mask2=None,\n",
    "        token_type_ids2=None,\n",
    "        position_ids2=None,\n",
    "        head_mask2=None,\n",
    "        inputs_embeds2=None,\n",
    "        labels2=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n",
    "            Labels for computing the sequence classification/regression loss.\n",
    "            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n",
    "            If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "\n",
    "    Returns:\n",
    "        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.BertConfig`) and inputs:\n",
    "        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n",
    "            Classification (or regression if config.num_labels==1) loss.\n",
    "        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`):\n",
    "            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
    "        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
    "            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
    "\n",
    "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n",
    "            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n",
    "\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        from transformers import BertTokenizer, BertForSequenceClassification\n",
    "        import torch\n",
    "\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "\n",
    "        loss, logits = outputs[:2]\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        _, outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "#             position_ids=position_ids,\n",
    "#             head_mask=head_mask,\n",
    "#             inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        _, outputsC = self.bert(\n",
    "            input_ids2,\n",
    "            attention_mask=attention_mask2,\n",
    "            token_type_ids=token_type_ids2,\n",
    "#             position_ids=position_ids2,\n",
    "#             head_mask=head_mask2,\n",
    "#             inputs_embeds=inputs_embeds2,\n",
    "        )\n",
    "#         print(\"Careful, outputs:\")\n",
    "#         print(outputs)\n",
    "#         print(outputsC)\n",
    "        pooled_output = outputs\n",
    "        pooled_outputC = outputsC\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_outputC = self.dropout(pooled_outputC)\n",
    "        \n",
    "        cos_pooled_outputs = torch.cosine_similarity(pooled_output, pooled_outputC, dim=1)\n",
    "        \n",
    "#         print('pooled_output size:')\n",
    "#         print(pooled_output.size())\n",
    "#         print(pooled_output)\n",
    "#         print('cos_pooled_outputs size:')\n",
    "#         print(cos_pooled_outputs.size())\n",
    "#         print(cos_pooled_outputs)\n",
    "        batch_size = list(pooled_output.size())[0]\n",
    "        hidden_size = list(pooled_output.size())[1]\n",
    "\n",
    "        logits_ce = self.classifier2(pooled_output)\n",
    "        print('logits_ce:')\n",
    "        print(logits_ce)\n",
    "        \n",
    "    \n",
    "        ## v2: concat\n",
    "        ## v3: multiply\n",
    "        ## v4: v2 & ce_cos_similarity\n",
    "        ## v5: v3 & ce_cos_similarity\n",
    "        \n",
    "#         print(torch.cat((pooled_output, cos_pooled_outputs.unsqueeze(1)),1))\n",
    "#         print((pooled_output*cos_pooled_outputs.unsqueeze(1)))\n",
    "        logits_cos = self.classifier(torch.cat((pooled_output, cos_pooled_outputs.unsqueeze(1)),1))\n",
    "#         logits_cos = self.classifier2((pooled_output*cos_pooled_outputs.unsqueeze(1)))\n",
    "#         self.classifier = torch.nn.Linear(hidden_size+batch_size, 2).to(device)\n",
    "#         logits_cos = self.classifier(torch.cat((pooled_output, cos_pooled_outputs.repeat(batch_size,1)),1))\n",
    "        print('logits_cos:')\n",
    "        print(logits_cos)\n",
    "        \n",
    "#         logits = self.classifier(pooled_output)\n",
    "#         logitsC = self.classifier(pooled_outputC)\n",
    "\n",
    "#         outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "#         print(logits)\n",
    "#         print('xd')\n",
    "#         print(outputs[2:])\n",
    "#         outputs = (logits,) + outputs[2:]\n",
    "#         print(\"labels:\")\n",
    "#         print(labels)\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "#                 loss_fct_ce = CrossEntropyLoss()\n",
    "#                 loss_ce = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "                loss_fct_ce = CrossEntropyLoss()\n",
    "#                 print('pooled_output size:')\n",
    "#                 print(pooled_output.size())\n",
    "                loss_ce = loss_fct_ce(logits_ce.view(-1, self.num_labels), labels.view(-1))\n",
    "#                 loss_ce = loss_fct_ce(pooled_output.view(-1), labels.view(-1))\n",
    "                print('loss_ce:')\n",
    "                print(loss_ce)\n",
    "\n",
    "                \n",
    "                loss_fct_cos = CosineEmbeddingLoss()\n",
    "#                 print(labels)\n",
    "#                 print(pooled_outputC)\n",
    "\n",
    "\n",
    "                labels2[labels2==0] = -1\n",
    "                loss_cos = loss_fct_cos(pooled_output, pooled_outputC, labels2)\n",
    "                labels2[labels2==-1] = 0\n",
    "        \n",
    "#                 loss_cos = loss_fct_cos(logits_ce, logits_cos, labels2)\n",
    "#                 loss_cos = loss_fct_ce(logits_cos.view(-1, self.num_labels), labels2.view(-1))\n",
    "                print('loss_cos:')\n",
    "                print(loss_cos)\n",
    "            \n",
    "                loss = loss_ce + loss_cos\n",
    "                print('final loss:')\n",
    "                print(loss)\n",
    "#                 logits = self.classifier(loss)\n",
    "#             outputs = (loss,) + outputs\n",
    "#             outputs = (loss,) + logits_cos \n",
    "                outputs = loss\n",
    "                return outputs\n",
    "        else:\n",
    "            return logits_cos\n",
    "        \n",
    "          # (loss), logits, (hidden_states), (attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labe = torch.ones(8)\n",
    "# print(labe )\n",
    "# labe[labe==1] = -1\n",
    "# labe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.tensor([[4.2,5,6,7,8],[9,10,11,12,13]])\n",
    "# b = torch.tensor([[3.4,5,6,7,8],[9,10,11,12,13]])\n",
    "\n",
    "# # a = torch.tensor([[4,5,6,7,8],[9,10,11,12,13]])\n",
    "# # b = torch.tensor([1,2])\n",
    "# c= torch.cosine_similarity(a,b,dim=1)\n",
    "# # b.unsqueeze(1)\n",
    "# # # a.size()\n",
    "# # torch.cat((a,c.unsqueeze(1)),1)\n",
    "# a*c.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input1 = torch.randn(100, 128)\n",
    "# input2 = torch.randn(100, 128)\n",
    "# output = torch.cosine_similarity(input1, input2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2020 16:26:43 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\arsen\\.cache\\torch\\transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2020 16:26:46 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\arsen\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "05/04/2020 16:26:46 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file C:\\Users\\arsen\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\arsen\\AppData\\Local\\Temp\\tmpqnbs2wut\n",
      "05/04/2020 16:26:49 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/04/2020 16:26:52 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForConsistencyCueClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias', 'classifier2.weight', 'classifier2.bias']\n",
      "05/04/2020 16:26:52 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForConsistencyCueClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForConsistencyCueClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=769, out_features=2, bias=True)\n",
       "  (classifier2): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare model \n",
    "model = BertForConsistencyCueClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 203 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "classifier.weight                                           (2, 769)\n",
      "classifier.bias                                                 (2,)\n",
      "classifier2.weight                                          (2, 768)\n",
      "classifier2.bias                                                (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "    \n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2020 16:30:50 - INFO - run_classifier -   LOOKING AT D:/Jupyter/data/dataset/perspective_stances/train.tsv\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"D:/Jupyter/data/dataset/perspective_stances/\"\n",
    "data_dir_output = \"D:/Projects/Stance/Models/Consistency_Cues/\"\n",
    "output_dir=data_dir_output\n",
    "max_seq_length=32\n",
    "max_grad_norm = 1.0\n",
    "num_training_steps = 1000\n",
    "num_warmup_steps = 100\n",
    "warmup_proportion = float(num_warmup_steps) / float(num_training_steps)  # 0.1\n",
    "# warmup_proportion = 0.1\n",
    "train_batch_size=32\n",
    "eval_batch_size=8\n",
    "learning_rate=5e-5\n",
    "num_train_epochs=3\n",
    "local_rank=-1\n",
    "seed=42\n",
    "gradient_accumulation_steps=1\n",
    "loss_scale=128\n",
    "train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "\n",
    "processors = {\n",
    "        \"mrpc\": MrpcProcessor,\n",
    "    }\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "processor = processors['mrpc']()\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)\n",
    "# print('label list')\n",
    "# print(label_list)\n",
    "\n",
    "train_examples = processor.get_train_examples(data_dir)\n",
    "num_train_steps = int(\n",
    "    len(train_examples) / train_batch_size / gradient_accumulation_steps * num_train_epochs)\n",
    "\n",
    "##preprare optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "t_total = num_train_steps\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=learning_rate,\n",
    "                         warmup=warmup_proportion,\n",
    "                         t_total=t_total)\n",
    "# optimizer = AdamW(optimizer_grouped_parameters,\n",
    "#                   lr = learning_rate, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "#                   eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n",
    "#                   correct_bias=False\n",
    "#                 )\n",
    "\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)  # PyTorch scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2020 16:30:53 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   guid: train-1\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP] parents have the right to use their best judgment , in the light of medical advice [SEP]\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 3008 2031 1996 2157 2000 2224 2037 2190 8689 1010 1999 1996 2422 1997 2966 6040 102\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   guid: train-2\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP] parents know what best for th ##ier child [SEP]\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 3008 2113 2054 2190 2005 16215 3771 2775 102 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   guid: train-3\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP] parents have the right to make the decisions for their child [SEP]\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 3008 2031 1996 2157 2000 2191 1996 6567 2005 2037 2775 102 0 0 0 0 0\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   guid: train-4\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   tokens: [CLS] punishment should fit the criminal [SEP] it will cause less re - offenders . [SEP]\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   input_ids: 101 7750 2323 4906 1996 4735 102 2009 2097 3426 2625 2128 1011 19591 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   guid: train-5\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   tokens: [CLS] punishment should fit the criminal [SEP] adequate punishment reduces future offenses . [SEP]\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   input_ids: 101 7750 2323 4906 1996 4735 102 11706 7750 13416 2925 25173 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:53 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   guid: train-1\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP]\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   guid: train-2\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP]\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   guid: train-3\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   tokens: [CLS] male infant ci ##rc ##um ##cision is tan ##tam ##ount to child abuse [SEP]\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   input_ids: 101 3287 10527 25022 11890 2819 28472 2003 9092 15464 21723 2000 2775 6905 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   guid: train-4\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   tokens: [CLS] punishment should fit the criminal [SEP]\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   input_ids: 101 7750 2323 4906 1996 4735 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   guid: train-5\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   tokens: [CLS] punishment should fit the criminal [SEP]\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   input_ids: 101 7750 2323 4906 1996 4735 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 16:30:58 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 16:30:59 - INFO - run_classifier -   ***** Running training *****\n",
      "05/04/2020 16:30:59 - INFO - run_classifier -     Num examples = 7007\n",
      "05/04/2020 16:30:59 - INFO - run_classifier -     Batch size = 32\n",
      "05/04/2020 16:30:59 - INFO - run_classifier -     Num steps = 656\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "train_features = convert_examples_to_features(train_examples, label_list, max_seq_length, tokenizer)\n",
    "claim_features = convert_claims_to_features(train_examples, label_list, max_seq_length, tokenizer)\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "\n",
    "claims_input_ids = torch.tensor([f.input_ids for f in claim_features], dtype=torch.long)\n",
    "claims_input_mask = torch.tensor([f.input_mask for f in claim_features], dtype=torch.long)\n",
    "claims_segment_ids = torch.tensor([f.segment_ids for f in claim_features], dtype=torch.long)\n",
    "claims_label_ids = torch.tensor([f.label_id for f in claim_features], dtype=torch.long)\n",
    "\n",
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, claims_input_ids, claims_input_mask, claims_segment_ids, claims_label_ids)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
    "\n",
    "# claims_data = TensorDataset(claims_input_ids, claims_input_mask, claims_segment_ids, claims_label_ids)\n",
    "# claims_sampler = RandomSampler(claims_data)\n",
    "# claims_dataloader = DataLoader(claims_data, sampler=train_sampler, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                                                               | 0/219 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.2314, -0.6650],\n",
      "        [ 0.3943, -0.4516],\n",
      "        [ 0.4322, -0.0965],\n",
      "        [ 0.1780, -0.3529],\n",
      "        [ 0.3853, -0.3258],\n",
      "        [ 0.3594, -0.5737],\n",
      "        [ 0.1195, -0.5358],\n",
      "        [ 0.3951,  0.0253],\n",
      "        [ 0.4374, -0.4874],\n",
      "        [ 0.4429, -0.3628],\n",
      "        [ 0.5287, -0.2464],\n",
      "        [ 0.4071, -0.3961],\n",
      "        [ 0.3223, -0.2628],\n",
      "        [ 0.2889, -0.2883],\n",
      "        [-0.0845, -0.4138],\n",
      "        [ 0.1327, -0.5746],\n",
      "        [ 0.3086, -0.3244],\n",
      "        [ 0.6812, -0.4486],\n",
      "        [ 0.4316, -0.3043],\n",
      "        [ 0.1387, -0.0339],\n",
      "        [ 0.4069, -0.2528],\n",
      "        [ 0.2407, -0.4991],\n",
      "        [ 0.5314, -0.0160],\n",
      "        [ 0.4126,  0.0717],\n",
      "        [ 0.3478, -0.5088],\n",
      "        [ 0.2907, -0.3635],\n",
      "        [ 0.3470, -0.4222],\n",
      "        [ 0.5832, -0.5329],\n",
      "        [ 0.2071, -0.2342],\n",
      "        [-0.0331, -0.2073],\n",
      "        [ 0.2420, -0.4617],\n",
      "        [ 0.4175, -0.0977]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[0.1803, 0.3131],\n",
      "        [0.3351, 0.2469],\n",
      "        [0.2901, 0.2153],\n",
      "        [0.6301, 0.3063],\n",
      "        [0.4377, 0.2712],\n",
      "        [0.3861, 0.5100],\n",
      "        [0.3644, 0.2242],\n",
      "        [0.4664, 0.1441],\n",
      "        [0.4780, 0.3443],\n",
      "        [0.5931, 0.4864],\n",
      "        [0.2396, 0.4051],\n",
      "        [0.2340, 0.3906],\n",
      "        [0.3326, 0.0559],\n",
      "        [0.3506, 0.4656],\n",
      "        [0.3056, 0.3673],\n",
      "        [0.2402, 0.3635],\n",
      "        [0.1607, 0.2803],\n",
      "        [0.4468, 0.3571],\n",
      "        [0.4727, 0.3086],\n",
      "        [0.1083, 0.3155],\n",
      "        [0.5737, 0.1247],\n",
      "        [0.4557, 0.4540],\n",
      "        [0.4173, 0.2742],\n",
      "        [0.5775, 0.3092],\n",
      "        [0.3703, 0.4870],\n",
      "        [0.6980, 0.4687],\n",
      "        [0.3868, 0.3673],\n",
      "        [0.4148, 0.6549],\n",
      "        [0.5135, 0.4391],\n",
      "        [0.4415, 0.1646],\n",
      "        [0.3485, 0.2112],\n",
      "        [0.2130, 0.1938]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.8332, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.3622, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1954, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1954, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   0%|▎                                                                      | 1/219 [00:09<33:23,  9.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.6230, -0.5412],\n",
      "        [ 0.1508, -0.6390],\n",
      "        [ 0.2166, -0.5909],\n",
      "        [-0.0295, -0.1559],\n",
      "        [ 0.2701, -0.2234],\n",
      "        [ 0.2780, -0.3062],\n",
      "        [ 0.2757, -0.4610],\n",
      "        [ 0.3367, -0.4396],\n",
      "        [ 0.3625, -0.3776],\n",
      "        [ 0.4325, -0.4440],\n",
      "        [ 0.2607, -0.1739],\n",
      "        [ 0.2596, -0.0895],\n",
      "        [ 0.2792, -0.3845],\n",
      "        [ 0.4030, -0.0779],\n",
      "        [ 0.0435, -0.2992],\n",
      "        [ 0.3822, -0.4722],\n",
      "        [ 0.3694, -0.1960],\n",
      "        [ 0.3876, -0.2019],\n",
      "        [ 0.4551,  0.1025],\n",
      "        [ 0.4233, -0.2248],\n",
      "        [ 0.3331, -0.3808],\n",
      "        [ 0.1247, -0.3444],\n",
      "        [ 0.1704, -0.6095],\n",
      "        [ 0.3646, -0.3216],\n",
      "        [ 0.4743, -0.5278],\n",
      "        [ 0.3620, -0.4271],\n",
      "        [-0.0275, -0.2572],\n",
      "        [ 0.3220, -0.3605],\n",
      "        [ 0.5877, -0.4058],\n",
      "        [ 0.2166, -0.4710],\n",
      "        [ 0.4079, -0.3565],\n",
      "        [ 0.2466, -0.1440]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.7015,  0.3966],\n",
      "        [ 0.4807,  0.2073],\n",
      "        [ 0.2774,  0.4099],\n",
      "        [ 0.1256,  0.6665],\n",
      "        [ 0.5584,  0.3789],\n",
      "        [ 0.3307,  0.1386],\n",
      "        [ 0.3621,  0.1774],\n",
      "        [ 0.4011,  0.2765],\n",
      "        [ 0.2581,  0.3514],\n",
      "        [ 0.2927,  0.4462],\n",
      "        [ 0.5107, -0.0172],\n",
      "        [ 0.2948,  0.4728],\n",
      "        [ 0.1338,  0.2213],\n",
      "        [ 0.5308,  0.5422],\n",
      "        [ 0.1381,  0.3164],\n",
      "        [-0.0289,  0.5670],\n",
      "        [ 0.1745,  0.0821],\n",
      "        [ 0.5376,  0.4724],\n",
      "        [ 0.2395,  0.1020],\n",
      "        [ 0.4308,  0.0815],\n",
      "        [ 0.1137,  0.1194],\n",
      "        [ 0.1915,  0.2052],\n",
      "        [ 0.5097,  0.4259],\n",
      "        [ 0.5713,  0.3125],\n",
      "        [ 0.3634,  0.5891],\n",
      "        [ 0.3468,  0.4464],\n",
      "        [ 0.3240,  0.1257],\n",
      "        [ 0.4609,  0.7044],\n",
      "        [ 0.6544,  0.4624],\n",
      "        [ 0.5927,  0.5075],\n",
      "        [ 0.2628,  0.5017],\n",
      "        [ 0.5135,  0.4636]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.8135, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.3718, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1852, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1852, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|▋                                                                      | 2/219 [00:18<33:18,  9.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.6408, -0.6406],\n",
      "        [ 0.0827, -0.4257],\n",
      "        [ 0.0794, -0.3705],\n",
      "        [ 0.5214, -0.0134],\n",
      "        [ 0.4455, -0.1985],\n",
      "        [ 0.4907, -0.2666],\n",
      "        [ 0.4063, -0.1285],\n",
      "        [ 0.3239, -0.5046],\n",
      "        [ 0.0585, -0.3826],\n",
      "        [ 0.3527, -0.6641],\n",
      "        [ 0.3498, -0.3980],\n",
      "        [ 0.3118, -0.2137],\n",
      "        [ 0.2741, -0.2912],\n",
      "        [ 0.5116, -0.2392],\n",
      "        [ 0.1339, -0.2388],\n",
      "        [ 0.3306, -0.2525],\n",
      "        [ 0.6550, -0.5088],\n",
      "        [ 0.3718, -0.6648],\n",
      "        [ 0.2631, -0.2024],\n",
      "        [ 0.1756, -0.4722],\n",
      "        [ 0.0991, -0.1517],\n",
      "        [ 0.4522, -0.1659],\n",
      "        [ 0.4171, -0.2045],\n",
      "        [ 0.0721, -0.3741],\n",
      "        [ 0.6310, -0.4548],\n",
      "        [ 0.2297, -0.4596],\n",
      "        [ 0.3386, -0.5132],\n",
      "        [ 0.3218, -0.3638],\n",
      "        [ 0.4290, -0.2990],\n",
      "        [ 0.5476, -0.3909],\n",
      "        [ 0.3849, -0.4529],\n",
      "        [ 0.2685, -0.4311]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.1939,  0.4645],\n",
      "        [ 0.5103,  0.2263],\n",
      "        [ 0.2548,  0.4977],\n",
      "        [-0.0763,  0.2960],\n",
      "        [ 0.6089,  0.3324],\n",
      "        [ 0.1998,  0.4067],\n",
      "        [ 0.2195,  0.2759],\n",
      "        [ 0.4907,  0.6100],\n",
      "        [ 0.1186,  0.2265],\n",
      "        [ 0.1160,  0.2408],\n",
      "        [ 0.4515,  0.3154],\n",
      "        [ 0.5937,  0.4102],\n",
      "        [ 0.6057,  0.4524],\n",
      "        [ 0.3602,  0.3252],\n",
      "        [ 0.3300,  0.3051],\n",
      "        [ 0.3623,  0.1245],\n",
      "        [ 0.3820,  0.2789],\n",
      "        [ 0.2876,  0.3132],\n",
      "        [ 0.5306,  0.5215],\n",
      "        [ 0.3991,  0.3091],\n",
      "        [ 0.2456,  0.5592],\n",
      "        [ 0.3369,  0.3636],\n",
      "        [ 0.4426,  0.3193],\n",
      "        [ 0.4648,  0.2780],\n",
      "        [ 0.8233,  0.3967],\n",
      "        [ 0.5197,  0.5279],\n",
      "        [ 0.4688,  0.4245],\n",
      "        [ 0.3267,  0.2459],\n",
      "        [ 0.7018,  0.3531],\n",
      "        [ 0.5629,  0.3030],\n",
      "        [ 0.0726,  0.1945],\n",
      "        [ 0.5367,  0.3126]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6675, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5165, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1841, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1841, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|▉                                                                      | 3/219 [00:28<33:56,  9.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.2232, -0.3017],\n",
      "        [ 0.5716, -0.0969],\n",
      "        [ 0.4495, -0.6064],\n",
      "        [ 0.1446, -0.2688],\n",
      "        [ 0.7431, -0.4017],\n",
      "        [ 0.1721, -0.2256],\n",
      "        [ 0.4330, -0.5504],\n",
      "        [ 0.1752, -0.5817],\n",
      "        [ 0.6330, -0.5571],\n",
      "        [ 0.5975, -0.6782],\n",
      "        [ 0.3070, -0.3193],\n",
      "        [ 0.4973, -0.2868],\n",
      "        [ 0.4942, -0.3096],\n",
      "        [ 0.3527, -0.1628],\n",
      "        [ 0.5468, -0.2571],\n",
      "        [ 0.2942, -0.4337],\n",
      "        [ 0.6330, -0.0848],\n",
      "        [ 0.4515, -0.5876],\n",
      "        [ 0.2239, -0.2595],\n",
      "        [ 0.2511, -0.3209],\n",
      "        [ 0.6797, -0.2210],\n",
      "        [ 0.6368, -0.0530],\n",
      "        [ 0.2984, -0.2194],\n",
      "        [ 0.2375, -0.3584],\n",
      "        [ 0.4378, -0.2186],\n",
      "        [ 0.3606, -0.4024],\n",
      "        [ 0.3854, -0.2471],\n",
      "        [ 0.4838, -0.4859],\n",
      "        [ 0.3356, -0.3728],\n",
      "        [ 0.4127, -0.3928],\n",
      "        [ 0.0291, -0.4703],\n",
      "        [ 0.4111, -0.5665]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.2085,  0.1595],\n",
      "        [ 0.2480,  0.3805],\n",
      "        [ 0.1660,  0.2372],\n",
      "        [ 0.4433,  0.3398],\n",
      "        [ 0.4361,  0.3135],\n",
      "        [ 0.4147,  0.2863],\n",
      "        [ 0.6520,  0.1450],\n",
      "        [ 0.1279,  0.4419],\n",
      "        [ 0.0256,  0.6306],\n",
      "        [ 0.6685,  0.3276],\n",
      "        [ 0.3712,  0.1507],\n",
      "        [ 0.5597,  0.7046],\n",
      "        [ 0.2244,  0.2005],\n",
      "        [ 0.2999,  0.3666],\n",
      "        [ 0.4097,  0.2419],\n",
      "        [ 0.0874,  0.3001],\n",
      "        [ 0.4671,  0.2991],\n",
      "        [ 0.1405,  0.2660],\n",
      "        [ 0.5237,  0.3737],\n",
      "        [ 0.2156,  0.4538],\n",
      "        [ 0.4902,  0.1849],\n",
      "        [-0.3944,  0.1056],\n",
      "        [ 0.2314,  0.1626],\n",
      "        [ 0.3574, -0.0631],\n",
      "        [ 0.5053,  0.2614],\n",
      "        [ 0.3504,  0.1925],\n",
      "        [ 0.8316,  0.3239],\n",
      "        [ 0.3901,  0.4738],\n",
      "        [ 0.3399,  0.4905],\n",
      "        [ 0.2789,  0.3835],\n",
      "        [ 0.2265,  0.4098],\n",
      "        [ 0.4254,  0.2924]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7571, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4623, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2193, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2193, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|█▎                                                                     | 4/219 [00:37<33:58,  9.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.3497, -0.2489],\n",
      "        [ 0.1286, -0.3845],\n",
      "        [ 0.0483, -0.4237],\n",
      "        [ 0.1843, -0.3474],\n",
      "        [ 0.3070, -0.2055],\n",
      "        [-0.0059, -0.4622],\n",
      "        [ 0.2492, -0.3847],\n",
      "        [ 0.0783, -0.4114],\n",
      "        [ 0.2072, -0.0573],\n",
      "        [ 0.2911, -0.5850],\n",
      "        [ 0.3016, -0.3598],\n",
      "        [ 0.2204, -0.4052],\n",
      "        [ 0.2595, -0.4033],\n",
      "        [ 0.4887, -0.0927],\n",
      "        [ 0.1803, -0.3817],\n",
      "        [ 0.3734, -0.4137],\n",
      "        [ 0.3098, -0.0546],\n",
      "        [ 0.3612, -0.4234],\n",
      "        [ 0.3704,  0.0611],\n",
      "        [ 0.3971, -0.2868],\n",
      "        [-0.1385, -0.4728],\n",
      "        [ 0.3066, -0.2742],\n",
      "        [ 0.5722, -0.1028],\n",
      "        [ 0.3947, -0.3526],\n",
      "        [ 0.2087, -0.2425],\n",
      "        [ 0.4621, -0.4501],\n",
      "        [ 0.2849, -0.4669],\n",
      "        [ 0.1212, -0.3620],\n",
      "        [ 0.1853, -0.3628],\n",
      "        [ 0.2952, -0.2509],\n",
      "        [ 0.2584, -0.3211],\n",
      "        [ 0.5079, -0.1106]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[0.4358, 0.4468],\n",
      "        [0.4012, 0.2469],\n",
      "        [0.3840, 0.2190],\n",
      "        [0.3982, 0.2263],\n",
      "        [0.2111, 0.2270],\n",
      "        [0.4058, 0.3225],\n",
      "        [0.4066, 0.6018],\n",
      "        [0.1027, 0.0659],\n",
      "        [0.2428, 0.0986],\n",
      "        [0.3861, 0.2189],\n",
      "        [0.6145, 0.1758],\n",
      "        [0.1394, 0.1842],\n",
      "        [0.2246, 0.5043],\n",
      "        [0.2176, 0.3854],\n",
      "        [0.0827, 0.4312],\n",
      "        [0.3281, 0.3978],\n",
      "        [0.5207, 0.1167],\n",
      "        [0.0897, 0.1206],\n",
      "        [0.4326, 0.0522],\n",
      "        [0.2813, 0.5980],\n",
      "        [0.1542, 0.0551],\n",
      "        [0.2568, 0.1837],\n",
      "        [0.5966, 0.4089],\n",
      "        [0.4523, 0.2953],\n",
      "        [0.0350, 0.2860],\n",
      "        [0.3789, 0.2852],\n",
      "        [0.4170, 0.0817],\n",
      "        [0.3547, 0.2204],\n",
      "        [0.3690, 0.4848],\n",
      "        [0.5039, 0.2549],\n",
      "        [0.5878, 0.0455],\n",
      "        [0.5976, 0.2923]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7174, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4052, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1226, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1226, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|█▌                                                                     | 5/219 [00:47<34:12,  9.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1796, -0.4358],\n",
      "        [ 0.2470, -0.1013],\n",
      "        [ 0.0637, -0.3381],\n",
      "        [ 0.3035, -0.2588],\n",
      "        [ 0.1963, -0.1963],\n",
      "        [ 0.3037, -0.6536],\n",
      "        [ 0.2360, -0.6463],\n",
      "        [ 0.2410, -0.1980],\n",
      "        [ 0.2268, -0.2517],\n",
      "        [ 0.0022, -0.5125],\n",
      "        [ 0.3687, -0.7542],\n",
      "        [ 0.0823, -0.5200],\n",
      "        [ 0.4700, -0.0415],\n",
      "        [ 0.6861, -0.4341],\n",
      "        [ 0.2054, -0.4950],\n",
      "        [ 0.3267, -0.2946],\n",
      "        [ 0.1963, -0.0597],\n",
      "        [ 0.4406, -0.2801],\n",
      "        [ 0.3902, -0.5139],\n",
      "        [ 0.0846, -0.3891],\n",
      "        [-0.0286, -0.4019],\n",
      "        [ 0.1121, -0.2087],\n",
      "        [ 0.1619, -0.2576],\n",
      "        [ 0.5357, -0.2119],\n",
      "        [ 0.0067, -0.0784],\n",
      "        [ 0.3902, -0.2492],\n",
      "        [ 0.3862, -0.3352],\n",
      "        [ 0.2650, -0.0980],\n",
      "        [ 0.3060, -0.3500],\n",
      "        [ 0.1995, -0.5375],\n",
      "        [ 0.4095, -0.3446],\n",
      "        [ 0.1447, -0.0550]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.1427,  0.4211],\n",
      "        [ 0.2633,  0.2063],\n",
      "        [ 0.3830,  0.4002],\n",
      "        [ 0.3774,  0.2423],\n",
      "        [ 0.3197,  0.2922],\n",
      "        [ 0.6632,  0.1920],\n",
      "        [ 0.3472,  0.3684],\n",
      "        [ 0.4536,  0.4704],\n",
      "        [ 0.2483,  0.2642],\n",
      "        [ 0.4123,  0.0987],\n",
      "        [-0.0154,  0.2251],\n",
      "        [ 0.3971,  0.4105],\n",
      "        [ 0.2928,  0.3726],\n",
      "        [ 0.2427,  0.3607],\n",
      "        [ 0.1845,  0.3526],\n",
      "        [ 0.4058,  0.2612],\n",
      "        [ 0.1441,  0.2058],\n",
      "        [-0.0820,  0.0566],\n",
      "        [ 0.3807,  0.3855],\n",
      "        [ 0.1539,  0.5366],\n",
      "        [ 0.5338,  0.3792],\n",
      "        [ 0.6536,  0.2509],\n",
      "        [ 0.3070, -0.0076],\n",
      "        [ 0.5270,  0.3927],\n",
      "        [ 0.0587,  0.3339],\n",
      "        [ 0.2352,  0.5810],\n",
      "        [ 0.4511,  0.6419],\n",
      "        [ 0.0614,  0.4223],\n",
      "        [ 0.4902,  0.3079],\n",
      "        [ 0.7136,  0.2907],\n",
      "        [ 0.4947,  0.0134],\n",
      "        [ 0.3597,  0.1804]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6314, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5072, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1387, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1387, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|█▉                                                                     | 6/219 [00:57<34:22,  9.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1521, -0.3112],\n",
      "        [ 0.5923, -0.1229],\n",
      "        [-0.0743, -0.0750],\n",
      "        [ 0.2238, -0.0242],\n",
      "        [ 0.3642, -0.4269],\n",
      "        [ 0.3735, -0.1890],\n",
      "        [-0.0261, -0.1016],\n",
      "        [ 0.2835, -0.0707],\n",
      "        [ 0.2997, -0.2698],\n",
      "        [ 0.3732,  0.0953],\n",
      "        [ 0.2624, -0.0997],\n",
      "        [ 0.2254, -0.0952],\n",
      "        [ 0.4500, -0.1622],\n",
      "        [ 0.4022, -0.2065],\n",
      "        [ 0.3066, -0.2726],\n",
      "        [ 0.2421, -0.3768],\n",
      "        [ 0.2363, -0.2217],\n",
      "        [ 0.2138, -0.2922],\n",
      "        [ 0.3478,  0.0079],\n",
      "        [ 0.0654, -0.0527],\n",
      "        [ 0.1872, -0.3062],\n",
      "        [ 0.3532,  0.0510],\n",
      "        [-0.0689, -0.2578],\n",
      "        [ 0.3705, -0.1380],\n",
      "        [ 0.1950, -0.3916],\n",
      "        [-0.1305,  0.0123],\n",
      "        [ 0.4862, -0.2935],\n",
      "        [ 0.1593, -0.2112],\n",
      "        [ 0.1917, -0.4139],\n",
      "        [ 0.1530, -0.2047],\n",
      "        [ 0.1652, -0.0824],\n",
      "        [ 0.4684, -0.1423]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[3.6087e-01, 2.8901e-01],\n",
      "        [2.8201e-01, 3.0014e-01],\n",
      "        [2.5209e-01, 2.8864e-01],\n",
      "        [2.1146e-01, 1.7279e-01],\n",
      "        [3.1390e-01, 6.7603e-03],\n",
      "        [7.2854e-02, 8.9039e-02],\n",
      "        [4.7077e-01, 4.0606e-01],\n",
      "        [3.7354e-01, 2.0937e-01],\n",
      "        [3.6061e-01, 1.8998e-01],\n",
      "        [4.4855e-01, 3.8962e-01],\n",
      "        [5.5731e-01, 9.9659e-05],\n",
      "        [3.0844e-01, 4.0398e-01],\n",
      "        [3.0431e-01, 3.5393e-01],\n",
      "        [2.2568e-01, 4.3945e-01],\n",
      "        [4.4261e-01, 1.5130e-01],\n",
      "        [3.3257e-01, 4.5147e-01],\n",
      "        [3.3896e-01, 2.8669e-01],\n",
      "        [4.6366e-01, 1.2325e-01],\n",
      "        [3.3066e-01, 1.3739e-01],\n",
      "        [1.2456e-02, 2.9139e-01],\n",
      "        [3.7100e-01, 3.6432e-01],\n",
      "        [4.3265e-01, 4.5926e-01],\n",
      "        [2.3573e-01, 4.0949e-01],\n",
      "        [4.9933e-01, 3.5209e-01],\n",
      "        [3.3948e-01, 1.4891e-01],\n",
      "        [2.3954e-01, 3.5651e-01],\n",
      "        [4.6575e-01, 2.8652e-01],\n",
      "        [1.0904e-01, 1.6383e-01],\n",
      "        [2.7902e-01, 6.8032e-01],\n",
      "        [9.0722e-02, 1.9692e-01],\n",
      "        [4.9747e-01, 5.8771e-01],\n",
      "        [4.4370e-01, 1.9270e-01]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7820, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.3888, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1707, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1707, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|██▎                                                                    | 7/219 [01:07<34:09,  9.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.3984, -0.2806],\n",
      "        [ 0.1316, -0.4878],\n",
      "        [ 0.0967,  0.0716],\n",
      "        [ 0.1337, -0.3171],\n",
      "        [ 0.0769, -0.4170],\n",
      "        [ 0.0636, -0.1809],\n",
      "        [ 0.0824, -0.1961],\n",
      "        [ 0.1810, -0.3069],\n",
      "        [ 0.1990, -0.7707],\n",
      "        [ 0.3488, -0.2599],\n",
      "        [-0.0736, -0.4698],\n",
      "        [-0.1559, -0.3478],\n",
      "        [ 0.2011, -0.2997],\n",
      "        [ 0.0074, -0.5215],\n",
      "        [ 0.1775, -0.2497],\n",
      "        [ 0.3910, -0.2160],\n",
      "        [ 0.1578, -0.3523],\n",
      "        [ 0.1758, -0.3248],\n",
      "        [ 0.1891, -0.3644],\n",
      "        [ 0.2662, -0.2306],\n",
      "        [ 0.0731, -0.1742],\n",
      "        [ 0.1668, -0.1728],\n",
      "        [ 0.2991, -0.0952],\n",
      "        [ 0.1264,  0.0566],\n",
      "        [ 0.5530, -0.1885],\n",
      "        [ 0.2578, -0.2855],\n",
      "        [ 0.3505, -0.3731],\n",
      "        [ 0.1081, -0.1726],\n",
      "        [ 0.2690, -0.3105],\n",
      "        [ 0.3604, -0.3020],\n",
      "        [ 0.4171, -0.1719],\n",
      "        [-0.0212,  0.0247]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.5545,  0.4331],\n",
      "        [-0.0806,  0.2559],\n",
      "        [ 0.5781,  0.1965],\n",
      "        [ 0.4159,  0.0415],\n",
      "        [ 0.1657,  0.3023],\n",
      "        [ 0.2089,  0.3594],\n",
      "        [-0.1263,  0.3506],\n",
      "        [ 0.4976,  0.3890],\n",
      "        [ 0.3538,  0.1850],\n",
      "        [ 0.3901,  0.1247],\n",
      "        [ 0.1951,  0.2744],\n",
      "        [ 0.1515,  0.3159],\n",
      "        [ 0.2365,  0.0940],\n",
      "        [ 0.5513,  0.2325],\n",
      "        [ 0.1703,  0.6133],\n",
      "        [ 0.3410,  0.2317],\n",
      "        [ 0.0242,  0.3439],\n",
      "        [ 0.2737,  0.3963],\n",
      "        [ 0.3471,  0.1498],\n",
      "        [ 0.4133,  0.1458],\n",
      "        [ 0.5496,  0.2488],\n",
      "        [ 0.0823,  0.5564],\n",
      "        [ 0.5014,  0.2231],\n",
      "        [ 0.0780,  0.3105],\n",
      "        [ 0.2523,  0.2038],\n",
      "        [ 0.3385,  0.3570],\n",
      "        [-0.1313,  0.4001],\n",
      "        [ 0.2272,  0.3547],\n",
      "        [ 0.5086,  0.2364],\n",
      "        [ 0.4659,  0.1059],\n",
      "        [ 0.4673,  0.2017],\n",
      "        [ 0.3129,  0.4229]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7559, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5225, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2784, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2784, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   4%|██▌                                                                    | 8/219 [01:17<33:59,  9.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.4387, -0.2871],\n",
      "        [ 0.0436, -0.0539],\n",
      "        [ 0.2396,  0.0981],\n",
      "        [-0.0044, -0.1927],\n",
      "        [ 0.2125, -0.0037],\n",
      "        [ 0.0776,  0.0505],\n",
      "        [ 0.1815, -0.0362],\n",
      "        [ 0.0098, -0.3272],\n",
      "        [ 0.0523, -0.0380],\n",
      "        [-0.1383, -0.2532],\n",
      "        [ 0.0588, -0.2094],\n",
      "        [-0.0831, -0.0674],\n",
      "        [ 0.1968, -0.1385],\n",
      "        [ 0.2209, -0.0843],\n",
      "        [-0.0450, -0.1748],\n",
      "        [ 0.2376, -0.2452],\n",
      "        [ 0.1368, -0.2665],\n",
      "        [ 0.3117, -0.3318],\n",
      "        [ 0.4907, -0.3625],\n",
      "        [ 0.2018, -0.0067],\n",
      "        [ 0.0612, -0.0500],\n",
      "        [-0.0205, -0.3537],\n",
      "        [ 0.1557,  0.1059],\n",
      "        [ 0.0327, -0.0937],\n",
      "        [ 0.1913, -0.0221],\n",
      "        [ 0.1137, -0.0931],\n",
      "        [ 0.1106, -0.0556],\n",
      "        [ 0.0430, -0.2491],\n",
      "        [ 0.0451, -0.1846],\n",
      "        [ 0.6476, -0.0759],\n",
      "        [ 0.0701,  0.0164],\n",
      "        [ 0.1971, -0.0526]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.2248,  0.0162],\n",
      "        [ 0.1399,  0.2087],\n",
      "        [ 0.2773,  0.1433],\n",
      "        [ 0.4530,  0.2827],\n",
      "        [ 0.3345,  0.2971],\n",
      "        [ 0.1846,  0.2173],\n",
      "        [ 0.3375,  0.2613],\n",
      "        [ 0.4390,  0.3102],\n",
      "        [ 0.6888,  0.2265],\n",
      "        [ 0.5200, -0.0754],\n",
      "        [ 0.1886,  0.4461],\n",
      "        [ 0.4512,  0.4711],\n",
      "        [ 0.2167,  0.5302],\n",
      "        [ 0.3816,  0.3870],\n",
      "        [ 0.0062,  0.0528],\n",
      "        [ 0.1399,  0.1772],\n",
      "        [ 0.0260, -0.0229],\n",
      "        [ 0.0163,  0.4277],\n",
      "        [ 0.3145,  0.3531],\n",
      "        [ 0.5607,  0.6099],\n",
      "        [ 0.1222,  0.1609],\n",
      "        [ 0.7452,  0.2172],\n",
      "        [ 0.2323,  0.0398],\n",
      "        [ 0.2231,  0.1767],\n",
      "        [ 0.2249,  0.3481],\n",
      "        [-0.1542,  0.2985],\n",
      "        [ 0.4672,  0.2834],\n",
      "        [ 0.1094,  0.3634],\n",
      "        [ 0.5288,  0.2119],\n",
      "        [-0.3049, -0.0433],\n",
      "        [ 0.2552,  0.2516],\n",
      "        [ 0.3545,  0.4347]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7659, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5757, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.3416, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.3416, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   4%|██▉                                                                    | 9/219 [01:26<33:47,  9.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-1.6224e-01, -5.3025e-02],\n",
      "        [-1.5118e-01,  2.2678e-02],\n",
      "        [-3.0436e-02, -1.7338e-01],\n",
      "        [ 1.2806e-01, -7.7034e-02],\n",
      "        [ 1.5586e-01,  3.5663e-01],\n",
      "        [ 2.1422e-01,  5.5212e-02],\n",
      "        [ 3.1246e-01, -1.5453e-01],\n",
      "        [ 1.6862e-04, -1.7275e-01],\n",
      "        [ 2.1618e-02, -1.1787e-01],\n",
      "        [ 2.2923e-01, -9.0570e-02],\n",
      "        [ 2.0138e-01, -1.2815e-01],\n",
      "        [ 2.4567e-01,  8.2065e-02],\n",
      "        [ 3.2837e-02, -2.3818e-01],\n",
      "        [ 7.3116e-02, -4.0607e-01],\n",
      "        [-1.1445e-02, -3.6095e-01],\n",
      "        [ 1.1887e-01, -2.0714e-01],\n",
      "        [ 5.0366e-02, -4.2891e-02],\n",
      "        [-7.0396e-02, -8.3686e-03],\n",
      "        [-1.1124e-01,  8.4857e-03],\n",
      "        [ 1.9955e-01, -1.4722e-01],\n",
      "        [ 1.1320e-01, -2.2394e-01],\n",
      "        [ 2.7276e-01,  7.9690e-02],\n",
      "        [ 4.6701e-01, -1.5741e-01],\n",
      "        [-1.5843e-02, -1.6898e-01],\n",
      "        [ 1.1342e-01, -1.4064e-01],\n",
      "        [ 1.5737e-01,  9.9224e-02],\n",
      "        [-2.9736e-02, -1.1967e-01],\n",
      "        [-2.8190e-01, -3.4852e-01],\n",
      "        [ 9.2790e-02, -7.9201e-02],\n",
      "        [ 2.7252e-01, -2.8621e-01],\n",
      "        [-1.4855e-01, -2.9693e-01],\n",
      "        [ 3.2826e-02, -3.2983e-01]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.1433,  0.1951],\n",
      "        [ 0.3117,  0.0360],\n",
      "        [ 0.2761,  0.3146],\n",
      "        [ 0.3714,  0.3196],\n",
      "        [ 0.5952,  0.1661],\n",
      "        [ 0.0560,  0.1613],\n",
      "        [ 0.3167,  0.2878],\n",
      "        [ 0.6492,  0.3046],\n",
      "        [ 0.3820,  0.3772],\n",
      "        [ 0.3578,  0.2526],\n",
      "        [-0.1832,  0.0792],\n",
      "        [-0.0620,  0.1813],\n",
      "        [ 0.1197,  0.2880],\n",
      "        [ 0.4881,  0.1176],\n",
      "        [ 0.1856,  0.0008],\n",
      "        [-0.0826,  0.1002],\n",
      "        [ 0.2294, -0.0899],\n",
      "        [ 0.2978,  0.3488],\n",
      "        [ 0.1905,  0.2158],\n",
      "        [ 0.2202,  0.3439],\n",
      "        [ 0.2320,  0.2111],\n",
      "        [-0.0501,  0.1306],\n",
      "        [ 0.6144,  0.2897],\n",
      "        [ 0.4495,  0.2342],\n",
      "        [ 0.1979,  0.5307],\n",
      "        [ 0.3849,  0.0361],\n",
      "        [ 0.4224,  0.2617],\n",
      "        [ 0.2902,  0.2082],\n",
      "        [-0.0329,  0.1968],\n",
      "        [-0.1103, -0.0380],\n",
      "        [ 0.4616,  0.1288],\n",
      "        [ 0.4001,  0.1640]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6986, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4535, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1521, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1521, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   5%|███▏                                                                  | 10/219 [01:36<33:34,  9.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0899,  0.1176],\n",
      "        [ 0.3955, -0.0194],\n",
      "        [-0.0004, -0.0496],\n",
      "        [ 0.1174, -0.0586],\n",
      "        [ 0.3711,  0.0288],\n",
      "        [-0.0234, -0.2060],\n",
      "        [ 0.0686, -0.2227],\n",
      "        [-0.0116,  0.1484],\n",
      "        [-0.0800,  0.1044],\n",
      "        [-0.1483, -0.0470],\n",
      "        [ 0.1473, -0.0466],\n",
      "        [-0.2522,  0.0362],\n",
      "        [ 0.2651, -0.0204],\n",
      "        [ 0.2155, -0.0850],\n",
      "        [ 0.1778, -0.1743],\n",
      "        [ 0.1832,  0.0961],\n",
      "        [-0.2174, -0.0486],\n",
      "        [-0.0214, -0.2343],\n",
      "        [-0.1850,  0.1645],\n",
      "        [ 0.1254, -0.1699],\n",
      "        [-0.0885,  0.0927],\n",
      "        [-0.0437,  0.1076],\n",
      "        [ 0.1289, -0.0444],\n",
      "        [ 0.3336, -0.1739],\n",
      "        [ 0.1352,  0.0926],\n",
      "        [-0.3273, -0.0844],\n",
      "        [-0.0474, -0.0807],\n",
      "        [-0.2965,  0.0476],\n",
      "        [-0.0969, -0.2650],\n",
      "        [-0.1977, -0.3572],\n",
      "        [ 0.1485,  0.1694],\n",
      "        [-0.0133, -0.0744]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.4710,  0.1152],\n",
      "        [ 0.3588,  0.2138],\n",
      "        [ 0.2223,  0.3208],\n",
      "        [ 0.7364,  0.2049],\n",
      "        [ 0.0530,  0.1899],\n",
      "        [ 0.3527,  0.3399],\n",
      "        [ 0.3224,  0.1447],\n",
      "        [ 0.3928,  0.1349],\n",
      "        [ 0.5677,  0.1780],\n",
      "        [ 0.3122,  0.1815],\n",
      "        [ 0.0468,  0.0275],\n",
      "        [ 0.3739,  0.0638],\n",
      "        [-0.1423,  0.0290],\n",
      "        [ 0.5273,  0.2440],\n",
      "        [ 0.3890,  0.3742],\n",
      "        [ 0.3684,  0.0447],\n",
      "        [ 0.2544,  0.3438],\n",
      "        [ 0.4587,  0.0202],\n",
      "        [ 0.3946,  0.2344],\n",
      "        [-0.1395,  0.3326],\n",
      "        [ 0.1131,  0.1403],\n",
      "        [ 0.4613,  0.2690],\n",
      "        [-0.1124,  0.2476],\n",
      "        [ 0.0027, -0.1222],\n",
      "        [-0.0948, -0.1054],\n",
      "        [ 0.2446,  0.3546],\n",
      "        [ 0.0072,  0.1599],\n",
      "        [-0.1127,  0.1887],\n",
      "        [ 0.5925,  0.2948],\n",
      "        [ 0.2899,  0.2876],\n",
      "        [-0.0082,  0.1859],\n",
      "        [ 0.3894,  0.1066]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6982, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4688, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1669, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1669, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   5%|███▌                                                                  | 11/219 [01:45<33:27,  9.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0503,  0.0405],\n",
      "        [-0.1369, -0.1958],\n",
      "        [-0.2660, -0.1581],\n",
      "        [-0.0086,  0.0773],\n",
      "        [-0.0792,  0.1753],\n",
      "        [-0.2007, -0.0174],\n",
      "        [-0.0967,  0.0295],\n",
      "        [ 0.0485,  0.1455],\n",
      "        [-0.0466,  0.0160],\n",
      "        [ 0.2146,  0.1414],\n",
      "        [ 0.0357,  0.0662],\n",
      "        [-0.1250, -0.2008],\n",
      "        [ 0.2777,  0.0665],\n",
      "        [ 0.0080,  0.0567],\n",
      "        [ 0.1677,  0.0314],\n",
      "        [ 0.0145,  0.2466],\n",
      "        [-0.1427, -0.1096],\n",
      "        [-0.0487,  0.0861],\n",
      "        [-0.2279,  0.1468],\n",
      "        [ 0.3398,  0.1674],\n",
      "        [-0.0164, -0.1252],\n",
      "        [-0.1759,  0.0782],\n",
      "        [-0.1520,  0.1807],\n",
      "        [-0.0357, -0.1428],\n",
      "        [-0.1614, -0.1402],\n",
      "        [-0.1717,  0.0074],\n",
      "        [ 0.2171, -0.0085],\n",
      "        [-0.1598,  0.0974],\n",
      "        [ 0.4350,  0.3391],\n",
      "        [ 0.0029, -0.1318],\n",
      "        [-0.1017,  0.0191],\n",
      "        [ 0.1414, -0.1264]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.0179,  0.0588],\n",
      "        [ 0.3556,  0.0602],\n",
      "        [ 0.2931,  0.2465],\n",
      "        [-0.0554,  0.1167],\n",
      "        [ 0.5054,  0.2551],\n",
      "        [ 0.6249,  0.1459],\n",
      "        [ 0.0573,  0.3096],\n",
      "        [ 0.2969,  0.2623],\n",
      "        [ 0.4702,  0.0036],\n",
      "        [ 0.2405, -0.0130],\n",
      "        [ 0.3231,  0.0955],\n",
      "        [ 0.3182,  0.1801],\n",
      "        [ 0.2147,  0.1626],\n",
      "        [ 0.5587,  0.0178],\n",
      "        [-0.1283,  0.1171],\n",
      "        [ 0.1051, -0.1684],\n",
      "        [ 0.2028,  0.2030],\n",
      "        [ 0.1033,  0.2572],\n",
      "        [ 0.0232,  0.2324],\n",
      "        [ 0.2714,  0.1602],\n",
      "        [ 0.3724, -0.0373],\n",
      "        [ 0.2121,  0.2096],\n",
      "        [ 0.1000,  0.2128],\n",
      "        [ 0.1014,  0.5632],\n",
      "        [ 0.0568,  0.2861],\n",
      "        [ 0.1816,  0.2860],\n",
      "        [ 0.0547,  0.1295],\n",
      "        [ 0.2401,  0.1118],\n",
      "        [-0.3045, -0.2505],\n",
      "        [ 0.2303,  0.3155],\n",
      "        [ 0.5065,  0.3493],\n",
      "        [ 0.2228,  0.2392]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6879, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4871, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1751, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1751, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   5%|███▊                                                                  | 12/219 [01:55<33:18,  9.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0336, -0.1445],\n",
      "        [-0.0502, -0.0084],\n",
      "        [ 0.0243,  0.3733],\n",
      "        [-0.0957,  0.2088],\n",
      "        [-0.3372,  0.2594],\n",
      "        [-0.1968, -0.0223],\n",
      "        [-0.2900,  0.0865],\n",
      "        [ 0.1162,  0.1523],\n",
      "        [-0.1411, -0.0826],\n",
      "        [-0.3521, -0.0428],\n",
      "        [-0.0192,  0.0365],\n",
      "        [ 0.2697, -0.1419],\n",
      "        [-0.0489,  0.1031],\n",
      "        [-0.2154, -0.1450],\n",
      "        [-0.0687,  0.0016],\n",
      "        [ 0.0957, -0.0243],\n",
      "        [-0.1931, -0.1485],\n",
      "        [ 0.1213,  0.2894],\n",
      "        [-0.2112,  0.3550],\n",
      "        [ 0.0158,  0.1003],\n",
      "        [ 0.1181, -0.2291],\n",
      "        [-0.1913,  0.1469],\n",
      "        [-0.2503,  0.2715],\n",
      "        [ 0.2076,  0.0161],\n",
      "        [-0.0796, -0.1695],\n",
      "        [-0.1774,  0.1620],\n",
      "        [ 0.2469,  0.1323],\n",
      "        [-0.3305, -0.0658],\n",
      "        [ 0.0684,  0.0125],\n",
      "        [ 0.0985, -0.2666],\n",
      "        [ 0.0321, -0.0395],\n",
      "        [ 0.2242, -0.2247]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.2243,  0.1415],\n",
      "        [-0.0652,  0.0883],\n",
      "        [ 0.0971,  0.3096],\n",
      "        [ 0.3082,  0.1564],\n",
      "        [ 0.1690,  0.3040],\n",
      "        [ 0.2565,  0.1959],\n",
      "        [ 0.2687,  0.1212],\n",
      "        [ 0.2575,  0.2770],\n",
      "        [ 0.0542,  0.0441],\n",
      "        [ 0.2514,  0.2656],\n",
      "        [ 0.5003,  0.1786],\n",
      "        [ 0.0400,  0.0692],\n",
      "        [ 0.4893,  0.1895],\n",
      "        [ 0.2968,  0.0967],\n",
      "        [ 0.2222,  0.2175],\n",
      "        [ 0.0080, -0.3488],\n",
      "        [ 0.4246, -0.0598],\n",
      "        [-0.0277, -0.0789],\n",
      "        [ 0.3215,  0.0044],\n",
      "        [ 0.0311, -0.1319],\n",
      "        [-0.0661, -0.1777],\n",
      "        [ 0.0883,  0.3257],\n",
      "        [ 0.2201,  0.3042],\n",
      "        [-0.0879, -0.3605],\n",
      "        [ 0.2620,  0.0627],\n",
      "        [ 0.5209,  0.0071],\n",
      "        [ 0.3402,  0.2845],\n",
      "        [ 0.2541,  0.0493],\n",
      "        [ 0.1668,  0.1994],\n",
      "        [ 0.3382,  0.3921],\n",
      "        [ 0.3379,  0.1981],\n",
      "        [-0.0412, -0.1965]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6683, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5542, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2225, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2225, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|████▏                                                                 | 13/219 [02:05<33:07,  9.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1786,  0.3741],\n",
      "        [-0.1469, -0.0361],\n",
      "        [-0.1013,  0.0909],\n",
      "        [-0.0431,  0.1080],\n",
      "        [-0.0354, -0.1862],\n",
      "        [-0.1096,  0.1805],\n",
      "        [-0.5520,  0.1265],\n",
      "        [-0.0553,  0.0181],\n",
      "        [ 0.0074,  0.1258],\n",
      "        [ 0.2276, -0.0323],\n",
      "        [-0.2692,  0.3922],\n",
      "        [-0.1565, -0.0620],\n",
      "        [ 0.0522,  0.1104],\n",
      "        [ 0.1162,  0.2660],\n",
      "        [-0.1507, -0.3342],\n",
      "        [ 0.3549,  0.2157],\n",
      "        [ 0.0279, -0.1134],\n",
      "        [ 0.0313, -0.2186],\n",
      "        [-0.2813,  0.1620],\n",
      "        [-0.2610, -0.0853],\n",
      "        [ 0.1183,  0.2293],\n",
      "        [-0.0374, -0.1367],\n",
      "        [-0.0920,  0.2467],\n",
      "        [-0.1087,  0.2904],\n",
      "        [ 0.1819, -0.0135],\n",
      "        [-0.1661,  0.0536],\n",
      "        [-0.0880, -0.0799],\n",
      "        [ 0.1998,  0.0204],\n",
      "        [ 0.2688,  0.1596],\n",
      "        [-0.1222,  0.1572],\n",
      "        [ 0.0925,  0.2101],\n",
      "        [-0.1796, -0.0950]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 3.9472e-01,  3.1282e-01],\n",
      "        [ 3.9319e-01,  1.4409e-01],\n",
      "        [ 3.0991e-03,  2.7705e-02],\n",
      "        [ 6.6829e-02,  2.3710e-01],\n",
      "        [ 2.4679e-01,  4.3112e-01],\n",
      "        [ 4.4758e-01,  2.9359e-01],\n",
      "        [ 2.3167e-01,  2.3417e-01],\n",
      "        [ 4.5027e-01,  2.9178e-01],\n",
      "        [ 2.6336e-01,  4.1020e-01],\n",
      "        [-7.7781e-02, -3.1861e-01],\n",
      "        [ 1.7867e-01,  1.8480e-01],\n",
      "        [ 2.6629e-01,  3.3503e-01],\n",
      "        [ 3.3303e-01,  2.6242e-01],\n",
      "        [ 4.4255e-01,  1.1707e-01],\n",
      "        [ 4.0273e-01,  3.2831e-01],\n",
      "        [ 4.9807e-02, -1.8226e-01],\n",
      "        [ 4.8829e-01,  3.7154e-01],\n",
      "        [ 5.0154e-01, -2.5361e-02],\n",
      "        [ 2.0415e-01,  2.0326e-01],\n",
      "        [ 3.5263e-01,  2.6138e-02],\n",
      "        [ 2.6064e-02,  2.7536e-02],\n",
      "        [ 3.3571e-01,  3.8694e-01],\n",
      "        [ 3.8686e-01, -5.0753e-05],\n",
      "        [ 7.7559e-02,  2.7055e-01],\n",
      "        [-1.5475e-01, -1.1345e-01],\n",
      "        [ 1.3816e-01, -3.8290e-02],\n",
      "        [ 1.9618e-01, -3.1389e-01],\n",
      "        [ 1.3817e-01,  1.2857e-01],\n",
      "        [-2.5642e-01, -3.0086e-01],\n",
      "        [ 4.6576e-02,  2.0779e-01],\n",
      "        [ 1.4520e-01,  1.5186e-01],\n",
      "        [ 7.3511e-01,  3.4320e-01]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7070, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5077, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2147, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2147, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|████▍                                                                 | 14/219 [02:14<33:03,  9.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0033,  0.1157],\n",
      "        [-0.2754,  0.2748],\n",
      "        [ 0.1202, -0.0861],\n",
      "        [ 0.3045, -0.2546],\n",
      "        [ 0.0313,  0.3767],\n",
      "        [ 0.2387, -0.0715],\n",
      "        [-0.2391,  0.1412],\n",
      "        [-0.4607,  0.4885],\n",
      "        [-0.0120,  0.2686],\n",
      "        [-0.0639,  0.3441],\n",
      "        [-0.0587,  0.0730],\n",
      "        [-0.3376,  0.0178],\n",
      "        [ 0.0853,  0.2428],\n",
      "        [ 0.1746, -0.0332],\n",
      "        [-0.0755,  0.2429],\n",
      "        [-0.1422,  0.0188],\n",
      "        [-0.2961,  0.4013],\n",
      "        [-0.1773,  0.2433],\n",
      "        [ 0.1251,  0.0390],\n",
      "        [-0.2500,  0.1054],\n",
      "        [ 0.0481,  0.0522],\n",
      "        [-0.2167,  0.2642],\n",
      "        [-0.2787,  0.1103],\n",
      "        [ 0.0875,  0.0427],\n",
      "        [-0.1712,  0.0428],\n",
      "        [ 0.0649, -0.0042],\n",
      "        [-0.3380, -0.0119],\n",
      "        [ 0.0024,  0.1539],\n",
      "        [-0.0156,  0.0823],\n",
      "        [-0.4918,  0.1818],\n",
      "        [-0.1756, -0.0353],\n",
      "        [ 0.0295,  0.3312]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.2811,  0.0317],\n",
      "        [ 0.3177, -0.0113],\n",
      "        [ 0.0886,  0.0914],\n",
      "        [ 0.1014, -0.0530],\n",
      "        [-0.0147,  0.3301],\n",
      "        [-0.0746, -0.1601],\n",
      "        [ 0.0291,  0.1714],\n",
      "        [ 0.1458,  0.2859],\n",
      "        [ 0.2572, -0.0644],\n",
      "        [-0.0144, -0.0731],\n",
      "        [ 0.0262,  0.0034],\n",
      "        [ 0.1096, -0.0176],\n",
      "        [ 0.1745, -0.0411],\n",
      "        [-0.0511,  0.0042],\n",
      "        [ 0.1298,  0.0405],\n",
      "        [ 0.0616, -0.0546],\n",
      "        [ 0.1127,  0.3470],\n",
      "        [ 0.1023, -0.0024],\n",
      "        [ 0.0581, -0.0268],\n",
      "        [ 0.1973,  0.2303],\n",
      "        [-0.0625,  0.1379],\n",
      "        [ 0.2825, -0.0308],\n",
      "        [ 0.0752,  0.2197],\n",
      "        [-0.0768,  0.0220],\n",
      "        [-0.0104, -0.0782],\n",
      "        [ 0.0559, -0.1456],\n",
      "        [ 0.1086,  0.2952],\n",
      "        [ 0.1684,  0.1130],\n",
      "        [ 0.6102,  0.4195],\n",
      "        [ 0.3761,  0.2908],\n",
      "        [ 0.0337,  0.1307],\n",
      "        [ 0.1143,  0.0581]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7015, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5281, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2296, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2296, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   7%|████▊                                                                 | 15/219 [02:24<32:52,  9.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.3297,  0.2882],\n",
      "        [ 0.0625,  0.1461],\n",
      "        [ 0.0037,  0.4054],\n",
      "        [-0.1710,  0.0013],\n",
      "        [-0.2232,  0.6080],\n",
      "        [-0.1674,  0.2249],\n",
      "        [-0.1679,  0.0489],\n",
      "        [-0.0524,  0.2139],\n",
      "        [-0.3739,  0.1120],\n",
      "        [ 0.1885,  0.0823],\n",
      "        [-0.1865,  0.1711],\n",
      "        [ 0.1004,  0.2694],\n",
      "        [-0.0007, -0.0067],\n",
      "        [-0.1000,  0.1035],\n",
      "        [ 0.1253, -0.1997],\n",
      "        [-0.0327,  0.2646],\n",
      "        [-0.3709,  0.3066],\n",
      "        [ 0.0501, -0.0121],\n",
      "        [-0.0647, -0.0100],\n",
      "        [-0.3620,  0.1291],\n",
      "        [ 0.2580,  0.0110],\n",
      "        [-0.2011,  0.0145],\n",
      "        [ 0.0858, -0.0127],\n",
      "        [-0.1816,  0.0864],\n",
      "        [-0.0458,  0.2135],\n",
      "        [-0.0547,  0.1747],\n",
      "        [-0.2343,  0.1722],\n",
      "        [-0.1115,  0.2845],\n",
      "        [-0.2426,  0.0441],\n",
      "        [ 0.0626, -0.0123],\n",
      "        [-0.0418,  0.0560],\n",
      "        [-0.0944,  0.3527]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.4399,  0.3202],\n",
      "        [ 0.1521,  0.1083],\n",
      "        [ 0.1962,  0.1039],\n",
      "        [-0.0356, -0.0607],\n",
      "        [ 0.2563, -0.0458],\n",
      "        [ 0.0871,  0.2058],\n",
      "        [ 0.1709,  0.2880],\n",
      "        [ 0.0633,  0.2687],\n",
      "        [ 0.2612,  0.1843],\n",
      "        [-0.0169,  0.0783],\n",
      "        [ 0.2780,  0.1284],\n",
      "        [ 0.1242, -0.1513],\n",
      "        [-0.0532,  0.4164],\n",
      "        [ 0.0451, -0.2086],\n",
      "        [-0.0040, -0.1981],\n",
      "        [ 0.1226,  0.1012],\n",
      "        [ 0.2252,  0.1049],\n",
      "        [-0.1324,  0.0099],\n",
      "        [ 0.2127,  0.2308],\n",
      "        [ 0.1899,  0.1000],\n",
      "        [ 0.0018, -0.0848],\n",
      "        [-0.1700, -0.2641],\n",
      "        [-0.0314,  0.0232],\n",
      "        [ 0.1302,  0.3394],\n",
      "        [ 0.1192,  0.1606],\n",
      "        [-0.2134,  0.0845],\n",
      "        [ 0.4062,  0.3421],\n",
      "        [ 0.2739,  0.2794],\n",
      "        [ 0.0918,  0.2893],\n",
      "        [-0.0455,  0.2543],\n",
      "        [ 0.0549,  0.2608],\n",
      "        [ 0.1238, -0.0355]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6777, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4758, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1535, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1535, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   7%|█████                                                                 | 16/219 [02:34<32:37,  9.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0597,  0.2299],\n",
      "        [-0.1477,  0.0040],\n",
      "        [-0.3435,  0.2668],\n",
      "        [-0.1796,  0.3343],\n",
      "        [-0.0340,  0.4630],\n",
      "        [-0.2282, -0.0305],\n",
      "        [-0.3825,  0.1211],\n",
      "        [ 0.0040,  0.3032],\n",
      "        [-0.1273,  0.1906],\n",
      "        [-0.0313,  0.4637],\n",
      "        [-0.2371,  0.0787],\n",
      "        [-0.0142,  0.3677],\n",
      "        [ 0.1013,  0.1722],\n",
      "        [-0.2746,  0.1945],\n",
      "        [-0.1587,  0.2913],\n",
      "        [ 0.2526, -0.1981],\n",
      "        [-0.1147,  0.1907],\n",
      "        [-0.1519,  0.3084],\n",
      "        [ 0.0485,  0.2599],\n",
      "        [-0.3787,  0.2907],\n",
      "        [ 0.0682,  0.1372],\n",
      "        [ 0.2362, -0.1065],\n",
      "        [-0.2842,  0.3107],\n",
      "        [-0.2365,  0.4794],\n",
      "        [-0.1671,  0.1470],\n",
      "        [-0.1674,  0.3458],\n",
      "        [ 0.1518, -0.0526],\n",
      "        [ 0.0115,  0.2506],\n",
      "        [-0.0765, -0.0370],\n",
      "        [-0.2684,  0.1936],\n",
      "        [ 0.0671,  0.2481],\n",
      "        [-0.1168,  0.2687]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 2.5211e-01, -1.9637e-01],\n",
      "        [ 1.5321e-01,  5.0846e-02],\n",
      "        [ 1.8412e-01,  9.3493e-02],\n",
      "        [ 3.1689e-01, -7.9737e-02],\n",
      "        [-1.2900e-01,  3.4861e-01],\n",
      "        [ 5.5944e-02, -1.1990e-01],\n",
      "        [ 5.7786e-03, -1.6847e-01],\n",
      "        [ 3.5893e-02, -5.6730e-02],\n",
      "        [ 1.0928e-01,  9.9928e-02],\n",
      "        [ 1.1706e-01,  4.6360e-02],\n",
      "        [-1.7239e-02, -9.6431e-02],\n",
      "        [-2.5588e-01, -8.4479e-02],\n",
      "        [-7.3392e-02, -6.6658e-02],\n",
      "        [-7.2914e-02, -4.3891e-02],\n",
      "        [-8.6855e-02,  5.7992e-02],\n",
      "        [ 2.7237e-01, -1.2777e-01],\n",
      "        [ 1.9178e-02,  2.1859e-01],\n",
      "        [ 4.1175e-04,  1.4134e-01],\n",
      "        [ 2.0275e-01, -1.5402e-01],\n",
      "        [ 1.2992e-01, -8.8945e-02],\n",
      "        [ 2.0492e-01,  7.7891e-02],\n",
      "        [-2.1842e-02,  1.5752e-02],\n",
      "        [ 2.9791e-01,  1.1169e-01],\n",
      "        [-1.3037e-01,  3.8323e-01],\n",
      "        [ 3.5522e-01,  4.2682e-01],\n",
      "        [-5.9410e-02,  4.9208e-02],\n",
      "        [-1.7790e-01, -1.8197e-01],\n",
      "        [ 1.8952e-01,  8.2283e-02],\n",
      "        [-9.9450e-02, -2.5218e-01],\n",
      "        [ 1.8643e-01,  1.0960e-01],\n",
      "        [-9.9101e-02, -1.5129e-02],\n",
      "        [ 8.0959e-02, -6.6187e-02]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7738, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5173, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2911, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2911, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|█████▍                                                                | 17/219 [02:43<32:26,  9.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0706,  0.0950],\n",
      "        [-0.0300,  0.4122],\n",
      "        [ 0.0018,  0.2799],\n",
      "        [-0.2880,  0.1769],\n",
      "        [-0.0985,  0.1587],\n",
      "        [-0.0106,  0.2395],\n",
      "        [ 0.0881, -0.1206],\n",
      "        [-0.4559,  0.2631],\n",
      "        [ 0.1992, -0.0941],\n",
      "        [ 0.0875,  0.4570],\n",
      "        [-0.1069,  0.3808],\n",
      "        [-0.0366,  0.2992],\n",
      "        [-0.0690, -0.0486],\n",
      "        [ 0.1405, -0.1284],\n",
      "        [-0.3068,  0.0272],\n",
      "        [ 0.0067, -0.1104],\n",
      "        [-0.0088,  0.4129],\n",
      "        [-0.0631,  0.0401],\n",
      "        [ 0.0412,  0.1736],\n",
      "        [ 0.0342,  0.0190],\n",
      "        [ 0.0585, -0.2480],\n",
      "        [ 0.0031, -0.3544],\n",
      "        [-0.1381,  0.2842],\n",
      "        [-0.0703,  0.1023],\n",
      "        [ 0.1789,  0.1111],\n",
      "        [-0.1412,  0.3134],\n",
      "        [ 0.1871,  0.0241],\n",
      "        [ 0.0873,  0.1275],\n",
      "        [ 0.0981,  0.0981],\n",
      "        [ 0.2131, -0.0780],\n",
      "        [-0.0174,  0.0918],\n",
      "        [-0.2333,  0.3173]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.0113,  0.1101],\n",
      "        [-0.1177, -0.0804],\n",
      "        [-0.0685,  0.1470],\n",
      "        [ 0.3583,  0.1721],\n",
      "        [-0.0889, -0.0160],\n",
      "        [ 0.0544, -0.0358],\n",
      "        [ 0.0110, -0.2813],\n",
      "        [ 0.4561,  0.2458],\n",
      "        [ 0.0286, -0.3314],\n",
      "        [-0.1742, -0.1337],\n",
      "        [ 0.0605, -0.0726],\n",
      "        [ 0.1771, -0.0748],\n",
      "        [ 0.0247,  0.0033],\n",
      "        [-0.0126, -0.0451],\n",
      "        [-0.0539,  0.1745],\n",
      "        [ 0.0709, -0.2601],\n",
      "        [ 0.0019, -0.0870],\n",
      "        [ 0.2226,  0.2793],\n",
      "        [-0.0545, -0.0967],\n",
      "        [ 0.0579,  0.0235],\n",
      "        [ 0.0661, -0.2243],\n",
      "        [-0.0931, -0.2473],\n",
      "        [ 0.0615, -0.1047],\n",
      "        [ 0.0113,  0.1615],\n",
      "        [ 0.1962,  0.0923],\n",
      "        [ 0.0802, -0.0649],\n",
      "        [ 0.0454, -0.1580],\n",
      "        [-0.0703,  0.1638],\n",
      "        [-0.0879, -0.0174],\n",
      "        [-0.0093, -0.1408],\n",
      "        [ 0.1238,  0.1621],\n",
      "        [ 0.3916, -0.1519]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7178, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4496, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1674, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1674, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|█████▊                                                                | 18/219 [02:53<32:18,  9.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0315,  0.0323],\n",
      "        [ 0.1600, -0.2214],\n",
      "        [ 0.0301,  0.0569],\n",
      "        [-0.1666,  0.1663],\n",
      "        [-0.1891,  0.1741],\n",
      "        [-0.3186,  0.1636],\n",
      "        [ 0.0915,  0.0223],\n",
      "        [-0.0580, -0.2649],\n",
      "        [ 0.0911,  0.0290],\n",
      "        [-0.0192,  0.2664],\n",
      "        [-0.2271,  0.2168],\n",
      "        [ 0.2175,  0.1446],\n",
      "        [-0.1299,  0.3664],\n",
      "        [-0.2519,  0.2384],\n",
      "        [-0.3359,  0.1227],\n",
      "        [-0.2592, -0.0421],\n",
      "        [ 0.2493, -0.3404],\n",
      "        [-0.1902,  0.4421],\n",
      "        [-0.2132,  0.1950],\n",
      "        [-0.0058,  0.3774],\n",
      "        [-0.0438, -0.0419],\n",
      "        [-0.4010,  0.0331],\n",
      "        [-0.1855,  0.1709],\n",
      "        [-0.1818,  0.1981],\n",
      "        [-0.1359,  0.2443],\n",
      "        [-0.0658,  0.1654],\n",
      "        [-0.0132,  0.0552],\n",
      "        [-0.1878,  0.1745],\n",
      "        [ 0.2489,  0.0413],\n",
      "        [ 0.1226,  0.1035],\n",
      "        [ 0.1854,  0.1270],\n",
      "        [-0.1271,  0.0632]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 1.1537e-01,  3.8549e-02],\n",
      "        [ 1.2485e-01, -3.0165e-01],\n",
      "        [-1.5352e-02, -1.2677e-01],\n",
      "        [-5.2895e-02,  5.9792e-03],\n",
      "        [-7.5115e-02, -4.2605e-02],\n",
      "        [ 8.8092e-02, -6.0517e-02],\n",
      "        [ 3.0418e-02, -2.6807e-01],\n",
      "        [ 3.1927e-02, -2.5133e-01],\n",
      "        [ 4.3407e-05, -8.4373e-02],\n",
      "        [ 5.6931e-02,  1.2345e-01],\n",
      "        [-1.2008e-01,  5.0051e-02],\n",
      "        [ 2.0099e-01,  2.2237e-02],\n",
      "        [ 3.5902e-02,  6.5971e-03],\n",
      "        [ 2.3033e-01, -2.9634e-02],\n",
      "        [ 3.0529e-01,  6.4727e-02],\n",
      "        [-8.8357e-03,  1.7597e-01],\n",
      "        [-7.8281e-02, -2.0101e-01],\n",
      "        [ 2.4092e-02,  1.0777e-01],\n",
      "        [ 8.5385e-02,  1.6676e-01],\n",
      "        [-1.4367e-02,  1.7326e-02],\n",
      "        [-1.5180e-01, -9.5408e-02],\n",
      "        [ 2.2261e-01,  2.5753e-01],\n",
      "        [ 1.5758e-01,  1.8857e-01],\n",
      "        [ 1.3599e-01,  5.9166e-02],\n",
      "        [-8.5405e-03, -2.5595e-01],\n",
      "        [-2.8237e-03,  6.1310e-02],\n",
      "        [ 1.1913e-01,  6.8846e-02],\n",
      "        [ 1.5132e-02,  1.8455e-01],\n",
      "        [ 1.6570e-01, -2.1081e-01],\n",
      "        [ 4.3880e-01, -2.1878e-01],\n",
      "        [-1.1034e-01, -5.1008e-02],\n",
      "        [-4.0529e-02, -6.9949e-02]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7009, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4670, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1679, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1679, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   9%|██████                                                                | 19/219 [03:03<32:09,  9.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-5.6859e-02, -3.8623e-02],\n",
      "        [-1.9241e-01,  8.9429e-02],\n",
      "        [-8.4998e-02, -6.0954e-02],\n",
      "        [ 7.8499e-02,  3.7249e-02],\n",
      "        [-5.0063e-02,  2.3394e-01],\n",
      "        [-1.7403e-01,  2.5047e-01],\n",
      "        [-3.7747e-02,  1.0213e-01],\n",
      "        [-2.8435e-01,  3.0286e-01],\n",
      "        [-2.9373e-02,  3.0225e-01],\n",
      "        [-2.3215e-01,  4.1478e-01],\n",
      "        [ 3.4416e-01, -3.4673e-01],\n",
      "        [-2.2000e-01,  2.5817e-01],\n",
      "        [ 1.8279e-02,  2.7100e-01],\n",
      "        [-1.1462e-01,  7.8360e-02],\n",
      "        [ 1.5244e-02,  4.2009e-01],\n",
      "        [ 6.9507e-02, -1.5544e-01],\n",
      "        [-2.3690e-01, -2.1628e-02],\n",
      "        [-8.3859e-02,  1.0926e-01],\n",
      "        [ 3.4648e-04,  1.9446e-01],\n",
      "        [ 2.8332e-01, -7.7534e-02],\n",
      "        [-7.2002e-02, -3.4948e-02],\n",
      "        [-7.3501e-02, -1.1228e-01],\n",
      "        [ 4.3195e-02, -2.6914e-03],\n",
      "        [ 7.1221e-02,  6.0519e-02],\n",
      "        [ 2.1565e-02, -6.5616e-02],\n",
      "        [ 3.8293e-02, -1.7667e-01],\n",
      "        [-1.2950e-01,  2.5693e-01],\n",
      "        [-2.8525e-01,  5.6903e-02],\n",
      "        [ 1.0930e-01, -1.0547e-01],\n",
      "        [ 2.8123e-01, -6.8577e-02],\n",
      "        [-1.2653e-01,  1.7907e-02],\n",
      "        [ 1.3701e-01, -3.1943e-01]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.0469, -0.2958],\n",
      "        [ 0.0905, -0.0238],\n",
      "        [-0.0150, -0.0794],\n",
      "        [-0.1356,  0.0687],\n",
      "        [-0.0072, -0.2119],\n",
      "        [ 0.2161,  0.2869],\n",
      "        [ 0.1992,  0.0252],\n",
      "        [ 0.0849,  0.1069],\n",
      "        [ 0.1359,  0.0231],\n",
      "        [ 0.1146, -0.2076],\n",
      "        [-0.0254, -0.2956],\n",
      "        [ 0.0177, -0.0024],\n",
      "        [-0.1230, -0.1643],\n",
      "        [ 0.0856, -0.0656],\n",
      "        [ 0.2296, -0.3478],\n",
      "        [ 0.2224, -0.1393],\n",
      "        [ 0.0978, -0.1465],\n",
      "        [-0.0345,  0.1626],\n",
      "        [ 0.0142,  0.0031],\n",
      "        [ 0.1121, -0.2496],\n",
      "        [-0.1168, -0.2734],\n",
      "        [ 0.1024, -0.1173],\n",
      "        [ 0.1538, -0.1628],\n",
      "        [-0.1368, -0.0083],\n",
      "        [ 0.0692, -0.4679],\n",
      "        [-0.0539, -0.2497],\n",
      "        [ 0.0763, -0.3696],\n",
      "        [ 0.0886,  0.0152],\n",
      "        [ 0.0232, -0.2065],\n",
      "        [-0.1082, -0.3443],\n",
      "        [ 0.1948,  0.0251],\n",
      "        [ 0.0584, -0.2986]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7259, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5437, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2696, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2696, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   9%|██████▍                                                               | 20/219 [03:12<32:00,  9.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.2584, -0.1343],\n",
      "        [ 0.1583,  0.0443],\n",
      "        [-0.1948, -0.0337],\n",
      "        [-0.2723,  0.1993],\n",
      "        [ 0.2877,  0.5158],\n",
      "        [ 0.0666,  0.0838],\n",
      "        [ 0.0741,  0.0117],\n",
      "        [-0.0457,  0.1264],\n",
      "        [ 0.1024,  0.1288],\n",
      "        [-0.1923,  0.1255],\n",
      "        [ 0.0258, -0.2862],\n",
      "        [ 0.1454,  0.1245],\n",
      "        [-0.2878,  0.0400],\n",
      "        [ 0.0389,  0.0554],\n",
      "        [-0.0705,  0.0607],\n",
      "        [ 0.0166, -0.0094],\n",
      "        [-0.1842,  0.1304],\n",
      "        [-0.3397,  0.0499],\n",
      "        [ 0.0789,  0.1055],\n",
      "        [ 0.0773,  0.2114],\n",
      "        [-0.0798,  0.1638],\n",
      "        [-0.0482,  0.1862],\n",
      "        [-0.1220,  0.5311],\n",
      "        [ 0.2286, -0.0086],\n",
      "        [ 0.0915,  0.1735],\n",
      "        [ 0.2178, -0.0775],\n",
      "        [-0.0356,  0.2376],\n",
      "        [-0.1223,  0.0643],\n",
      "        [ 0.1269, -0.2741],\n",
      "        [-0.2304, -0.0113],\n",
      "        [-0.0534, -0.0026],\n",
      "        [-0.2148,  0.0211]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.0535,  0.0495],\n",
      "        [-0.0740, -0.1049],\n",
      "        [-0.0202,  0.1789],\n",
      "        [ 0.2411, -0.0781],\n",
      "        [ 0.1691, -0.2765],\n",
      "        [ 0.0189, -0.1700],\n",
      "        [ 0.1851, -0.1806],\n",
      "        [-0.1179, -0.2709],\n",
      "        [-0.0462, -0.0059],\n",
      "        [ 0.1138,  0.0868],\n",
      "        [ 0.1129, -0.4207],\n",
      "        [-0.0173, -0.2183],\n",
      "        [ 0.0174,  0.2558],\n",
      "        [-0.0752, -0.0880],\n",
      "        [ 0.0337,  0.1322],\n",
      "        [-0.1163, -0.0933],\n",
      "        [ 0.0137, -0.0128],\n",
      "        [ 0.4668, -0.1785],\n",
      "        [-0.0208,  0.0308],\n",
      "        [ 0.1416, -0.1232],\n",
      "        [ 0.0377, -0.0241],\n",
      "        [ 0.0448, -0.4376],\n",
      "        [ 0.0494,  0.1951],\n",
      "        [-0.0709,  0.0275],\n",
      "        [ 0.0465, -0.2827],\n",
      "        [-0.0318, -0.1363],\n",
      "        [ 0.2063,  0.0195],\n",
      "        [ 0.1463,  0.3748],\n",
      "        [ 0.0755, -0.1738],\n",
      "        [ 0.0714,  0.0550],\n",
      "        [-0.2525, -0.3059],\n",
      "        [ 0.0641, -0.2023]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6985, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4954, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1938, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1938, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  10%|██████▋                                                               | 21/219 [03:22<31:51,  9.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.2209,  0.1473],\n",
      "        [-0.0913, -0.1349],\n",
      "        [-0.0310, -0.0259],\n",
      "        [-0.0979,  0.3668],\n",
      "        [-0.0115,  0.0127],\n",
      "        [-0.1549,  0.2176],\n",
      "        [ 0.2154, -0.0710],\n",
      "        [ 0.0684,  0.1979],\n",
      "        [ 0.1025,  0.0768],\n",
      "        [ 0.2388,  0.1164],\n",
      "        [ 0.1558,  0.0972],\n",
      "        [-0.1602,  0.1047],\n",
      "        [ 0.0887,  0.0516],\n",
      "        [ 0.0498, -0.3019],\n",
      "        [ 0.3164, -0.1131],\n",
      "        [-0.0280, -0.0986],\n",
      "        [-0.0907,  0.0920],\n",
      "        [ 0.1757,  0.0809],\n",
      "        [ 0.0091,  0.0778],\n",
      "        [-0.1044,  0.2061],\n",
      "        [ 0.0200,  0.1655],\n",
      "        [-0.2042,  0.1014],\n",
      "        [ 0.0255,  0.0997],\n",
      "        [-0.0231, -0.0251],\n",
      "        [ 0.1096,  0.0560],\n",
      "        [ 0.1299,  0.2591],\n",
      "        [ 0.0690,  0.1085],\n",
      "        [ 0.0246, -0.1230],\n",
      "        [-0.1277,  0.0223],\n",
      "        [-0.0250,  0.1692],\n",
      "        [ 0.0320,  0.2123],\n",
      "        [ 0.4514,  0.1794]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.1540, -0.1114],\n",
      "        [ 0.1837, -0.1010],\n",
      "        [-0.0664,  0.0103],\n",
      "        [-0.0405,  0.2638],\n",
      "        [-0.0984, -0.3699],\n",
      "        [-0.0943, -0.1004],\n",
      "        [-0.0903, -0.4293],\n",
      "        [ 0.1691, -0.0208],\n",
      "        [ 0.0589, -0.1642],\n",
      "        [-0.0267, -0.1374],\n",
      "        [-0.0174,  0.0344],\n",
      "        [-0.1032, -0.0845],\n",
      "        [ 0.1099, -0.0227],\n",
      "        [ 0.0807, -0.3663],\n",
      "        [-0.0459, -0.1873],\n",
      "        [ 0.2037, -0.0414],\n",
      "        [-0.0026, -0.0637],\n",
      "        [ 0.0049, -0.1349],\n",
      "        [-0.1367, -0.0257],\n",
      "        [ 0.3245,  0.3146],\n",
      "        [ 0.2294, -0.0009],\n",
      "        [-0.1250, -0.1186],\n",
      "        [ 0.3311, -0.0485],\n",
      "        [-0.0754,  0.1289],\n",
      "        [ 0.0008,  0.1003],\n",
      "        [ 0.0752, -0.0681],\n",
      "        [-0.1264, -0.3666],\n",
      "        [ 0.0521, -0.0560],\n",
      "        [-0.0413, -0.0516],\n",
      "        [ 0.2356, -0.1412],\n",
      "        [-0.0177,  0.0987],\n",
      "        [-0.0453, -0.3467]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7238, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5246, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2483, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2483, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  10%|███████                                                               | 22/219 [03:32<31:41,  9.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1261,  0.2423],\n",
      "        [-0.0938,  0.1661],\n",
      "        [-0.0263,  0.0253],\n",
      "        [ 0.1191,  0.2029],\n",
      "        [-0.0445, -0.2760],\n",
      "        [ 0.0086, -0.0620],\n",
      "        [ 0.0600,  0.1017],\n",
      "        [ 0.0225, -0.0703],\n",
      "        [ 0.0400,  0.1366],\n",
      "        [-0.0729, -0.0816],\n",
      "        [ 0.1577,  0.0188],\n",
      "        [-0.1583,  0.0196],\n",
      "        [ 0.0476, -0.2359],\n",
      "        [-0.0923,  0.2513],\n",
      "        [ 0.0295,  0.1732],\n",
      "        [-0.0215,  0.3910],\n",
      "        [ 0.2247, -0.0029],\n",
      "        [ 0.2368, -0.1103],\n",
      "        [ 0.1385,  0.2756],\n",
      "        [ 0.1079,  0.0113],\n",
      "        [ 0.3964, -0.2399],\n",
      "        [ 0.0627,  0.0381],\n",
      "        [ 0.1878, -0.1131],\n",
      "        [ 0.3662,  0.0140],\n",
      "        [ 0.0349,  0.1087],\n",
      "        [-0.2572,  0.0925],\n",
      "        [ 0.0427, -0.0791],\n",
      "        [ 0.1045,  0.0381],\n",
      "        [ 0.2061,  0.0174],\n",
      "        [ 0.2624, -0.1417],\n",
      "        [ 0.0101,  0.0966],\n",
      "        [ 0.1286,  0.2291]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.0791,  0.1152],\n",
      "        [-0.1851, -0.0680],\n",
      "        [ 0.1147, -0.1530],\n",
      "        [ 0.0705, -0.2469],\n",
      "        [ 0.0014, -0.1197],\n",
      "        [-0.0334, -0.0990],\n",
      "        [-0.1057, -0.1494],\n",
      "        [ 0.0900, -0.1726],\n",
      "        [ 0.0381, -0.2318],\n",
      "        [-0.0715, -0.1302],\n",
      "        [ 0.0234, -0.0232],\n",
      "        [ 0.0566, -0.0351],\n",
      "        [-0.0239, -0.3366],\n",
      "        [ 0.1238, -0.2244],\n",
      "        [ 0.0943, -0.0741],\n",
      "        [-0.1434,  0.0099],\n",
      "        [ 0.1312, -0.0691],\n",
      "        [-0.0732, -0.2840],\n",
      "        [-0.0395, -0.0661],\n",
      "        [ 0.1899, -0.0763],\n",
      "        [ 0.1678, -0.2607],\n",
      "        [ 0.2144, -0.2439],\n",
      "        [-0.0397, -0.1590],\n",
      "        [-0.0188, -0.1698],\n",
      "        [-0.0838, -0.2619],\n",
      "        [ 0.1201, -0.2992],\n",
      "        [-0.0240, -0.1273],\n",
      "        [ 0.1490,  0.0814],\n",
      "        [ 0.0519, -0.5368],\n",
      "        [ 0.2375, -0.2239],\n",
      "        [-0.1076, -0.2960],\n",
      "        [ 0.1153, -0.2002]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6911, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4508, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1419, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1419, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███████▎                                                              | 23/219 [03:41<31:31,  9.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0891, -0.1384],\n",
      "        [ 0.0976, -0.0343],\n",
      "        [ 0.3333, -0.0945],\n",
      "        [-0.0931, -0.0864],\n",
      "        [ 0.1380,  0.1000],\n",
      "        [ 0.1553,  0.0266],\n",
      "        [ 0.1962, -0.2579],\n",
      "        [ 0.0939, -0.4068],\n",
      "        [-0.1013,  0.3827],\n",
      "        [-0.1802, -0.0762],\n",
      "        [ 0.0576,  0.0994],\n",
      "        [ 0.1834, -0.0976],\n",
      "        [-0.0614, -0.0895],\n",
      "        [ 0.0720,  0.0890],\n",
      "        [ 0.0459,  0.1049],\n",
      "        [ 0.3510, -0.4252],\n",
      "        [ 0.0826, -0.1486],\n",
      "        [-0.1922, -0.2879],\n",
      "        [ 0.0779,  0.0662],\n",
      "        [ 0.2322,  0.3727],\n",
      "        [ 0.1759,  0.0265],\n",
      "        [ 0.2387, -0.3425],\n",
      "        [ 0.0502, -0.0997],\n",
      "        [ 0.2378, -0.2655],\n",
      "        [ 0.2024, -0.3260],\n",
      "        [ 0.3171, -0.1629],\n",
      "        [-0.1581,  0.0428],\n",
      "        [-0.0830, -0.0307],\n",
      "        [-0.0177, -0.0669],\n",
      "        [ 0.3010, -0.0599],\n",
      "        [ 0.1656, -0.4089],\n",
      "        [ 0.2155,  0.1590]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-3.1314e-02, -1.6844e-01],\n",
      "        [ 2.0476e-01, -1.1289e-01],\n",
      "        [ 3.2077e-02, -5.7208e-02],\n",
      "        [ 4.4702e-02, -1.3756e-01],\n",
      "        [ 2.2621e-02, -2.9478e-01],\n",
      "        [-1.4440e-01, -2.2161e-01],\n",
      "        [-4.5239e-03, -2.2560e-01],\n",
      "        [ 2.2015e-01, -2.2534e-02],\n",
      "        [-1.8728e-01,  8.8895e-02],\n",
      "        [-2.0169e-04, -9.7694e-02],\n",
      "        [-1.8456e-01, -2.2702e-01],\n",
      "        [ 2.7140e-02, -2.1796e-01],\n",
      "        [-4.0117e-02, -1.0654e-01],\n",
      "        [ 5.7896e-02,  5.3244e-02],\n",
      "        [-9.8254e-03, -2.9940e-01],\n",
      "        [ 7.6026e-02, -2.1156e-01],\n",
      "        [ 1.5663e-01,  3.9147e-02],\n",
      "        [-6.8954e-02, -1.9502e-01],\n",
      "        [-6.4588e-02, -2.4987e-01],\n",
      "        [-3.8964e-02, -7.8353e-02],\n",
      "        [ 6.2798e-02, -3.5855e-02],\n",
      "        [ 2.4655e-01, -2.5252e-01],\n",
      "        [ 1.5821e-01, -2.3473e-01],\n",
      "        [-8.9089e-02, -1.7465e-01],\n",
      "        [ 1.3114e-01, -2.3121e-01],\n",
      "        [ 4.4039e-02, -2.9912e-01],\n",
      "        [ 4.6927e-02,  6.6296e-02],\n",
      "        [-1.8564e-01, -6.3170e-02],\n",
      "        [-2.0972e-03, -2.6085e-01],\n",
      "        [-2.4970e-02, -3.3885e-01],\n",
      "        [ 1.3273e-02, -3.2016e-01],\n",
      "        [ 6.7891e-02,  1.0588e-01]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6588, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5597, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2185, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███████▋                                                              | 24/219 [03:51<31:18,  9.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1196, -0.0744],\n",
      "        [ 0.1305, -0.0180],\n",
      "        [ 0.3076, -0.2361],\n",
      "        [ 0.4553, -0.1705],\n",
      "        [ 0.0555, -0.0774],\n",
      "        [ 0.2391,  0.0926],\n",
      "        [ 0.0309, -0.2542],\n",
      "        [-0.2154,  0.1559],\n",
      "        [ 0.1007,  0.1071],\n",
      "        [ 0.1639,  0.1126],\n",
      "        [ 0.1095,  0.0255],\n",
      "        [ 0.0663,  0.0520],\n",
      "        [-0.1047, -0.1067],\n",
      "        [ 0.1896,  0.0336],\n",
      "        [ 0.2225, -0.0207],\n",
      "        [ 0.1945, -0.2408],\n",
      "        [ 0.1039,  0.0584],\n",
      "        [ 0.2994, -0.1747],\n",
      "        [-0.0280, -0.1413],\n",
      "        [ 0.2963, -0.3307],\n",
      "        [ 0.1338, -0.0508],\n",
      "        [-0.2156,  0.1472],\n",
      "        [-0.0769, -0.0498],\n",
      "        [ 0.2857, -0.1708],\n",
      "        [-0.0329, -0.1608],\n",
      "        [-0.1682, -0.1058],\n",
      "        [ 0.2491, -0.0545],\n",
      "        [-0.0404,  0.1619],\n",
      "        [ 0.0502, -0.0844],\n",
      "        [ 0.3189, -0.0718],\n",
      "        [ 0.1680, -0.2090],\n",
      "        [ 0.0349, -0.0865]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 2.4251e-02, -9.9275e-02],\n",
      "        [-2.6268e-02, -2.8228e-01],\n",
      "        [ 4.2916e-02, -4.5512e-01],\n",
      "        [-3.8176e-02, -1.3822e-01],\n",
      "        [ 2.0209e-02, -2.0348e-01],\n",
      "        [ 1.4960e-01, -7.6210e-02],\n",
      "        [-2.1027e-02, -1.6639e-01],\n",
      "        [ 3.9129e-02,  4.9296e-03],\n",
      "        [ 1.9767e-03, -1.7709e-01],\n",
      "        [ 1.2398e-01, -3.3062e-02],\n",
      "        [-9.0336e-02, -3.9165e-01],\n",
      "        [ 6.9113e-02, -6.7282e-02],\n",
      "        [ 5.4300e-02, -2.5169e-01],\n",
      "        [ 5.9798e-02,  4.9827e-02],\n",
      "        [ 7.1353e-03, -3.4047e-01],\n",
      "        [-3.4194e-02,  7.0433e-02],\n",
      "        [ 5.7480e-02, -3.3506e-01],\n",
      "        [-3.6424e-04, -1.9295e-01],\n",
      "        [-8.8956e-02, -2.0398e-01],\n",
      "        [ 3.1782e-01, -1.7769e-01],\n",
      "        [ 8.1430e-02,  1.2483e-02],\n",
      "        [-7.2226e-02,  1.6860e-01],\n",
      "        [-1.9702e-01, -5.3357e-02],\n",
      "        [-2.9167e-02, -2.4716e-01],\n",
      "        [ 7.2080e-02, -1.0370e-01],\n",
      "        [ 7.8387e-02,  8.5933e-02],\n",
      "        [ 6.5213e-02, -1.0873e-01],\n",
      "        [ 1.3973e-01, -1.9091e-01],\n",
      "        [ 6.1045e-02, -1.0672e-01],\n",
      "        [ 2.3331e-02, -2.4317e-01],\n",
      "        [-3.3310e-02, -1.5424e-01],\n",
      "        [-2.9677e-02, -2.5444e-01]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7380, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.3174, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.0554, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.0554, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███████▉                                                              | 25/219 [04:01<31:36,  9.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 8.0010e-02,  3.0311e-02],\n",
      "        [ 1.1398e-01, -1.8320e-01],\n",
      "        [ 1.9124e-01,  5.5748e-02],\n",
      "        [ 4.9089e-02,  4.5621e-02],\n",
      "        [ 1.7883e-01, -2.4019e-01],\n",
      "        [ 8.0763e-02,  4.5509e-02],\n",
      "        [ 2.5451e-04, -1.7054e-02],\n",
      "        [ 8.8278e-02,  7.5427e-02],\n",
      "        [ 7.2939e-02, -8.3501e-03],\n",
      "        [ 9.4891e-02, -9.9346e-02],\n",
      "        [ 3.1681e-01, -2.1593e-02],\n",
      "        [ 2.4926e-01, -2.9689e-01],\n",
      "        [ 1.5836e-02, -2.9223e-02],\n",
      "        [ 2.5431e-01, -2.5664e-01],\n",
      "        [ 6.6139e-02,  1.0135e-01],\n",
      "        [ 3.0572e-01, -1.7651e-01],\n",
      "        [ 3.0632e-02, -9.0666e-03],\n",
      "        [ 4.0767e-01,  6.3173e-02],\n",
      "        [ 1.0139e-01, -2.4289e-01],\n",
      "        [ 4.6453e-02,  2.6497e-01],\n",
      "        [ 1.6470e-01,  1.5103e-01],\n",
      "        [ 2.0391e-01,  2.5203e-01],\n",
      "        [ 1.6695e-01, -1.7069e-01],\n",
      "        [ 3.4594e-02, -6.7065e-02],\n",
      "        [ 1.0864e-01, -1.4434e-02],\n",
      "        [ 1.4079e-01, -8.7071e-02],\n",
      "        [ 1.6585e-01, -2.6583e-02],\n",
      "        [ 3.3821e-01, -1.6413e-01],\n",
      "        [ 1.2251e-01, -2.1399e-02],\n",
      "        [ 3.3520e-01, -9.1065e-02],\n",
      "        [ 1.7475e-01, -1.1827e-01],\n",
      "        [ 3.0662e-01, -8.6994e-02]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.0351, -0.3256],\n",
      "        [-0.1118, -0.3354],\n",
      "        [-0.2796, -0.3486],\n",
      "        [ 0.1351,  0.5296],\n",
      "        [ 0.1012, -0.1321],\n",
      "        [ 0.2264, -0.2675],\n",
      "        [-0.0328, -0.0477],\n",
      "        [ 0.0812, -0.1227],\n",
      "        [ 0.0278, -0.4750],\n",
      "        [-0.2834, -0.0085],\n",
      "        [ 0.0826, -0.3237],\n",
      "        [ 0.1549, -0.1646],\n",
      "        [-0.0833, -0.4861],\n",
      "        [ 0.0658, -0.2244],\n",
      "        [ 0.0203, -0.1080],\n",
      "        [-0.0945, -0.1313],\n",
      "        [ 0.2343, -0.1904],\n",
      "        [ 0.1268, -0.1345],\n",
      "        [ 0.1394, -0.3472],\n",
      "        [-0.0018, -0.2335],\n",
      "        [-0.1617, -0.3552],\n",
      "        [ 0.5362, -0.0165],\n",
      "        [ 0.0095, -0.3313],\n",
      "        [ 0.0362, -0.2589],\n",
      "        [-0.0346,  0.1024],\n",
      "        [ 0.1334, -0.2833],\n",
      "        [ 0.1059, -0.3260],\n",
      "        [ 0.0099, -0.3702],\n",
      "        [-0.0111, -0.1942],\n",
      "        [ 0.0235, -0.1101],\n",
      "        [-0.0373,  0.0975],\n",
      "        [-0.0058, -0.1839]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7072, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5030, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2102, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2102, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|████████▎                                                             | 26/219 [04:11<31:32,  9.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.2966,  0.0077],\n",
      "        [ 0.3696, -0.2515],\n",
      "        [ 0.1668, -0.0091],\n",
      "        [ 0.2262, -0.0323],\n",
      "        [ 0.3171, -0.1083],\n",
      "        [-0.0875,  0.1252],\n",
      "        [ 0.0202,  0.1545],\n",
      "        [ 0.0321, -0.0122],\n",
      "        [ 0.1483, -0.2030],\n",
      "        [-0.1203, -0.2041],\n",
      "        [ 0.2858,  0.0204],\n",
      "        [ 0.1471,  0.1322],\n",
      "        [ 0.2070, -0.1716],\n",
      "        [-0.0461,  0.1796],\n",
      "        [ 0.1840, -0.1423],\n",
      "        [ 0.1561, -0.0830],\n",
      "        [ 0.2013, -0.1844],\n",
      "        [-0.0173,  0.0985],\n",
      "        [ 0.1563,  0.0059],\n",
      "        [ 0.3933,  0.1169],\n",
      "        [ 0.1228,  0.0769],\n",
      "        [ 0.1139, -0.0075],\n",
      "        [ 0.0807, -0.2048],\n",
      "        [ 0.1547, -0.2193],\n",
      "        [ 0.3374,  0.0048],\n",
      "        [ 0.1770, -0.0316],\n",
      "        [ 0.0456, -0.1568],\n",
      "        [ 0.1629, -0.2140],\n",
      "        [ 0.0119, -0.2772],\n",
      "        [ 0.1393, -0.1235],\n",
      "        [ 0.0378,  0.0597],\n",
      "        [ 0.2121,  0.1018]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.0072, -0.2571],\n",
      "        [-0.1959, -0.1560],\n",
      "        [-0.1108, -0.2812],\n",
      "        [-0.1292, -0.3131],\n",
      "        [ 0.1228, -0.2298],\n",
      "        [-0.2309, -0.1241],\n",
      "        [ 0.0249, -0.2062],\n",
      "        [-0.1037, -0.2542],\n",
      "        [-0.1646, -0.0990],\n",
      "        [ 0.0332,  0.2020],\n",
      "        [-0.1286,  0.1429],\n",
      "        [ 0.0146, -0.4627],\n",
      "        [-0.0302, -0.3154],\n",
      "        [-0.0298, -0.1328],\n",
      "        [ 0.0558, -0.1417],\n",
      "        [-0.0856, -0.3130],\n",
      "        [ 0.0346, -0.2335],\n",
      "        [ 0.0503, -0.0651],\n",
      "        [-0.0206, -0.4942],\n",
      "        [-0.1926, -0.3289],\n",
      "        [-0.0140, -0.2087],\n",
      "        [-0.1017, -0.2684],\n",
      "        [-0.0507, -0.1546],\n",
      "        [ 0.1435, -0.0982],\n",
      "        [-0.0794, -0.2632],\n",
      "        [-0.0955, -0.0391],\n",
      "        [-0.0099, -0.4054],\n",
      "        [ 0.1205, -0.1274],\n",
      "        [ 0.2165, -0.2538],\n",
      "        [-0.0281, -0.5101],\n",
      "        [-0.1852, -0.2683],\n",
      "        [-0.2632, -0.3002]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6855, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5688, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2544, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2544, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|████████▋                                                             | 27/219 [04:20<31:05,  9.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.3142, -0.2832],\n",
      "        [ 0.3081,  0.0688],\n",
      "        [ 0.2150, -0.0195],\n",
      "        [-0.0285,  0.1179],\n",
      "        [ 0.0467, -0.3166],\n",
      "        [ 0.2199,  0.1516],\n",
      "        [ 0.1126, -0.1494],\n",
      "        [-0.0395,  0.0964],\n",
      "        [ 0.2178,  0.0344],\n",
      "        [-0.0203, -0.1495],\n",
      "        [ 0.0249, -0.1122],\n",
      "        [ 0.3236,  0.1123],\n",
      "        [-0.2195, -0.0952],\n",
      "        [ 0.2399, -0.2667],\n",
      "        [ 0.2603, -0.1191],\n",
      "        [ 0.1457,  0.0220],\n",
      "        [ 0.2486, -0.1136],\n",
      "        [ 0.4135, -0.1888],\n",
      "        [ 0.1622, -0.0171],\n",
      "        [-0.1074,  0.2816],\n",
      "        [ 0.1531, -0.1714],\n",
      "        [ 0.0682, -0.1347],\n",
      "        [ 0.1133,  0.1841],\n",
      "        [ 0.1129, -0.0655],\n",
      "        [ 0.2553, -0.1577],\n",
      "        [ 0.3529,  0.1830],\n",
      "        [ 0.2106, -0.0552],\n",
      "        [ 0.1257, -0.0763],\n",
      "        [ 0.1282,  0.2364],\n",
      "        [ 0.1938, -0.1251],\n",
      "        [ 0.1291,  0.0246],\n",
      "        [-0.0088, -0.0673]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.1479, -0.3228],\n",
      "        [ 0.0139, -0.2345],\n",
      "        [ 0.1035, -0.1096],\n",
      "        [ 0.2811, -0.3338],\n",
      "        [ 0.0453, -0.1304],\n",
      "        [-0.1003, -0.2081],\n",
      "        [ 0.0368, -0.0007],\n",
      "        [-0.0705, -0.1804],\n",
      "        [-0.1084, -0.2395],\n",
      "        [-0.0216, -0.1458],\n",
      "        [ 0.0795, -0.1983],\n",
      "        [-0.0324, -0.3056],\n",
      "        [ 0.0460, -0.1456],\n",
      "        [-0.0074, -0.0074],\n",
      "        [-0.1769,  0.0336],\n",
      "        [-0.0271, -0.2111],\n",
      "        [-0.1967, -0.1073],\n",
      "        [ 0.0356,  0.0578],\n",
      "        [-0.0336, -0.3274],\n",
      "        [-0.1312, -0.2667],\n",
      "        [ 0.1828, -0.2205],\n",
      "        [ 0.1811, -0.0420],\n",
      "        [-0.0724, -0.4021],\n",
      "        [ 0.1453, -0.0870],\n",
      "        [-0.0243, -0.1214],\n",
      "        [ 0.1503, -0.3305],\n",
      "        [ 0.2002, -0.0324],\n",
      "        [ 0.0661, -0.2490],\n",
      "        [-0.3337, -0.3062],\n",
      "        [ 0.0858, -0.1252],\n",
      "        [-0.0014, -0.4294],\n",
      "        [-0.0876, -0.2402]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6986, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5432, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2419, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2419, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  13%|████████▉                                                             | 28/219 [04:30<31:14,  9.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1257, -0.1525],\n",
      "        [ 0.0065,  0.2039],\n",
      "        [ 0.0311, -0.0825],\n",
      "        [ 0.0537,  0.2488],\n",
      "        [ 0.2493, -0.1535],\n",
      "        [ 0.1008,  0.2573],\n",
      "        [ 0.1681,  0.0146],\n",
      "        [ 0.1288, -0.0803],\n",
      "        [ 0.1300, -0.1453],\n",
      "        [ 0.0720,  0.2352],\n",
      "        [-0.0699, -0.1276],\n",
      "        [ 0.1128,  0.2919],\n",
      "        [ 0.0455, -0.1724],\n",
      "        [-0.0293, -0.0115],\n",
      "        [ 0.3685, -0.2097],\n",
      "        [-0.0302, -0.0792],\n",
      "        [ 0.1494,  0.2413],\n",
      "        [ 0.1146, -0.0903],\n",
      "        [ 0.1211, -0.2179],\n",
      "        [ 0.3181, -0.1346],\n",
      "        [-0.0505,  0.2194],\n",
      "        [-0.0438, -0.0577],\n",
      "        [ 0.0799,  0.0937],\n",
      "        [ 0.1791, -0.0116],\n",
      "        [ 0.0098, -0.0165],\n",
      "        [-0.0792,  0.1035],\n",
      "        [ 0.2644,  0.1053],\n",
      "        [-0.0378,  0.1499],\n",
      "        [ 0.1628, -0.0380],\n",
      "        [ 0.1672,  0.0652],\n",
      "        [ 0.0611, -0.0668],\n",
      "        [ 0.0995, -0.2280]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.1735, -0.2555],\n",
      "        [-0.1441, -0.0543],\n",
      "        [-0.0504, -0.0577],\n",
      "        [ 0.1602, -0.4806],\n",
      "        [ 0.0181, -0.2376],\n",
      "        [ 0.1003, -0.1231],\n",
      "        [-0.0453, -0.3830],\n",
      "        [ 0.0811, -0.2735],\n",
      "        [ 0.0227, -0.1064],\n",
      "        [-0.0579, -0.4862],\n",
      "        [ 0.0881, -0.3774],\n",
      "        [-0.0449, -0.2112],\n",
      "        [ 0.0280, -0.3418],\n",
      "        [-0.0809, -0.2603],\n",
      "        [ 0.0107, -0.0745],\n",
      "        [-0.0466, -0.1543],\n",
      "        [ 0.0863, -0.0066],\n",
      "        [ 0.2890, -0.3800],\n",
      "        [ 0.0554, -0.2830],\n",
      "        [-0.1719, -0.0988],\n",
      "        [-0.1493, -0.2573],\n",
      "        [-0.0878, -0.2823],\n",
      "        [-0.1094, -0.1759],\n",
      "        [-0.2708, -0.2458],\n",
      "        [-0.1532, -0.2558],\n",
      "        [-0.0356, -0.2698],\n",
      "        [-0.0288, -0.2936],\n",
      "        [-0.1688, -0.1389],\n",
      "        [ 0.0445, -0.1549],\n",
      "        [-0.0863, -0.0911],\n",
      "        [ 0.0351, -0.0727],\n",
      "        [ 0.1074, -0.2511]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7167, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.3903, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1070, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1070, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  13%|█████████▎                                                            | 29/219 [04:40<31:08,  9.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0472, -0.0402],\n",
      "        [ 0.1605,  0.1414],\n",
      "        [ 0.1618,  0.0191],\n",
      "        [ 0.2324, -0.1387],\n",
      "        [ 0.0837, -0.0339],\n",
      "        [ 0.1170, -0.0203],\n",
      "        [ 0.0110,  0.1401],\n",
      "        [ 0.2509,  0.0681],\n",
      "        [ 0.1830,  0.1957],\n",
      "        [-0.0231,  0.0053],\n",
      "        [-0.0274,  0.2200],\n",
      "        [ 0.1095,  0.3073],\n",
      "        [ 0.0257, -0.0998],\n",
      "        [ 0.0696,  0.0134],\n",
      "        [ 0.2012,  0.0949],\n",
      "        [-0.0436,  0.2228],\n",
      "        [ 0.1392, -0.1157],\n",
      "        [ 0.1349,  0.2811],\n",
      "        [ 0.2656,  0.2046],\n",
      "        [ 0.2522,  0.0276],\n",
      "        [ 0.1036, -0.0426],\n",
      "        [ 0.0671,  0.1397],\n",
      "        [ 0.2950, -0.0792],\n",
      "        [-0.0896,  0.1231],\n",
      "        [-0.0862,  0.1920],\n",
      "        [ 0.1015, -0.0848],\n",
      "        [ 0.3677,  0.1326],\n",
      "        [ 0.2585, -0.0785],\n",
      "        [ 0.0656,  0.0816],\n",
      "        [ 0.1488, -0.0185],\n",
      "        [ 0.0454, -0.0472],\n",
      "        [ 0.2005, -0.3896]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.1111, -0.3066],\n",
      "        [-0.2814, -0.4044],\n",
      "        [ 0.1690, -0.2462],\n",
      "        [ 0.1165, -0.2792],\n",
      "        [-0.1538, -0.1279],\n",
      "        [-0.1487, -0.0640],\n",
      "        [ 0.0603, -0.2913],\n",
      "        [-0.1053, -0.3342],\n",
      "        [-0.0420, -0.3089],\n",
      "        [-0.0950, -0.2894],\n",
      "        [-0.0099, -0.1507],\n",
      "        [ 0.0891, -0.2218],\n",
      "        [ 0.0667, -0.3971],\n",
      "        [-0.0673,  0.0882],\n",
      "        [ 0.0497, -0.3338],\n",
      "        [-0.0310, -0.1732],\n",
      "        [-0.0470, -0.4344],\n",
      "        [ 0.1141, -0.0414],\n",
      "        [-0.2049, -0.3419],\n",
      "        [-0.0273, -0.5792],\n",
      "        [ 0.0888, -0.1768],\n",
      "        [ 0.3606, -0.0231],\n",
      "        [-0.0053, -0.2785],\n",
      "        [-0.0241,  0.0920],\n",
      "        [-0.0790, -0.2439],\n",
      "        [ 0.0698, -0.3542],\n",
      "        [-0.1153, -0.1338],\n",
      "        [ 0.1154, -0.1281],\n",
      "        [-0.1129, -0.4569],\n",
      "        [ 0.0953, -0.3322],\n",
      "        [ 0.1729, -0.1807],\n",
      "        [ 0.1636, -0.3004]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6746, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4524, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1270, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1270, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  14%|█████████▌                                                            | 30/219 [04:50<30:41,  9.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.3809, -0.1006],\n",
      "        [-0.0637,  0.0793],\n",
      "        [ 0.2377, -0.0282],\n",
      "        [-0.0572,  0.3100],\n",
      "        [ 0.2488,  0.0335],\n",
      "        [ 0.1812,  0.2181],\n",
      "        [ 0.0670,  0.0936],\n",
      "        [-0.1165,  0.1194],\n",
      "        [ 0.1278, -0.1855],\n",
      "        [ 0.0029,  0.2483],\n",
      "        [-0.1010,  0.1170],\n",
      "        [ 0.1160,  0.0461],\n",
      "        [-0.0548,  0.1760],\n",
      "        [ 0.3321,  0.2450],\n",
      "        [-0.0582,  0.2974],\n",
      "        [ 0.2026,  0.3346],\n",
      "        [-0.2208,  0.1050],\n",
      "        [-0.3179, -0.0811],\n",
      "        [ 0.0566,  0.3646],\n",
      "        [ 0.0196,  0.0644],\n",
      "        [-0.0662,  0.2474],\n",
      "        [ 0.1200, -0.1001],\n",
      "        [ 0.0149, -0.2020],\n",
      "        [ 0.0907,  0.1250],\n",
      "        [ 0.2625, -0.2728],\n",
      "        [ 0.0625,  0.1310],\n",
      "        [-0.0237,  0.1683],\n",
      "        [-0.1365, -0.1075],\n",
      "        [-0.1377,  0.0181],\n",
      "        [-0.0588,  0.2721],\n",
      "        [ 0.2654,  0.2597],\n",
      "        [-0.0753,  0.1784]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.0118, -0.3537],\n",
      "        [-0.0974, -0.2091],\n",
      "        [ 0.0819, -0.0543],\n",
      "        [ 0.1173, -0.4715],\n",
      "        [-0.0187,  0.0038],\n",
      "        [-0.1085, -0.3069],\n",
      "        [ 0.1457, -0.0499],\n",
      "        [ 0.0711, -0.2576],\n",
      "        [-0.0150, -0.0977],\n",
      "        [ 0.1534, -0.3115],\n",
      "        [-0.0147, -0.1684],\n",
      "        [-0.2254, -0.2090],\n",
      "        [ 0.0201, -0.0263],\n",
      "        [ 0.0405, -0.3365],\n",
      "        [ 0.0575,  0.0372],\n",
      "        [ 0.1683, -0.3052],\n",
      "        [ 0.0442, -0.1942],\n",
      "        [-0.1888, -0.1504],\n",
      "        [ 0.0715, -0.2130],\n",
      "        [ 0.0077, -0.2731],\n",
      "        [ 0.1342,  0.1364],\n",
      "        [ 0.0461, -0.0257],\n",
      "        [ 0.2235, -0.1898],\n",
      "        [-0.0569, -0.2771],\n",
      "        [-0.0922, -0.0168],\n",
      "        [-0.0493, -0.2638],\n",
      "        [-0.1543, -0.1472],\n",
      "        [ 0.0294, -0.2612],\n",
      "        [ 0.0444, -0.2151],\n",
      "        [ 0.0914, -0.2611],\n",
      "        [-0.0702, -0.1303],\n",
      "        [-0.2877, -0.1442]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7237, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5168, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2405, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2405, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  14%|█████████▉                                                            | 31/219 [05:00<30:36,  9.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1052,  0.1814],\n",
      "        [ 0.1261,  0.1022],\n",
      "        [ 0.0545,  0.2240],\n",
      "        [-0.0694,  0.2779],\n",
      "        [-0.1082,  0.0470],\n",
      "        [ 0.1315,  0.2033],\n",
      "        [ 0.0613,  0.2975],\n",
      "        [-0.1222,  0.0911],\n",
      "        [-0.0056,  0.1613],\n",
      "        [-0.0652,  0.1618],\n",
      "        [-0.1593,  0.1158],\n",
      "        [ 0.1788,  0.0796],\n",
      "        [ 0.0134,  0.0937],\n",
      "        [-0.0435, -0.1261],\n",
      "        [-0.2366,  0.0224],\n",
      "        [ 0.1725, -0.0454],\n",
      "        [-0.1308,  0.1805],\n",
      "        [ 0.0035,  0.1217],\n",
      "        [-0.0157, -0.0797],\n",
      "        [-0.1041,  0.1026],\n",
      "        [ 0.2201,  0.1310],\n",
      "        [-0.1481, -0.0377],\n",
      "        [-0.2046,  0.2194],\n",
      "        [-0.1280,  0.0199],\n",
      "        [-0.0332,  0.3726],\n",
      "        [-0.0793,  0.3582],\n",
      "        [-0.0427,  0.0997],\n",
      "        [ 0.2112,  0.1219],\n",
      "        [-0.0740, -0.0191],\n",
      "        [ 0.0371,  0.2008],\n",
      "        [ 0.0315, -0.5175],\n",
      "        [ 0.0923,  0.2421]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.1405, -0.0728],\n",
      "        [-0.0230, -0.0678],\n",
      "        [ 0.0670, -0.3277],\n",
      "        [ 0.1362, -0.2018],\n",
      "        [-0.0323, -0.3528],\n",
      "        [-0.1258, -0.3068],\n",
      "        [-0.1146, -0.2952],\n",
      "        [ 0.0759, -0.3774],\n",
      "        [-0.0117, -0.3668],\n",
      "        [ 0.0120,  0.0371],\n",
      "        [-0.0026, -0.1973],\n",
      "        [ 0.1580, -0.3289],\n",
      "        [ 0.0405, -0.1692],\n",
      "        [ 0.0812, -0.0249],\n",
      "        [-0.1665, -0.4175],\n",
      "        [ 0.0227, -0.2038],\n",
      "        [ 0.0838, -0.0344],\n",
      "        [ 0.0880,  0.0701],\n",
      "        [-0.0214, -0.2262],\n",
      "        [ 0.0920, -0.2305],\n",
      "        [-0.1096, -0.2623],\n",
      "        [ 0.0077, -0.3159],\n",
      "        [-0.2969, -0.4673],\n",
      "        [-0.1713, -0.0427],\n",
      "        [-0.1347, -0.4917],\n",
      "        [-0.0142,  0.1010],\n",
      "        [ 0.0169, -0.2334],\n",
      "        [-0.1408, -0.2699],\n",
      "        [ 0.0415,  0.0513],\n",
      "        [ 0.1459, -0.0404],\n",
      "        [-0.0666, -0.2596],\n",
      "        [-0.0210, -0.2300]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6569, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.3836, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.0405, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.0405, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  15%|██████████▏                                                           | 32/219 [05:09<30:23,  9.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0072,  0.1061],\n",
      "        [-0.0508,  0.2868],\n",
      "        [ 0.0948,  0.2834],\n",
      "        [-0.1802,  0.1975],\n",
      "        [ 0.1591,  0.1942],\n",
      "        [-0.1778,  0.4303],\n",
      "        [ 0.2839,  0.2544],\n",
      "        [-0.1157,  0.3468],\n",
      "        [-0.0743,  0.1764],\n",
      "        [-0.1117,  0.2255],\n",
      "        [ 0.0657, -0.0462],\n",
      "        [-0.0562,  0.4708],\n",
      "        [-0.2023,  0.2592],\n",
      "        [-0.0989,  0.3944],\n",
      "        [ 0.0370,  0.2555],\n",
      "        [-0.0650,  0.1123],\n",
      "        [-0.1180,  0.3827],\n",
      "        [ 0.2253,  0.3227],\n",
      "        [-0.3147,  0.2459],\n",
      "        [-0.0774,  0.0208],\n",
      "        [-0.0775,  0.2051],\n",
      "        [-0.1327,  0.1876],\n",
      "        [ 0.0104,  0.1647],\n",
      "        [ 0.0589,  0.1539],\n",
      "        [ 0.0422,  0.0521],\n",
      "        [ 0.6188,  0.0792],\n",
      "        [-0.1109,  0.0610],\n",
      "        [ 0.0410,  0.1471],\n",
      "        [ 0.0771,  0.3737],\n",
      "        [ 0.0390,  0.1690],\n",
      "        [-0.1511,  0.2783],\n",
      "        [-0.0413, -0.0442]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.1497, -0.0755],\n",
      "        [ 0.0363, -0.0502],\n",
      "        [ 0.1798, -0.5137],\n",
      "        [-0.0439, -0.0437],\n",
      "        [-0.1194, -0.0718],\n",
      "        [-0.0536, -0.0211],\n",
      "        [ 0.2116, -0.2392],\n",
      "        [-0.0381, -0.1878],\n",
      "        [ 0.0126, -0.2869],\n",
      "        [-0.0371, -0.1217],\n",
      "        [ 0.0310, -0.3807],\n",
      "        [ 0.1822,  0.0020],\n",
      "        [-0.0203, -0.1458],\n",
      "        [ 0.0881, -0.1824],\n",
      "        [-0.1472, -0.1819],\n",
      "        [ 0.1265, -0.3120],\n",
      "        [-0.1499, -0.1168],\n",
      "        [-0.0137, -0.0690],\n",
      "        [-0.0399, -0.1488],\n",
      "        [-0.0114, -0.3423],\n",
      "        [ 0.1575, -0.1714],\n",
      "        [-0.0408, -0.1623],\n",
      "        [-0.1658, -0.1768],\n",
      "        [ 0.1386, -0.2604],\n",
      "        [-0.1666, -0.1164],\n",
      "        [-0.2355, -0.2027],\n",
      "        [ 0.0890, -0.1652],\n",
      "        [ 0.0474, -0.0481],\n",
      "        [-0.0736, -0.1742],\n",
      "        [ 0.0027,  0.0011],\n",
      "        [ 0.1885, -0.2967],\n",
      "        [ 0.0507, -0.1697]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7046, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4948, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1995, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1995, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  15%|██████████▌                                                           | 33/219 [05:19<30:07,  9.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0708,  0.2801],\n",
      "        [-0.0303,  0.0825],\n",
      "        [-0.1681,  0.2736],\n",
      "        [-0.2401,  0.3143],\n",
      "        [ 0.1125,  0.0650],\n",
      "        [ 0.0958,  0.3923],\n",
      "        [-0.3084,  0.2729],\n",
      "        [-0.1115,  0.1488],\n",
      "        [-0.1683,  0.2375],\n",
      "        [-0.0078,  0.2050],\n",
      "        [-0.4591,  0.2073],\n",
      "        [ 0.0756,  0.0681],\n",
      "        [-0.1897,  0.4192],\n",
      "        [-0.1850,  0.2770],\n",
      "        [ 0.0225,  0.0623],\n",
      "        [-0.2282,  0.2599],\n",
      "        [ 0.0857,  0.3932],\n",
      "        [-0.0956,  0.1993],\n",
      "        [-0.1393,  0.2727],\n",
      "        [-0.1944,  0.1840],\n",
      "        [-0.0831,  0.1175],\n",
      "        [-0.1852,  0.3703],\n",
      "        [-0.2560,  0.3939],\n",
      "        [ 0.0898,  0.2786],\n",
      "        [-0.0513,  0.4425],\n",
      "        [-0.1536,  0.0553],\n",
      "        [-0.0381,  0.2025],\n",
      "        [ 0.2389,  0.1059],\n",
      "        [-0.3018,  0.3654],\n",
      "        [-0.0653,  0.2772],\n",
      "        [ 0.0165,  0.5418],\n",
      "        [-0.1736,  0.1913]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.0293, -0.3124],\n",
      "        [-0.0622, -0.3303],\n",
      "        [-0.1010, -0.3084],\n",
      "        [ 0.0860, -0.3949],\n",
      "        [-0.1242, -0.1227],\n",
      "        [ 0.0780, -0.1185],\n",
      "        [-0.0687, -0.3168],\n",
      "        [-0.2310, -0.3247],\n",
      "        [ 0.0434, -0.3594],\n",
      "        [ 0.0941, -0.0221],\n",
      "        [-0.1325, -0.2297],\n",
      "        [-0.0957, -0.1246],\n",
      "        [ 0.2133, -0.1704],\n",
      "        [ 0.2391, -0.1225],\n",
      "        [ 0.0529, -0.0597],\n",
      "        [ 0.0541, -0.2983],\n",
      "        [-0.2737, -0.3343],\n",
      "        [ 0.0511, -0.1947],\n",
      "        [-0.0219, -0.3247],\n",
      "        [-0.1071, -0.2451],\n",
      "        [ 0.0592, -0.1893],\n",
      "        [ 0.1480, -0.1576],\n",
      "        [-0.1365,  0.0220],\n",
      "        [-0.1834, -0.1514],\n",
      "        [-0.0578, -0.1397],\n",
      "        [ 0.0285, -0.1613],\n",
      "        [ 0.0925, -0.1210],\n",
      "        [-0.0474, -0.2117],\n",
      "        [-0.1612, -0.0461],\n",
      "        [-0.1736, -0.0162],\n",
      "        [ 0.2368, -0.3771],\n",
      "        [ 0.1376, -0.1054]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7240, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5172, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2412, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2412, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  16%|██████████▊                                                           | 34/219 [05:29<29:54,  9.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.1472,  0.3734],\n",
      "        [ 0.3259,  0.3410],\n",
      "        [-0.1584,  0.4331],\n",
      "        [-0.1085,  0.0125],\n",
      "        [-0.2375,  0.3088],\n",
      "        [-0.1652,  0.1584],\n",
      "        [-0.0168,  0.1687],\n",
      "        [ 0.0355,  0.3427],\n",
      "        [ 0.1239,  0.4269],\n",
      "        [ 0.0409,  0.5507],\n",
      "        [-0.1059,  0.0780],\n",
      "        [-0.0715,  0.2049],\n",
      "        [ 0.0183,  0.3491],\n",
      "        [-0.0709, -0.1383],\n",
      "        [-0.1245,  0.1630],\n",
      "        [-0.1528,  0.1697],\n",
      "        [-0.1115,  0.2664],\n",
      "        [-0.1815,  0.3520],\n",
      "        [ 0.0363,  0.0856],\n",
      "        [-0.0052,  0.4210],\n",
      "        [-0.1834,  0.1842],\n",
      "        [-0.1481,  0.1604],\n",
      "        [-0.0835,  0.1403],\n",
      "        [-0.0980,  0.2771],\n",
      "        [-0.1797,  0.4068],\n",
      "        [ 0.1367,  0.0337],\n",
      "        [-0.3417,  0.1761],\n",
      "        [ 0.1514,  0.4303],\n",
      "        [-0.4212, -0.2243],\n",
      "        [-0.0205,  0.2013],\n",
      "        [-0.1606,  0.5273],\n",
      "        [-0.0934, -0.1527]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.1221,  0.0433],\n",
      "        [-0.0641, -0.1280],\n",
      "        [-0.1148, -0.1357],\n",
      "        [ 0.1379,  0.0243],\n",
      "        [ 0.0885, -0.4475],\n",
      "        [-0.0590, -0.4203],\n",
      "        [ 0.1505, -0.1799],\n",
      "        [ 0.0955, -0.2894],\n",
      "        [ 0.1481, -0.3504],\n",
      "        [ 0.1406, -0.2250],\n",
      "        [-0.2553, -0.4856],\n",
      "        [ 0.0498, -0.3709],\n",
      "        [ 0.0653, -0.2806],\n",
      "        [-0.0062, -0.4258],\n",
      "        [-0.1690, -0.3031],\n",
      "        [-0.0705, -0.1282],\n",
      "        [-0.1254, -0.3299],\n",
      "        [-0.2119,  0.0102],\n",
      "        [ 0.0444, -0.1248],\n",
      "        [ 0.3133, -0.1379],\n",
      "        [ 0.2372,  0.2187],\n",
      "        [ 0.0769,  0.1253],\n",
      "        [ 0.1265,  0.2045],\n",
      "        [-0.1029, -0.2369],\n",
      "        [-0.0933, -0.6057],\n",
      "        [ 0.0925, -0.1311],\n",
      "        [-0.0495, -0.3669],\n",
      "        [ 0.0130, -0.1104],\n",
      "        [ 0.4345,  0.2532],\n",
      "        [ 0.1315, -0.0619],\n",
      "        [-0.0635, -0.2637],\n",
      "        [ 0.0607, -0.0568]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6779, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4645, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1424, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1424, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  16%|███████████▏                                                          | 35/219 [05:38<29:39,  9.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0779,  0.4008],\n",
      "        [-0.0224, -0.3220],\n",
      "        [ 0.0928, -0.5957],\n",
      "        [ 0.0739, -0.5266],\n",
      "        [ 0.1392, -0.0607],\n",
      "        [-0.0185,  0.1209],\n",
      "        [ 0.1258, -0.1756],\n",
      "        [-0.0260, -0.2330],\n",
      "        [ 0.1373,  0.3104],\n",
      "        [ 0.0859,  0.3700],\n",
      "        [ 0.0257, -0.3216],\n",
      "        [ 0.1980, -0.1580],\n",
      "        [ 0.0846, -0.4423],\n",
      "        [-0.1554, -0.4465],\n",
      "        [-0.1297, -0.4560],\n",
      "        [-0.1036, -0.1580],\n",
      "        [ 0.0858, -0.3846],\n",
      "        [-0.0903, -0.1220],\n",
      "        [ 0.0015, -0.7154],\n",
      "        [-0.0223, -0.1190],\n",
      "        [-0.0197, -0.1643],\n",
      "        [-0.0602,  0.1917],\n",
      "        [-0.1197,  0.3276],\n",
      "        [-0.0663, -0.1916],\n",
      "        [-0.0739, -0.3857],\n",
      "        [-0.0811,  0.4734],\n",
      "        [-0.0935, -0.2230],\n",
      "        [ 0.0126, -0.0417],\n",
      "        [ 0.0458, -0.2372],\n",
      "        [ 0.2723, -0.2990],\n",
      "        [ 0.2834, -0.4163],\n",
      "        [ 0.0750, -0.3862]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.2472, -0.1984],\n",
      "        [ 0.4403,  0.2369],\n",
      "        [ 0.3384,  0.4175],\n",
      "        [ 0.2414,  0.3145],\n",
      "        [ 0.2409, -0.2740],\n",
      "        [ 0.0017, -0.3122],\n",
      "        [ 0.2199,  0.3402],\n",
      "        [ 0.4488, -0.1626],\n",
      "        [ 0.0415,  0.0459],\n",
      "        [ 0.1616, -0.5242],\n",
      "        [ 0.2840,  0.3271],\n",
      "        [ 0.2927, -0.1067],\n",
      "        [ 0.2117,  0.3034],\n",
      "        [ 0.2484,  0.4019],\n",
      "        [ 0.3055,  0.2087],\n",
      "        [ 0.2830,  0.1679],\n",
      "        [ 0.2327,  0.3339],\n",
      "        [ 0.3746,  0.3181],\n",
      "        [ 0.1301,  0.2730],\n",
      "        [ 0.0439,  0.0073],\n",
      "        [ 0.3470,  0.3109],\n",
      "        [ 0.0058, -0.2189],\n",
      "        [-0.1266, -0.4111],\n",
      "        [ 0.4752,  0.0833],\n",
      "        [ 0.1857,  0.3147],\n",
      "        [-0.3112, -0.3524],\n",
      "        [ 0.3115,  0.3507],\n",
      "        [ 0.3557,  0.0821],\n",
      "        [ 0.1437,  0.5937],\n",
      "        [ 0.3693,  0.2821],\n",
      "        [ 0.2708,  0.2653],\n",
      "        [-0.0078,  0.3236]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7322, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4609, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1931, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1931, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  16%|███████████▌                                                          | 36/219 [05:48<29:26,  9.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.1020, -0.3852],\n",
      "        [ 0.1616,  0.1026],\n",
      "        [-0.1703, -0.3944],\n",
      "        [-0.2775, -0.3364],\n",
      "        [-0.2648, -0.2219],\n",
      "        [-0.2877, -0.0803],\n",
      "        [-0.2231, -0.4484],\n",
      "        [ 0.0695,  0.2826],\n",
      "        [-0.2540, -0.1666],\n",
      "        [-0.1710, -0.1434],\n",
      "        [-0.1665, -0.3640],\n",
      "        [ 0.0094, -0.1353],\n",
      "        [-0.2265, -0.2556],\n",
      "        [-0.1560,  0.0868],\n",
      "        [-0.1006, -0.3416],\n",
      "        [ 0.1803, -0.0167],\n",
      "        [-0.1885,  0.1396],\n",
      "        [-0.3669, -0.0261],\n",
      "        [-0.3792, -0.2026],\n",
      "        [-0.3675,  0.1414],\n",
      "        [-0.2056, -0.3358],\n",
      "        [-0.2817, -0.3435],\n",
      "        [-0.0994, -0.3091],\n",
      "        [-0.1790,  0.0424],\n",
      "        [-0.2537, -0.2144],\n",
      "        [-0.2338, -0.3125],\n",
      "        [-0.1839, -0.4042],\n",
      "        [-0.3256, -0.3447],\n",
      "        [-0.2192, -0.4119],\n",
      "        [-0.0224, -0.2244],\n",
      "        [-0.4004, -0.2264],\n",
      "        [-0.5610, -0.0968]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.1118,  0.3864],\n",
      "        [ 0.1433, -0.1767],\n",
      "        [ 0.3148,  0.5036],\n",
      "        [ 0.0692,  0.4163],\n",
      "        [ 0.0867,  0.4196],\n",
      "        [ 0.2304,  0.2281],\n",
      "        [ 0.2832,  0.3178],\n",
      "        [ 0.0524, -0.2932],\n",
      "        [ 0.3100,  0.6486],\n",
      "        [ 0.0177,  0.3486],\n",
      "        [ 0.1200,  0.5953],\n",
      "        [ 0.4370,  0.4202],\n",
      "        [ 0.2163,  0.3075],\n",
      "        [ 0.2912, -0.1784],\n",
      "        [ 0.2616,  0.3215],\n",
      "        [-0.0233, -0.0835],\n",
      "        [ 0.3564,  0.4559],\n",
      "        [ 0.3066,  0.3175],\n",
      "        [ 0.3476,  0.2241],\n",
      "        [ 0.3782,  0.1585],\n",
      "        [ 0.3008,  0.4387],\n",
      "        [ 0.1881,  0.4761],\n",
      "        [ 0.2895,  0.4622],\n",
      "        [ 0.1559,  0.7134],\n",
      "        [ 0.1152,  0.0762],\n",
      "        [ 0.0782,  0.2747],\n",
      "        [ 0.2629,  0.5905],\n",
      "        [ 0.0871,  0.3306],\n",
      "        [ 0.2786,  0.4604],\n",
      "        [ 0.2711,  0.3145],\n",
      "        [ 0.4664,  0.4744],\n",
      "        [ 0.0414,  0.3460]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6891, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4185, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1076, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1076, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  17%|███████████▊                                                          | 37/219 [05:58<29:16,  9.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.1448, -0.0669],\n",
      "        [-0.4462, -0.0649],\n",
      "        [ 0.2165,  0.4768],\n",
      "        [-0.0477, -0.3885],\n",
      "        [-0.5651, -0.1367],\n",
      "        [-0.1958, -0.2986],\n",
      "        [-0.2559,  0.0285],\n",
      "        [-0.1416, -0.2592],\n",
      "        [-0.4244,  0.0699],\n",
      "        [ 0.1851, -0.3759],\n",
      "        [-0.2121,  0.0221],\n",
      "        [-0.3803, -0.0458],\n",
      "        [-0.2756,  0.1790],\n",
      "        [-0.3665,  0.1213],\n",
      "        [-0.2934,  0.0555],\n",
      "        [-0.1164, -0.0764],\n",
      "        [-0.4496, -0.2717],\n",
      "        [-0.2201, -0.0761],\n",
      "        [-0.2101, -0.0456],\n",
      "        [ 0.0798, -0.3243],\n",
      "        [-0.4274, -0.2895],\n",
      "        [ 0.0072, -0.1150],\n",
      "        [-0.3853,  0.0259],\n",
      "        [-0.2813,  0.2315],\n",
      "        [-0.2723, -0.1085],\n",
      "        [-0.3152, -0.2025],\n",
      "        [ 0.3271,  0.0824],\n",
      "        [-0.2534, -0.0405],\n",
      "        [-0.0367, -0.0178],\n",
      "        [ 0.0374, -0.2088],\n",
      "        [-0.3514, -0.1358],\n",
      "        [-0.3917, -0.4665]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.2153,  0.5972],\n",
      "        [ 0.1162,  0.2766],\n",
      "        [-0.2129, -0.1960],\n",
      "        [ 0.6349,  0.3009],\n",
      "        [ 0.2044,  0.4147],\n",
      "        [ 0.3776,  0.7603],\n",
      "        [ 0.1485,  0.9220],\n",
      "        [ 0.0795,  0.5444],\n",
      "        [ 0.0509,  0.5972],\n",
      "        [ 0.2824,  0.1380],\n",
      "        [ 0.2684,  0.3191],\n",
      "        [ 0.1895,  0.7252],\n",
      "        [ 0.3346,  0.4642],\n",
      "        [ 0.3543,  0.6510],\n",
      "        [ 0.2368,  0.5265],\n",
      "        [ 0.1066,  0.5769],\n",
      "        [ 0.1666,  0.2939],\n",
      "        [ 0.0337,  0.5337],\n",
      "        [ 0.2032,  0.5755],\n",
      "        [ 0.0991,  0.5880],\n",
      "        [ 0.3375,  0.7973],\n",
      "        [ 0.2114, -0.1539],\n",
      "        [ 0.5732,  0.2563],\n",
      "        [ 0.0020,  0.3020],\n",
      "        [ 0.1694,  0.4187],\n",
      "        [ 0.1157,  0.6231],\n",
      "        [-0.0523, -0.3578],\n",
      "        [ 0.1523,  0.5112],\n",
      "        [ 0.2289,  0.7157],\n",
      "        [ 0.2864,  0.2155],\n",
      "        [ 0.3310,  0.5122],\n",
      "        [ 0.5764,  0.1334]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6852, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5602, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2454, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2454, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  17%|████████████▏                                                         | 38/219 [06:07<29:07,  9.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.5805,  0.0262],\n",
      "        [-0.2736, -0.0226],\n",
      "        [-0.4534,  0.1497],\n",
      "        [-0.3696,  0.0817],\n",
      "        [-0.5364,  0.2156],\n",
      "        [-0.3719, -0.1610],\n",
      "        [-0.2975,  0.2147],\n",
      "        [-0.3288,  0.0198],\n",
      "        [ 0.3087, -0.3403],\n",
      "        [-0.2652,  0.2488],\n",
      "        [-0.2964,  0.0669],\n",
      "        [-0.6772,  0.0768],\n",
      "        [-0.3211,  0.2304],\n",
      "        [-0.7240,  0.4864],\n",
      "        [-0.4842, -0.0914],\n",
      "        [-0.2899,  0.0150],\n",
      "        [-0.3310, -0.0717],\n",
      "        [-0.3513,  0.1944],\n",
      "        [-0.0706,  0.1201],\n",
      "        [-0.2947,  0.1899],\n",
      "        [-0.1109, -0.0189],\n",
      "        [-0.5472, -0.0484],\n",
      "        [-0.4359,  0.2079],\n",
      "        [ 0.0495, -0.2965],\n",
      "        [-0.1958,  0.0872],\n",
      "        [-0.1700,  0.0990],\n",
      "        [-0.2858,  0.5428],\n",
      "        [-0.3165, -0.3478],\n",
      "        [-0.2611,  0.1812],\n",
      "        [-0.6160,  0.3218],\n",
      "        [-0.3870,  0.2615],\n",
      "        [-0.4492,  0.2657]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.0175,  0.7152],\n",
      "        [ 0.1080,  0.4971],\n",
      "        [ 0.1061,  0.5866],\n",
      "        [ 0.2261,  0.4385],\n",
      "        [ 0.0472,  0.4618],\n",
      "        [ 0.2266,  0.5337],\n",
      "        [ 0.5056,  0.2546],\n",
      "        [ 0.2743,  0.4608],\n",
      "        [ 0.1109, -0.0381],\n",
      "        [ 0.1296,  0.7694],\n",
      "        [ 0.2949,  0.4724],\n",
      "        [ 0.2862,  0.3863],\n",
      "        [ 0.1378,  0.2307],\n",
      "        [ 0.1578,  0.3242],\n",
      "        [ 0.0604,  0.5630],\n",
      "        [ 0.0867,  0.6319],\n",
      "        [ 0.2024,  0.4535],\n",
      "        [ 0.2782,  0.3539],\n",
      "        [ 0.0140,  0.6573],\n",
      "        [ 0.0464,  0.5959],\n",
      "        [ 0.1295,  0.3734],\n",
      "        [ 0.3025,  0.4032],\n",
      "        [ 0.0756,  0.4182],\n",
      "        [ 0.3039,  0.2089],\n",
      "        [ 0.2078,  0.2408],\n",
      "        [ 0.1843,  0.5610],\n",
      "        [ 0.1108,  0.3063],\n",
      "        [ 0.1783,  0.5780],\n",
      "        [ 0.2415,  0.5994],\n",
      "        [ 0.1678,  0.2520],\n",
      "        [ 0.1315,  0.6450],\n",
      "        [ 0.2231,  0.4560]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7312, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4971, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2283, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2283, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  18%|████████████▍                                                         | 39/219 [06:17<28:58,  9.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.1450,  0.2433],\n",
      "        [-0.2452,  0.3817],\n",
      "        [ 0.0666, -0.4154],\n",
      "        [-0.4797,  0.1727],\n",
      "        [-0.3593, -0.1443],\n",
      "        [ 0.1483, -0.0758],\n",
      "        [-0.3481, -0.1287],\n",
      "        [-0.5792, -0.0036],\n",
      "        [-0.0223,  0.0750],\n",
      "        [-0.2556,  0.2526],\n",
      "        [-0.1811,  0.1002],\n",
      "        [-0.4499,  0.1736],\n",
      "        [-0.5533,  0.3080],\n",
      "        [-0.4153, -0.0678],\n",
      "        [-0.3415, -0.1229],\n",
      "        [-0.8419,  0.1804],\n",
      "        [ 0.1902, -0.3292],\n",
      "        [-0.3138,  0.1485],\n",
      "        [-0.2994,  0.1390],\n",
      "        [-0.1224, -0.1055],\n",
      "        [ 0.0694, -0.2952],\n",
      "        [-0.3367,  0.1227],\n",
      "        [ 0.3307, -0.1594],\n",
      "        [-0.2921,  0.1289],\n",
      "        [-0.2650, -0.0085],\n",
      "        [ 0.1853, -0.2786],\n",
      "        [-0.1216, -0.1136],\n",
      "        [-0.4415, -0.0880],\n",
      "        [ 0.1433, -0.3694],\n",
      "        [-0.5831, -0.2651],\n",
      "        [-0.0281,  0.0841],\n",
      "        [ 0.3221,  0.0636]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.1741,  0.2751],\n",
      "        [-0.0406,  0.4853],\n",
      "        [ 0.4180,  0.3276],\n",
      "        [ 0.3496,  0.6367],\n",
      "        [ 0.2379,  0.5085],\n",
      "        [ 0.2046,  0.5836],\n",
      "        [ 0.2528,  0.5242],\n",
      "        [ 0.3104,  0.2834],\n",
      "        [ 0.0359,  0.6506],\n",
      "        [ 0.2675,  0.6577],\n",
      "        [ 0.2566,  0.5600],\n",
      "        [ 0.2186,  0.6198],\n",
      "        [ 0.0910,  0.5467],\n",
      "        [ 0.1054,  0.4692],\n",
      "        [ 0.1589,  0.4242],\n",
      "        [ 0.2307,  0.5816],\n",
      "        [ 0.1781,  0.0823],\n",
      "        [ 0.3108,  0.4692],\n",
      "        [ 0.2835,  0.4606],\n",
      "        [ 0.2895,  0.6494],\n",
      "        [ 0.3761,  0.2581],\n",
      "        [ 0.4024,  0.6383],\n",
      "        [ 0.6788,  0.3045],\n",
      "        [ 0.1710,  0.6694],\n",
      "        [ 0.0726,  0.6074],\n",
      "        [-0.1352, -0.4096],\n",
      "        [ 0.1478,  0.3898],\n",
      "        [ 0.4806,  0.6113],\n",
      "        [ 0.3944, -0.0191],\n",
      "        [ 0.2325,  0.4582],\n",
      "        [ 0.0650,  0.2985],\n",
      "        [ 0.2039, -0.0406]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6582, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4937, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1519, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1519, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  18%|████████████▊                                                         | 40/219 [06:26<28:47,  9.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.3623, -0.1122],\n",
      "        [-0.3008, -0.0668],\n",
      "        [-0.2763,  0.0280],\n",
      "        [-0.1336, -0.0359],\n",
      "        [-0.4016,  0.0641],\n",
      "        [-0.0120, -0.0877],\n",
      "        [-0.4163,  0.0798],\n",
      "        [-0.1948,  0.0548],\n",
      "        [-0.2957, -0.1670],\n",
      "        [-0.1281,  0.1925],\n",
      "        [-0.3551,  0.0456],\n",
      "        [-0.1657,  0.0278],\n",
      "        [-0.6148,  0.1257],\n",
      "        [-0.2822, -0.0632],\n",
      "        [ 0.1431, -0.4210],\n",
      "        [-0.3431,  0.1517],\n",
      "        [-0.3095,  0.1796],\n",
      "        [ 0.3761,  0.0523],\n",
      "        [-0.1844, -0.5750],\n",
      "        [-0.2516,  0.0727],\n",
      "        [-0.2951,  0.0373],\n",
      "        [-0.3636, -0.0315],\n",
      "        [-0.6913, -0.0247],\n",
      "        [-0.4456, -0.0210],\n",
      "        [-0.5321,  0.4462],\n",
      "        [-0.0445, -0.0124],\n",
      "        [-0.1817,  0.2738],\n",
      "        [-0.3876,  0.1139],\n",
      "        [-0.1561, -0.1891],\n",
      "        [-0.0514, -0.0149],\n",
      "        [-0.3144, -0.0199],\n",
      "        [-0.3951,  0.2221]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 1.8188e-01,  8.5711e-01],\n",
      "        [ 9.6223e-02,  6.7101e-01],\n",
      "        [ 3.0246e-01,  5.2390e-01],\n",
      "        [-5.8295e-03,  5.6201e-01],\n",
      "        [ 1.3257e-01,  4.0559e-01],\n",
      "        [ 3.6258e-01,  6.8985e-01],\n",
      "        [-6.9834e-04,  7.7435e-01],\n",
      "        [ 3.5046e-01,  6.3072e-01],\n",
      "        [ 2.0770e-01,  7.7806e-01],\n",
      "        [ 2.6638e-01,  5.2003e-01],\n",
      "        [ 3.8808e-01,  7.5339e-01],\n",
      "        [ 3.7876e-01,  5.5275e-01],\n",
      "        [ 4.9928e-01,  5.9260e-01],\n",
      "        [ 1.2745e-01,  8.1257e-01],\n",
      "        [ 4.9031e-01,  3.9717e-01],\n",
      "        [ 2.5094e-01,  4.2668e-01],\n",
      "        [-1.3305e-02,  5.7220e-01],\n",
      "        [ 3.5812e-01,  1.6050e-01],\n",
      "        [ 1.5995e-01,  6.8791e-01],\n",
      "        [ 3.8130e-01,  3.5861e-01],\n",
      "        [ 1.0213e-01,  7.6467e-01],\n",
      "        [ 3.4783e-02,  5.7805e-01],\n",
      "        [ 1.9089e-01,  5.4856e-01],\n",
      "        [ 2.3715e-01,  6.1151e-01],\n",
      "        [ 4.0732e-01,  4.2009e-01],\n",
      "        [ 2.1714e-01,  6.8614e-01],\n",
      "        [-2.8211e-02,  4.4801e-01],\n",
      "        [ 2.6093e-01,  3.6807e-01],\n",
      "        [ 1.9855e-01,  8.8485e-01],\n",
      "        [ 1.9028e-01,  3.8198e-01],\n",
      "        [ 1.6321e-01,  7.0964e-01],\n",
      "        [ 1.7471e-01,  5.3199e-01]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7302, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5710, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.3012, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.3012, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|█████████████                                                         | 41/219 [06:37<29:15,  9.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.1805, -0.1088],\n",
      "        [-0.1383, -0.1479],\n",
      "        [-0.4120, -0.2376],\n",
      "        [-0.4195,  0.0335],\n",
      "        [-0.2775, -0.3170],\n",
      "        [-0.0535, -0.3690],\n",
      "        [-0.4084,  0.0129],\n",
      "        [-0.1182, -0.1313],\n",
      "        [-0.0654, -0.0651],\n",
      "        [-0.1775, -0.2825],\n",
      "        [-0.3109, -0.2127],\n",
      "        [-0.1288, -0.0608],\n",
      "        [-0.1757, -0.1968],\n",
      "        [ 0.0168, -0.3640],\n",
      "        [ 0.0377, -0.0106],\n",
      "        [-0.2270, -0.1032],\n",
      "        [-0.0401, -0.0054],\n",
      "        [ 0.0166, -0.0975],\n",
      "        [-0.1333, -0.5433],\n",
      "        [-0.2292,  0.0191],\n",
      "        [-0.1153, -0.2301],\n",
      "        [ 0.1930, -0.4617],\n",
      "        [-0.1554, -0.4180],\n",
      "        [-0.3351, -0.2874],\n",
      "        [-0.0943,  0.1704],\n",
      "        [-0.0607, -0.2019],\n",
      "        [-0.1006,  0.0583],\n",
      "        [-0.2420, -0.0120],\n",
      "        [-0.2677, -0.2625],\n",
      "        [-0.1536, -0.4263],\n",
      "        [-0.1213, -0.1568],\n",
      "        [-0.3326, -0.1255]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.2874,  0.7240],\n",
      "        [ 0.3474,  0.6478],\n",
      "        [ 0.2648,  0.4903],\n",
      "        [ 0.0638,  0.2872],\n",
      "        [ 0.3260,  0.5368],\n",
      "        [-0.0240,  0.6504],\n",
      "        [ 0.0498,  0.5284],\n",
      "        [ 0.0939,  0.4529],\n",
      "        [-0.0061,  0.7631],\n",
      "        [ 0.1314,  0.7505],\n",
      "        [ 0.2807,  0.6963],\n",
      "        [ 0.1809,  0.8341],\n",
      "        [ 0.3073,  0.5274],\n",
      "        [ 0.3238,  0.3630],\n",
      "        [ 0.1398,  0.6931],\n",
      "        [ 0.2740,  0.6901],\n",
      "        [ 0.2624,  0.4937],\n",
      "        [ 0.2253,  0.5500],\n",
      "        [ 0.2193,  1.1081],\n",
      "        [ 0.2034,  0.3939],\n",
      "        [ 0.2780,  0.9382],\n",
      "        [ 0.3318,  0.3614],\n",
      "        [ 0.3086,  0.7489],\n",
      "        [ 0.3342,  0.7544],\n",
      "        [ 0.0297,  0.4972],\n",
      "        [ 0.1804,  0.4391],\n",
      "        [ 0.4333,  0.1388],\n",
      "        [ 0.2052,  0.7375],\n",
      "        [-0.1085,  0.3628],\n",
      "        [-0.0208,  0.7416],\n",
      "        [ 0.4019,  0.3548],\n",
      "        [ 0.0281,  0.6467]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6847, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5592, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2439, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2439, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|█████████████▍                                                        | 42/219 [06:48<29:56, 10.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0115, -0.4635],\n",
      "        [-0.0795, -0.0857],\n",
      "        [-0.2284, -0.4318],\n",
      "        [ 0.0525, -0.1090],\n",
      "        [-0.0446, -0.4177],\n",
      "        [-0.2337, -0.4792],\n",
      "        [-0.2151, -0.2052],\n",
      "        [-0.1996, -0.0378],\n",
      "        [ 0.0014, -0.3393],\n",
      "        [ 0.1144, -0.6313],\n",
      "        [-0.2124, -0.0840],\n",
      "        [ 0.1224, -0.3802],\n",
      "        [ 0.0335, -0.3272],\n",
      "        [ 0.0221, -0.4121],\n",
      "        [-0.2200, -0.2296],\n",
      "        [-0.1898, -0.3664],\n",
      "        [-0.1975, -0.2975],\n",
      "        [-0.0561, -0.1688],\n",
      "        [ 0.0046, -0.4830],\n",
      "        [-0.2939, -0.2985],\n",
      "        [-0.0253, -0.0722],\n",
      "        [-0.1542, -0.5484],\n",
      "        [-0.1049, -0.4155],\n",
      "        [ 0.0139, -0.5005],\n",
      "        [ 0.1747, -0.1348],\n",
      "        [ 0.2498, -0.1192],\n",
      "        [-0.0267, -0.3260],\n",
      "        [-0.1520, -0.4383],\n",
      "        [-0.1977, -0.2227],\n",
      "        [ 0.3275, -0.3395],\n",
      "        [ 0.2673, -0.3184],\n",
      "        [-0.2675, -0.2203]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.4235,  0.6764],\n",
      "        [ 0.1640,  0.6888],\n",
      "        [ 0.3075,  0.3692],\n",
      "        [ 0.2149,  0.6549],\n",
      "        [ 0.0516,  0.8560],\n",
      "        [ 0.2598,  0.7465],\n",
      "        [ 0.3836,  0.5701],\n",
      "        [ 0.2586,  0.7117],\n",
      "        [ 0.0085,  0.7273],\n",
      "        [ 0.0965,  0.7799],\n",
      "        [ 0.2361,  0.6253],\n",
      "        [ 0.4101,  0.5768],\n",
      "        [ 0.2186,  0.6012],\n",
      "        [ 0.1304,  0.6855],\n",
      "        [ 0.5926,  0.5584],\n",
      "        [ 0.0258,  0.7896],\n",
      "        [ 0.0433,  0.9117],\n",
      "        [ 0.0869,  0.6542],\n",
      "        [ 0.0904,  0.8949],\n",
      "        [ 0.0408,  1.0066],\n",
      "        [ 0.2203,  0.6737],\n",
      "        [ 0.3791,  0.8644],\n",
      "        [ 0.6205,  0.2670],\n",
      "        [ 0.3949,  0.5014],\n",
      "        [ 0.1479,  0.7807],\n",
      "        [ 0.2599, -0.0046],\n",
      "        [ 0.0209,  0.7713],\n",
      "        [ 0.4256,  0.9107],\n",
      "        [ 0.2786,  0.7354],\n",
      "        [ 0.0616,  0.6062],\n",
      "        [ 0.1922,  0.7344],\n",
      "        [ 0.3117,  0.6893]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6789, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.6744, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.3533, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.3533, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  20%|█████████████▋                                                        | 43/219 [06:58<29:39, 10.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1325, -0.5666],\n",
      "        [ 0.1324, -0.3011],\n",
      "        [-0.0908, -0.7870],\n",
      "        [ 0.0555, -0.4207],\n",
      "        [-0.0407, -0.4921],\n",
      "        [ 0.1299, -0.3814],\n",
      "        [-0.1451, -0.4408],\n",
      "        [ 0.1125, -0.4995],\n",
      "        [ 0.2497, -0.6703],\n",
      "        [-0.2043, -0.5688],\n",
      "        [-0.3221, -0.6409],\n",
      "        [ 0.2068, -0.5268],\n",
      "        [ 0.2573, -0.6028],\n",
      "        [ 0.0395, -0.4683],\n",
      "        [ 0.2436, -0.5259],\n",
      "        [ 0.2456, -0.5288],\n",
      "        [ 0.1251, -0.4169],\n",
      "        [-0.0601, -0.5204],\n",
      "        [ 0.3776, -0.6598],\n",
      "        [ 0.0608, -0.4938],\n",
      "        [-0.0043, -0.3437],\n",
      "        [ 0.0795, -0.5444],\n",
      "        [ 0.3517, -0.4085],\n",
      "        [ 0.1745, -0.5163],\n",
      "        [ 0.1200, -0.2669],\n",
      "        [ 0.1478, -0.6005],\n",
      "        [-0.1876, -0.5397],\n",
      "        [ 0.0053, -0.4278],\n",
      "        [ 0.0391, -0.5095],\n",
      "        [-0.0934, -0.3077],\n",
      "        [ 0.3057, -0.4912],\n",
      "        [-0.0415, -0.4705]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.2363,  0.9024],\n",
      "        [-0.0859,  0.6582],\n",
      "        [-0.0854,  0.7569],\n",
      "        [ 0.2650,  0.6762],\n",
      "        [-0.2598,  0.6108],\n",
      "        [ 0.3878,  0.7751],\n",
      "        [ 0.1070,  0.6670],\n",
      "        [ 0.3213,  0.7315],\n",
      "        [ 0.2344,  0.6778],\n",
      "        [ 0.2194,  0.6240],\n",
      "        [ 0.1761,  0.5934],\n",
      "        [ 0.2187,  0.7857],\n",
      "        [ 0.3299,  0.6776],\n",
      "        [ 0.0909,  0.6681],\n",
      "        [ 0.0997,  0.5858],\n",
      "        [ 0.3373,  0.6824],\n",
      "        [ 0.1777,  0.8556],\n",
      "        [ 0.2977,  0.6167],\n",
      "        [-0.0017,  0.7733],\n",
      "        [ 0.1301,  0.7359],\n",
      "        [ 0.3510,  0.7478],\n",
      "        [ 0.3277,  0.4927],\n",
      "        [ 0.0045,  0.8525],\n",
      "        [ 0.0905,  0.7658],\n",
      "        [ 0.3648,  0.9241],\n",
      "        [ 0.2685,  0.7069],\n",
      "        [ 0.1630,  0.7055],\n",
      "        [ 0.2642,  0.5997],\n",
      "        [ 0.0756,  0.8496],\n",
      "        [ 0.1831,  0.6361],\n",
      "        [ 0.0799,  0.6663],\n",
      "        [ 0.0607,  0.6259]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7897, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4478, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2375, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2375, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  20%|██████████████                                                        | 44/219 [07:08<29:19, 10.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0903, -0.5883],\n",
      "        [-0.0458, -0.6907],\n",
      "        [ 0.0777, -0.7798],\n",
      "        [ 0.0636, -0.3992],\n",
      "        [ 0.0625, -0.3743],\n",
      "        [-0.1874, -0.6425],\n",
      "        [ 0.0448, -0.2004],\n",
      "        [-0.0778, -0.1015],\n",
      "        [-0.1185, -0.2947],\n",
      "        [ 0.0441, -0.4947],\n",
      "        [ 0.1851, -0.6768],\n",
      "        [-0.1698, -0.5262],\n",
      "        [ 0.1843, -0.1747],\n",
      "        [ 0.0790, -0.3865],\n",
      "        [ 0.0186, -0.5506],\n",
      "        [ 0.1782, -0.4952],\n",
      "        [-0.2067, -0.2860],\n",
      "        [ 0.0901, -0.4438],\n",
      "        [ 0.1374, -0.5937],\n",
      "        [-0.0101, -0.5512],\n",
      "        [ 0.1013, -0.5694],\n",
      "        [ 0.3337, -0.5671],\n",
      "        [ 0.0835, -0.5551],\n",
      "        [ 0.0614, -0.8448],\n",
      "        [-0.0022, -0.4418],\n",
      "        [-0.0337, -0.5959],\n",
      "        [-0.2677, -0.4516],\n",
      "        [ 0.2742, -0.4589],\n",
      "        [ 0.1849, -0.2666],\n",
      "        [ 0.2359, -0.5859],\n",
      "        [ 0.0039, -0.6067],\n",
      "        [-0.0451, -0.5726]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.1900,  0.4414],\n",
      "        [ 0.3260,  0.4894],\n",
      "        [ 0.2049,  0.7404],\n",
      "        [ 0.3258,  0.9986],\n",
      "        [ 0.1469,  0.5768],\n",
      "        [ 0.3719,  0.4980],\n",
      "        [ 0.3736,  0.6838],\n",
      "        [ 0.5748,  0.3482],\n",
      "        [ 0.1353,  0.6545],\n",
      "        [ 0.1837,  0.7037],\n",
      "        [ 0.5329,  0.7569],\n",
      "        [ 0.2884,  0.8849],\n",
      "        [ 0.1594,  0.4499],\n",
      "        [ 0.3939,  0.7419],\n",
      "        [ 0.0859,  0.6191],\n",
      "        [ 0.3297,  0.7268],\n",
      "        [ 0.4510,  0.4705],\n",
      "        [ 0.2013,  0.8166],\n",
      "        [ 0.1992,  0.7671],\n",
      "        [ 0.2832,  0.5623],\n",
      "        [ 0.1125,  0.9816],\n",
      "        [ 0.2812,  0.6881],\n",
      "        [ 0.4006,  0.7381],\n",
      "        [ 0.1869,  0.6907],\n",
      "        [ 0.0274,  0.7119],\n",
      "        [ 0.4717,  0.9279],\n",
      "        [-0.0402,  0.5014],\n",
      "        [ 0.0034,  0.6367],\n",
      "        [ 0.0171,  0.6409],\n",
      "        [ 0.2778,  0.7926],\n",
      "        [ 0.0846,  0.6067],\n",
      "        [ 0.1853,  0.5984]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7374, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5309, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2683, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2683, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|██████████████▍                                                       | 45/219 [07:17<28:59, 10.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.3139, -0.5708],\n",
      "        [ 0.3453, -0.6112],\n",
      "        [-0.1205, -0.5807],\n",
      "        [ 0.1851, -0.2173],\n",
      "        [ 0.2099, -0.2573],\n",
      "        [-0.0105, -0.0389],\n",
      "        [-0.0085, -0.6623],\n",
      "        [ 0.2756, -0.4121],\n",
      "        [ 0.0902, -0.5835],\n",
      "        [ 0.1506, -0.4561],\n",
      "        [ 0.1998, -0.3828],\n",
      "        [-0.2015, -0.2688],\n",
      "        [ 0.0961, -0.7307],\n",
      "        [ 0.0766, -0.2958],\n",
      "        [ 0.1941, -0.3107],\n",
      "        [ 0.0009, -0.4147],\n",
      "        [ 0.1534, -0.3213],\n",
      "        [ 0.0560, -0.2931],\n",
      "        [-0.0273, -0.3885],\n",
      "        [-0.0299, -0.5001],\n",
      "        [-0.0092, -0.3767],\n",
      "        [ 0.1408, -0.6072],\n",
      "        [ 0.3476, -0.2738],\n",
      "        [ 0.2716, -0.6167],\n",
      "        [ 0.0923, -0.6512],\n",
      "        [ 0.0640, -0.4566],\n",
      "        [-0.0297, -0.7076],\n",
      "        [-0.0051, -0.3783],\n",
      "        [ 0.1960, -0.3140],\n",
      "        [-0.1903, -0.6253],\n",
      "        [ 0.1183, -0.1926],\n",
      "        [ 0.2711, -0.2537]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[0.2979, 0.6865],\n",
      "        [0.2123, 0.8377],\n",
      "        [0.2676, 0.5370],\n",
      "        [0.4583, 0.8325],\n",
      "        [0.2390, 0.5952],\n",
      "        [0.4391, 0.7322],\n",
      "        [0.5623, 0.7272],\n",
      "        [0.1844, 0.6376],\n",
      "        [0.1522, 0.8909],\n",
      "        [0.5306, 0.5660],\n",
      "        [0.1974, 0.6442],\n",
      "        [0.4071, 0.7724],\n",
      "        [0.2188, 0.9259],\n",
      "        [0.2474, 0.9681],\n",
      "        [0.0561, 0.8927],\n",
      "        [0.2503, 0.4936],\n",
      "        [0.3173, 0.5010],\n",
      "        [0.3310, 0.5340],\n",
      "        [0.1501, 0.5354],\n",
      "        [0.1505, 0.8135],\n",
      "        [0.5092, 0.7762],\n",
      "        [0.1990, 0.6465],\n",
      "        [0.3118, 0.7367],\n",
      "        [0.4031, 1.0056],\n",
      "        [0.2246, 0.8219],\n",
      "        [0.2596, 0.5924],\n",
      "        [0.2359, 0.6120],\n",
      "        [0.2078, 0.7155],\n",
      "        [0.1598, 0.9395],\n",
      "        [0.3886, 0.7373],\n",
      "        [0.1910, 0.5749],\n",
      "        [0.1636, 0.6799]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7304, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4798, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2102, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2102, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|██████████████▋                                                       | 46/219 [07:27<28:34,  9.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.1253, -0.4498],\n",
      "        [ 0.0663, -0.1980],\n",
      "        [-0.2717, -0.0270],\n",
      "        [ 0.1055, -0.1646],\n",
      "        [ 0.1512, -0.2649],\n",
      "        [ 0.2329, -0.1689],\n",
      "        [ 0.1010, -0.4345],\n",
      "        [-0.2589, -0.0741],\n",
      "        [ 0.1517, -0.3179],\n",
      "        [ 0.0706, -0.2610],\n",
      "        [-0.0671, -0.0941],\n",
      "        [-0.1058, -0.1760],\n",
      "        [-0.0279, -0.2368],\n",
      "        [-0.1163, -0.3030],\n",
      "        [-0.0582, -0.2054],\n",
      "        [ 0.0775, -0.3610],\n",
      "        [-0.0722, -0.4305],\n",
      "        [-0.2335, -0.2647],\n",
      "        [ 0.1333, -0.3144],\n",
      "        [ 0.1248, -0.1599],\n",
      "        [ 0.0246, -0.2108],\n",
      "        [-0.0866, -0.1544],\n",
      "        [ 0.0646, -0.2059],\n",
      "        [-0.1309, -0.2505],\n",
      "        [-0.0347, -0.1724],\n",
      "        [-0.0197, -0.0664],\n",
      "        [ 0.1464, -0.4285],\n",
      "        [ 0.1309, -0.2457],\n",
      "        [-0.0264, -0.4402],\n",
      "        [-0.3219, -0.2843],\n",
      "        [-0.0193, -0.2080],\n",
      "        [ 0.1542, -0.0051]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.1180,  0.5049],\n",
      "        [ 0.2613,  0.6552],\n",
      "        [ 0.6148,  0.5055],\n",
      "        [ 0.4221,  0.9040],\n",
      "        [ 0.2295,  0.7866],\n",
      "        [-0.0537,  0.4323],\n",
      "        [ 0.4084,  0.9334],\n",
      "        [ 0.2267,  0.3866],\n",
      "        [ 0.1742,  0.6002],\n",
      "        [ 0.3066,  0.8180],\n",
      "        [ 0.2942,  0.5705],\n",
      "        [ 0.2907,  0.7803],\n",
      "        [ 0.4147,  0.4328],\n",
      "        [-0.0191,  0.6181],\n",
      "        [ 0.2312,  0.5709],\n",
      "        [ 0.0795,  0.4893],\n",
      "        [ 0.2734,  0.4827],\n",
      "        [-0.0602,  0.7317],\n",
      "        [ 0.4138,  0.7218],\n",
      "        [ 0.1390,  0.6719],\n",
      "        [ 0.1306,  0.6150],\n",
      "        [ 0.3497,  0.7564],\n",
      "        [ 0.2301,  0.3806],\n",
      "        [ 0.0525,  0.5737],\n",
      "        [ 0.0229,  0.4731],\n",
      "        [ 0.3854,  0.5223],\n",
      "        [ 0.3276,  0.5608],\n",
      "        [ 0.4748,  0.5795],\n",
      "        [ 0.1856,  0.8539],\n",
      "        [ 0.2978,  0.6230],\n",
      "        [ 0.4050,  0.8878],\n",
      "        [ 0.3767,  0.8848]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7049, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5252, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2301, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2301, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|███████████████                                                       | 47/219 [07:37<28:09,  9.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0509,  0.3902],\n",
      "        [-0.0554, -0.1019],\n",
      "        [-0.2384, -0.2346],\n",
      "        [ 0.0609,  0.1096],\n",
      "        [-0.1282,  0.2439],\n",
      "        [-0.3210, -0.1237],\n",
      "        [-0.1986, -0.0681],\n",
      "        [-0.1126,  0.0653],\n",
      "        [-0.2098, -0.0217],\n",
      "        [-0.2112,  0.0582],\n",
      "        [ 0.0700, -0.1493],\n",
      "        [ 0.2393,  0.0949],\n",
      "        [-0.2946, -0.3451],\n",
      "        [-0.0132, -0.5010],\n",
      "        [-0.2418, -0.0760],\n",
      "        [-0.1767, -0.0715],\n",
      "        [-0.0070, -0.2714],\n",
      "        [-0.4183, -0.2594],\n",
      "        [-0.0869,  0.0827],\n",
      "        [ 0.2297, -0.0841],\n",
      "        [-0.0431, -0.1587],\n",
      "        [ 0.0947, -0.3509],\n",
      "        [ 0.1050, -0.3842],\n",
      "        [-0.3801, -0.1210],\n",
      "        [-0.0415, -0.2295],\n",
      "        [ 0.0460,  0.1914],\n",
      "        [-0.0589, -0.2981],\n",
      "        [-0.2467, -0.1227],\n",
      "        [-0.1819, -0.1062],\n",
      "        [-0.2468, -0.0678],\n",
      "        [-0.1867, -0.5949],\n",
      "        [ 0.0040, -0.2734]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.4512,  0.5340],\n",
      "        [ 0.2066,  0.6473],\n",
      "        [ 0.2548,  0.6987],\n",
      "        [ 0.2955,  0.4683],\n",
      "        [ 0.5435,  0.6062],\n",
      "        [ 0.1564,  0.6126],\n",
      "        [ 0.6057,  0.6123],\n",
      "        [ 0.1825,  0.7011],\n",
      "        [ 0.1833,  0.3613],\n",
      "        [ 0.2824,  0.6301],\n",
      "        [-0.0557,  0.7328],\n",
      "        [ 0.3904,  0.7189],\n",
      "        [ 0.1067,  0.8752],\n",
      "        [ 0.4352,  0.7810],\n",
      "        [ 0.4890,  0.7173],\n",
      "        [ 0.4184,  0.7418],\n",
      "        [ 0.0567,  0.5924],\n",
      "        [ 0.3686,  0.7516],\n",
      "        [ 0.4638,  0.6689],\n",
      "        [ 0.0389,  0.7939],\n",
      "        [-0.0817,  0.6960],\n",
      "        [ 0.3905,  0.2485],\n",
      "        [ 0.3828,  0.5561],\n",
      "        [ 0.3114,  0.6850],\n",
      "        [ 0.3987,  0.5061],\n",
      "        [ 0.2574,  0.3295],\n",
      "        [ 0.2791,  0.7124],\n",
      "        [ 0.0633,  0.6446],\n",
      "        [ 0.2026,  0.4439],\n",
      "        [ 0.1642,  0.5923],\n",
      "        [ 0.0538,  0.6373],\n",
      "        [ 0.5011,  0.5120]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7256, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4731, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1987, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1987, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  22%|███████████████▎                                                      | 48/219 [07:47<28:07,  9.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.2632,  0.0999],\n",
      "        [-0.1177,  0.0716],\n",
      "        [-0.1885, -0.1507],\n",
      "        [-0.3932,  0.4294],\n",
      "        [-0.2233, -0.3039],\n",
      "        [ 0.0114,  0.0350],\n",
      "        [ 0.0234,  0.2442],\n",
      "        [-0.2957, -0.1397],\n",
      "        [-0.1365,  0.2481],\n",
      "        [-0.2296,  0.2287],\n",
      "        [-0.3925,  0.3519],\n",
      "        [-0.2815, -0.1842],\n",
      "        [-0.0316,  0.0075],\n",
      "        [-0.1286, -0.2000],\n",
      "        [-0.0387, -0.1205],\n",
      "        [-0.2005,  0.1516],\n",
      "        [-0.0934, -0.2916],\n",
      "        [-0.2112,  0.1873],\n",
      "        [-0.5112,  0.1360],\n",
      "        [-0.0869,  0.0765],\n",
      "        [-0.3969, -0.0347],\n",
      "        [-0.1279,  0.0484],\n",
      "        [-0.0086,  0.2366],\n",
      "        [-0.2346,  0.5467],\n",
      "        [-0.2190,  0.1359],\n",
      "        [-0.0155, -0.1266],\n",
      "        [-0.2758,  0.2458],\n",
      "        [-0.3327,  0.2356],\n",
      "        [-0.1783,  0.3389],\n",
      "        [-0.2550,  0.4133],\n",
      "        [-0.1822,  0.3039],\n",
      "        [-0.3555,  0.1842]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.2474,  0.5452],\n",
      "        [ 0.2427,  0.3806],\n",
      "        [ 0.3099,  0.5627],\n",
      "        [ 0.5175,  0.3194],\n",
      "        [ 0.3177,  0.6413],\n",
      "        [ 0.0589,  0.3924],\n",
      "        [ 0.1083,  0.6530],\n",
      "        [ 0.4356,  0.2882],\n",
      "        [ 0.5150,  0.6318],\n",
      "        [ 0.1436,  0.4090],\n",
      "        [-0.0079,  0.7021],\n",
      "        [ 0.1129,  0.5202],\n",
      "        [ 0.4795,  0.6618],\n",
      "        [ 0.3723,  0.6088],\n",
      "        [ 0.3080,  0.8725],\n",
      "        [ 0.0439,  0.5749],\n",
      "        [-0.0419,  0.8627],\n",
      "        [ 0.3535,  0.4578],\n",
      "        [ 0.3390,  0.2387],\n",
      "        [ 0.1946,  0.4911],\n",
      "        [ 0.4536,  0.8563],\n",
      "        [ 0.4247,  0.5098],\n",
      "        [ 0.3574,  0.6473],\n",
      "        [-0.0219,  0.2848],\n",
      "        [ 0.4663,  0.4083],\n",
      "        [ 0.1531,  0.6810],\n",
      "        [ 0.4509,  0.2382],\n",
      "        [ 0.3591,  0.6180],\n",
      "        [ 0.1584,  0.7156],\n",
      "        [ 0.4711,  0.4671],\n",
      "        [ 0.1984,  0.4607],\n",
      "        [ 0.2498,  0.4446]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6750, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4284, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1034, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1034, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  22%|███████████████▋                                                      | 49/219 [07:56<27:49,  9.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.4711,  0.3433],\n",
      "        [-0.0983,  0.0793],\n",
      "        [-0.2746,  0.2160],\n",
      "        [-0.3441,  0.0466],\n",
      "        [-0.5357,  0.2013],\n",
      "        [-0.3373,  0.1783],\n",
      "        [-0.4458,  0.2888],\n",
      "        [-0.4394,  0.2147],\n",
      "        [-0.6040,  0.3024],\n",
      "        [-0.2089, -0.1269],\n",
      "        [-0.4591,  0.3955],\n",
      "        [-0.1890,  0.3074],\n",
      "        [-0.4218,  0.2709],\n",
      "        [-0.3340,  0.2454],\n",
      "        [-0.3144,  0.2466],\n",
      "        [-0.2124,  0.2160],\n",
      "        [-0.4878,  0.2880],\n",
      "        [-0.3891,  0.0865],\n",
      "        [-0.0202,  0.2682],\n",
      "        [-0.5693,  0.1858],\n",
      "        [-0.3575,  0.4480],\n",
      "        [-0.2942,  0.1943],\n",
      "        [-0.3104,  0.4485],\n",
      "        [-0.1821,  0.4555],\n",
      "        [-0.0863,  0.3276],\n",
      "        [-0.2521,  0.3279],\n",
      "        [-0.4274,  0.3687],\n",
      "        [-0.1478,  0.2610],\n",
      "        [-0.3266,  0.2541],\n",
      "        [-0.5160,  0.3250],\n",
      "        [-0.3935,  0.0380],\n",
      "        [-0.5015,  0.0290]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[3.2270e-01, 3.4315e-01],\n",
      "        [1.6054e-01, 8.9075e-01],\n",
      "        [4.6317e-01, 3.6729e-01],\n",
      "        [3.5224e-01, 5.2785e-01],\n",
      "        [2.0490e-01, 5.4557e-01],\n",
      "        [3.0330e-01, 5.2756e-01],\n",
      "        [8.9643e-02, 6.1926e-01],\n",
      "        [4.7962e-01, 7.7891e-01],\n",
      "        [4.7095e-01, 3.4762e-01],\n",
      "        [2.3944e-01, 7.4932e-01],\n",
      "        [5.2157e-01, 3.1985e-01],\n",
      "        [2.8317e-01, 5.5268e-01],\n",
      "        [3.8738e-01, 4.8822e-01],\n",
      "        [2.4697e-01, 7.9142e-01],\n",
      "        [4.1006e-01, 4.5010e-01],\n",
      "        [2.7949e-04, 6.3616e-01],\n",
      "        [5.0651e-01, 5.9483e-01],\n",
      "        [1.2597e-01, 6.8624e-01],\n",
      "        [3.5059e-01, 4.9692e-01],\n",
      "        [4.5161e-01, 4.1443e-01],\n",
      "        [3.6414e-01, 3.9725e-01],\n",
      "        [4.8265e-01, 4.1361e-01],\n",
      "        [9.0632e-02, 1.6969e-01],\n",
      "        [3.1912e-01, 2.4139e-01],\n",
      "        [4.1226e-01, 7.9041e-01],\n",
      "        [2.5629e-01, 5.7092e-01],\n",
      "        [3.5680e-01, 5.3402e-01],\n",
      "        [4.5390e-01, 4.3862e-01],\n",
      "        [1.3913e-01, 4.9737e-01],\n",
      "        [8.2621e-02, 5.5156e-01],\n",
      "        [1.7511e-01, 4.8529e-01],\n",
      "        [4.1613e-01, 4.1163e-01]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7117, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4472, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1589, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1589, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  23%|███████████████▉                                                      | 50/219 [08:06<27:30,  9.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.4558,  0.0714],\n",
      "        [-0.3160,  0.0420],\n",
      "        [-0.1338, -0.0573],\n",
      "        [-0.3936,  0.3813],\n",
      "        [-0.6139,  0.4599],\n",
      "        [-0.3072,  0.2544],\n",
      "        [-0.5736,  0.0787],\n",
      "        [-0.2974,  0.0968],\n",
      "        [-0.4277,  0.5040],\n",
      "        [-0.3494,  0.4759],\n",
      "        [-0.5125,  0.3464],\n",
      "        [-0.5765,  0.4642],\n",
      "        [-0.5615,  0.3885],\n",
      "        [-0.6291,  0.0883],\n",
      "        [-0.4763,  0.4489],\n",
      "        [-0.3806,  0.3685],\n",
      "        [-0.0707,  0.3972],\n",
      "        [-0.4818,  0.2034],\n",
      "        [-0.5590,  0.4218],\n",
      "        [-0.2705,  0.2235],\n",
      "        [-0.2924,  0.6351],\n",
      "        [-0.1944,  0.6538],\n",
      "        [-0.4946,  0.3231],\n",
      "        [-0.1088,  0.0097],\n",
      "        [-0.3463,  0.1806],\n",
      "        [-0.2965,  0.1518],\n",
      "        [-0.5669,  0.4036],\n",
      "        [-0.4316,  0.4220],\n",
      "        [-0.2634,  0.2928],\n",
      "        [-0.3337,  0.2902],\n",
      "        [-0.1031,  0.1093],\n",
      "        [-0.3397,  0.0592]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[0.3201, 0.5232],\n",
      "        [0.5039, 0.6964],\n",
      "        [0.4664, 0.4813],\n",
      "        [0.3155, 0.4990],\n",
      "        [0.1902, 0.4881],\n",
      "        [0.2834, 0.7601],\n",
      "        [0.3832, 0.4186],\n",
      "        [0.4349, 0.4801],\n",
      "        [0.3651, 0.6942],\n",
      "        [0.1431, 0.3289],\n",
      "        [0.2613, 0.4764],\n",
      "        [0.4543, 0.3306],\n",
      "        [0.5926, 0.4613],\n",
      "        [0.3403, 0.6513],\n",
      "        [0.4009, 0.5498],\n",
      "        [0.4403, 0.6933],\n",
      "        [0.1071, 0.5340],\n",
      "        [0.1918, 0.5081],\n",
      "        [0.3612, 0.4532],\n",
      "        [0.0638, 0.4319],\n",
      "        [0.3084, 0.5191],\n",
      "        [0.5411, 0.6422],\n",
      "        [0.3789, 0.5139],\n",
      "        [0.2070, 0.2515],\n",
      "        [0.2523, 0.5982],\n",
      "        [0.2785, 0.5061],\n",
      "        [0.4019, 0.6621],\n",
      "        [0.3714, 0.5646],\n",
      "        [0.4346, 0.5767],\n",
      "        [0.3017, 0.4016],\n",
      "        [0.2649, 0.6328],\n",
      "        [0.1625, 0.5116]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7047, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4303, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1350, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1350, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  23%|████████████████▎                                                     | 51/219 [08:16<27:13,  9.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.6199,  0.1326],\n",
      "        [-0.4965,  0.1776],\n",
      "        [-0.3512,  0.0467],\n",
      "        [-0.5613,  0.1177],\n",
      "        [-0.4198,  0.7825],\n",
      "        [-0.3591,  0.2128],\n",
      "        [-0.3782,  0.0661],\n",
      "        [-0.3682,  0.2055],\n",
      "        [-0.4236,  0.5548],\n",
      "        [-0.6853,  0.1790],\n",
      "        [-0.3605,  0.3038],\n",
      "        [-0.4690,  0.2478],\n",
      "        [-0.3424,  0.1980],\n",
      "        [-0.3859,  0.4277],\n",
      "        [-0.4472,  0.3063],\n",
      "        [-0.1686,  0.1937],\n",
      "        [-0.4136,  0.1362],\n",
      "        [-0.6107,  0.3885],\n",
      "        [-0.2382,  0.1998],\n",
      "        [-0.4066,  0.1411],\n",
      "        [-0.4427,  0.1977],\n",
      "        [-0.4835,  0.2701],\n",
      "        [-0.2807,  0.1309],\n",
      "        [-0.5179,  0.2458],\n",
      "        [-0.5344,  0.2047],\n",
      "        [-0.2333,  0.3137],\n",
      "        [-0.6478,  0.1453],\n",
      "        [-0.4812, -0.0362],\n",
      "        [-0.3805,  0.3954],\n",
      "        [-0.3079,  0.2903],\n",
      "        [-0.5790,  0.6321],\n",
      "        [-0.3696,  0.5615]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.3517,  0.4525],\n",
      "        [ 0.1130,  0.7093],\n",
      "        [ 0.0194,  0.5661],\n",
      "        [ 0.0946,  0.4635],\n",
      "        [ 0.1729,  0.4367],\n",
      "        [ 0.2690,  0.7215],\n",
      "        [ 0.0671,  0.4572],\n",
      "        [ 0.2178,  0.6114],\n",
      "        [ 0.2118,  0.5047],\n",
      "        [ 0.3011,  0.2094],\n",
      "        [ 0.3197,  0.8285],\n",
      "        [ 0.3030,  0.4978],\n",
      "        [ 0.2453,  0.5884],\n",
      "        [-0.0266,  0.5149],\n",
      "        [ 0.1439,  0.4747],\n",
      "        [-0.0435,  0.4767],\n",
      "        [ 0.0938,  0.6524],\n",
      "        [ 0.1807,  0.3822],\n",
      "        [ 0.1487,  0.5883],\n",
      "        [ 0.2363,  0.3749],\n",
      "        [ 0.4390,  0.6064],\n",
      "        [ 0.3614,  0.1589],\n",
      "        [ 0.1239,  0.3946],\n",
      "        [ 0.3496,  0.4933],\n",
      "        [ 0.2310,  0.4286],\n",
      "        [ 0.2334,  0.4437],\n",
      "        [ 0.2732,  0.3294],\n",
      "        [ 0.0923,  0.5491],\n",
      "        [ 0.2784,  0.4844],\n",
      "        [ 0.3469,  0.7645],\n",
      "        [ 0.3344,  0.7183],\n",
      "        [ 0.3577,  0.3985]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7614, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5276, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2890, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2890, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  24%|████████████████▌                                                     | 52/219 [08:26<27:13,  9.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0771,  0.3107],\n",
      "        [-0.3880,  0.2812],\n",
      "        [-0.2627,  0.0385],\n",
      "        [-0.2866,  0.0558],\n",
      "        [-0.4364,  0.0073],\n",
      "        [-0.2385,  0.2882],\n",
      "        [-0.2009,  0.0855],\n",
      "        [-0.4619, -0.0346],\n",
      "        [-0.4333,  0.2274],\n",
      "        [-0.2389, -0.1611],\n",
      "        [-0.4247,  0.0489],\n",
      "        [-0.2424,  0.0953],\n",
      "        [-0.0801,  0.1612],\n",
      "        [-0.4271,  0.2660],\n",
      "        [-0.3728,  0.0335],\n",
      "        [-0.0423,  0.4686],\n",
      "        [-0.2490, -0.0049],\n",
      "        [-0.2754,  0.0411],\n",
      "        [-0.2859,  0.0779],\n",
      "        [-0.4852,  0.0191],\n",
      "        [-0.2054,  0.1427],\n",
      "        [-0.4547, -0.0696],\n",
      "        [-0.4118, -0.1286],\n",
      "        [-0.3934,  0.1886],\n",
      "        [-0.2312,  0.1346],\n",
      "        [-0.2990,  0.1041],\n",
      "        [-0.3046, -0.0314],\n",
      "        [-0.0426, -0.1729],\n",
      "        [-0.5762,  0.1042],\n",
      "        [-0.0760,  0.3451],\n",
      "        [-0.3094,  0.0391],\n",
      "        [-0.5077,  0.0493]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.0233,  0.3825],\n",
      "        [ 0.1673,  0.5393],\n",
      "        [ 0.0919,  0.9301],\n",
      "        [ 0.1081,  0.7252],\n",
      "        [ 0.3390,  0.7476],\n",
      "        [ 0.1583,  0.3476],\n",
      "        [ 0.0576,  0.6162],\n",
      "        [ 0.1831,  0.3857],\n",
      "        [ 0.5468,  0.7386],\n",
      "        [ 0.3617,  0.7262],\n",
      "        [ 0.4356,  0.5854],\n",
      "        [ 0.1372,  0.4541],\n",
      "        [ 0.2433,  0.4049],\n",
      "        [ 0.2867,  0.3690],\n",
      "        [-0.0919,  0.7388],\n",
      "        [ 0.1751,  0.6979],\n",
      "        [ 0.0792,  0.4486],\n",
      "        [ 0.3452,  0.8204],\n",
      "        [ 0.2138,  0.4701],\n",
      "        [ 0.3684,  0.4615],\n",
      "        [ 0.3449,  0.3730],\n",
      "        [ 0.1415,  0.4217],\n",
      "        [ 0.3263,  0.7762],\n",
      "        [ 0.3378,  0.7026],\n",
      "        [ 0.0238,  0.7430],\n",
      "        [ 0.1333,  0.5175],\n",
      "        [ 0.2991,  0.6476],\n",
      "        [ 0.1652,  0.5903],\n",
      "        [ 0.2212,  0.5988],\n",
      "        [ 0.0230,  0.7273],\n",
      "        [ 0.2170,  0.7482],\n",
      "        [ 0.2435,  0.5382]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7210, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4950, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2160, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2160, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  24%|████████████████▉                                                     | 53/219 [08:36<27:23,  9.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.2325, -0.3495],\n",
      "        [-0.4006, -0.2101],\n",
      "        [-0.2919,  0.1153],\n",
      "        [-0.2255, -0.0840],\n",
      "        [-0.2410, -0.0255],\n",
      "        [-0.2594, -0.4240],\n",
      "        [-0.1732, -0.0933],\n",
      "        [-0.2636,  0.1788],\n",
      "        [-0.2766, -0.2950],\n",
      "        [-0.4034, -0.2704],\n",
      "        [-0.3764, -0.0428],\n",
      "        [-0.3658,  0.0316],\n",
      "        [-0.1700, -0.1764],\n",
      "        [-0.3866, -0.1092],\n",
      "        [-0.1605,  0.1929],\n",
      "        [-0.2089, -0.0906],\n",
      "        [-0.1839,  0.0826],\n",
      "        [-0.4481, -0.1249],\n",
      "        [-0.5023, -0.3597],\n",
      "        [-0.0730,  0.3303],\n",
      "        [-0.1269, -0.2120],\n",
      "        [-0.2169, -0.0450],\n",
      "        [-0.2785, -0.2288],\n",
      "        [-0.4711, -0.2394],\n",
      "        [-0.3525,  0.2715],\n",
      "        [-0.4284, -0.2021],\n",
      "        [-0.3578, -0.0789],\n",
      "        [-0.2572, -0.2198],\n",
      "        [-0.2174, -0.0995],\n",
      "        [-0.2349, -0.1536],\n",
      "        [-0.3024, -0.2831],\n",
      "        [-0.2126, -0.3625]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[ 0.0857,  0.6424],\n",
      "        [ 0.1167,  0.3733],\n",
      "        [ 0.0797,  0.7227],\n",
      "        [-0.1154,  0.6443],\n",
      "        [-0.1092,  0.6435],\n",
      "        [-0.2951,  0.4021],\n",
      "        [-0.1802,  0.5279],\n",
      "        [-0.1032,  0.4124],\n",
      "        [-0.1088,  0.7110],\n",
      "        [-0.1811,  0.3850],\n",
      "        [ 0.1167,  0.7481],\n",
      "        [ 0.0092,  0.3600],\n",
      "        [ 0.0696,  0.6107],\n",
      "        [-0.0582,  0.7053],\n",
      "        [ 0.1877,  0.6467],\n",
      "        [-0.1909,  0.2597],\n",
      "        [ 0.2267,  0.4825],\n",
      "        [-0.0250,  0.6349],\n",
      "        [-0.2408,  0.5442],\n",
      "        [ 0.0707,  0.7405],\n",
      "        [ 0.0877,  0.4049],\n",
      "        [ 0.0045,  0.6551],\n",
      "        [-0.2967,  0.7736],\n",
      "        [-0.0301,  0.2785],\n",
      "        [ 0.1072,  0.2746],\n",
      "        [ 0.0524,  0.3668],\n",
      "        [-0.0881,  0.6647],\n",
      "        [ 0.0607,  0.5054],\n",
      "        [-0.0196,  0.5780],\n",
      "        [-0.0433,  0.3835],\n",
      "        [-0.1235,  0.4871],\n",
      "        [ 0.1151,  0.4448]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6676, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4554, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1230, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1230, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|█████████████████▎                                                    | 54/219 [08:45<27:00,  9.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.2918, -0.1834],\n",
      "        [-0.2286, -0.2405],\n",
      "        [-0.1030, -0.2158],\n",
      "        [-0.0684,  0.0661],\n",
      "        [-0.4092,  0.1042],\n",
      "        [-0.4670,  0.0228],\n",
      "        [-0.2283, -0.3119],\n",
      "        [-0.1518,  0.0989],\n",
      "        [-0.0398, -0.1949],\n",
      "        [-0.0958, -0.1781],\n",
      "        [-0.0318, -0.1905],\n",
      "        [-0.2202,  0.2100],\n",
      "        [-0.0636, -0.3840],\n",
      "        [-0.3101, -0.0855],\n",
      "        [ 0.0730, -0.1998],\n",
      "        [-0.0343, -0.3356],\n",
      "        [-0.2881, -0.4988],\n",
      "        [-0.1079, -0.0849],\n",
      "        [ 0.1124,  0.2567],\n",
      "        [-0.0977, -0.4223],\n",
      "        [-0.0331, -0.3412],\n",
      "        [-0.2398, -0.1019],\n",
      "        [-0.1359, -0.0796],\n",
      "        [-0.4618, -0.2698],\n",
      "        [-0.4976, -0.2313],\n",
      "        [-0.3072, -0.1388],\n",
      "        [-0.3253, -0.0645],\n",
      "        [-0.2461,  0.0770],\n",
      "        [ 0.0285, -0.2266],\n",
      "        [-0.5216, -0.2127],\n",
      "        [-0.3934, -0.3331],\n",
      "        [-0.4091,  0.0452]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-6.2472e-02,  2.9841e-01],\n",
      "        [-1.7023e-02,  3.2360e-01],\n",
      "        [ 1.6381e-01,  4.3267e-01],\n",
      "        [ 2.5377e-01,  6.4170e-01],\n",
      "        [ 1.2632e-01,  1.4769e-01],\n",
      "        [ 2.6536e-03,  4.8102e-01],\n",
      "        [-1.1635e-01,  8.3719e-01],\n",
      "        [ 3.5229e-01,  1.7118e-01],\n",
      "        [-1.5444e-02,  6.8228e-01],\n",
      "        [ 2.9238e-01,  1.1879e-01],\n",
      "        [ 3.2395e-02,  2.8193e-01],\n",
      "        [ 3.4252e-02,  4.4950e-01],\n",
      "        [-1.4098e-01,  2.6630e-01],\n",
      "        [ 2.1272e-01,  5.2086e-01],\n",
      "        [ 1.1014e-01,  4.9618e-01],\n",
      "        [-1.1474e-01,  3.9766e-01],\n",
      "        [ 7.0800e-02,  4.4591e-01],\n",
      "        [ 3.3194e-02,  2.4185e-01],\n",
      "        [-9.3795e-02,  4.2693e-02],\n",
      "        [ 5.9610e-02,  6.3117e-01],\n",
      "        [ 5.3945e-02,  5.2205e-01],\n",
      "        [ 6.6909e-02,  5.4509e-01],\n",
      "        [ 7.9100e-03,  3.3454e-01],\n",
      "        [ 7.8294e-02,  4.8002e-01],\n",
      "        [ 1.1869e-02,  4.5661e-01],\n",
      "        [-1.1181e-01,  1.9450e-01],\n",
      "        [ 2.9959e-01,  2.3949e-01],\n",
      "        [-5.7369e-06,  4.9644e-01],\n",
      "        [ 2.5597e-01,  4.2494e-01],\n",
      "        [-1.6830e-01,  5.1202e-01],\n",
      "        [-3.9297e-02,  6.1306e-01],\n",
      "        [-1.6982e-01,  4.6344e-01]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6603, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4056, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.0659, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.0659, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|█████████████████▌                                                    | 55/219 [08:55<26:48,  9.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0715,  0.2068],\n",
      "        [-0.0877,  0.1799],\n",
      "        [-0.2113,  0.2321],\n",
      "        [-0.3228,  0.3348],\n",
      "        [ 0.0293,  0.2749],\n",
      "        [ 0.0014,  0.1949],\n",
      "        [-0.1082,  0.0969],\n",
      "        [-0.3673,  0.4849],\n",
      "        [-0.1697,  0.3159],\n",
      "        [-0.1950,  0.0151],\n",
      "        [-0.0157,  0.3021],\n",
      "        [-0.1773, -0.0719],\n",
      "        [ 0.0229,  0.3276],\n",
      "        [ 0.1774,  0.1043],\n",
      "        [ 0.1919,  0.0625],\n",
      "        [-0.1351,  0.2543],\n",
      "        [-0.3469,  0.3028],\n",
      "        [-0.0560,  0.5253],\n",
      "        [-0.2667, -0.0562],\n",
      "        [-0.0947,  0.4491],\n",
      "        [ 0.0262,  0.2038],\n",
      "        [-0.1560,  0.3667],\n",
      "        [-0.1723,  0.4187],\n",
      "        [-0.0923,  0.2646],\n",
      "        [-0.3681,  0.2138],\n",
      "        [-0.0514,  0.2640],\n",
      "        [-0.1979,  0.3642],\n",
      "        [-0.4432,  0.0533],\n",
      "        [-0.0773,  0.3252],\n",
      "        [-0.1526,  0.3521],\n",
      "        [-0.4382,  0.1691],\n",
      "        [-0.0978, -0.3293]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-2.6859e-01,  5.0044e-02],\n",
      "        [-3.4946e-01, -2.7801e-01],\n",
      "        [-2.4596e-01, -2.3440e-01],\n",
      "        [ 2.6230e-03, -1.5150e-01],\n",
      "        [-1.8952e-01,  7.2298e-02],\n",
      "        [ 1.1639e-02, -1.0888e-01],\n",
      "        [ 1.9415e-01,  3.7184e-01],\n",
      "        [ 8.3767e-02,  1.2049e-01],\n",
      "        [-1.3195e-02, -1.8204e-01],\n",
      "        [-6.6091e-01, -9.3192e-02],\n",
      "        [-2.4063e-01,  1.1286e-01],\n",
      "        [ 2.7575e-01,  3.8121e-02],\n",
      "        [-4.0617e-02, -3.5205e-02],\n",
      "        [ 9.9353e-02, -2.8129e-01],\n",
      "        [-2.5757e-01, -1.0022e-01],\n",
      "        [-1.0613e-01,  4.4299e-02],\n",
      "        [-1.0539e-01, -3.0537e-01],\n",
      "        [-2.9748e-01, -8.5550e-02],\n",
      "        [ 4.4084e-04, -4.9386e-02],\n",
      "        [ 2.2998e-01, -3.8157e-01],\n",
      "        [-1.3142e-01, -2.5086e-01],\n",
      "        [ 3.4712e-02,  2.3483e-01],\n",
      "        [ 2.0095e-01, -3.2113e-02],\n",
      "        [-5.8088e-01, -2.9579e-01],\n",
      "        [-3.6101e-01,  1.5216e-01],\n",
      "        [ 1.1896e-01, -1.6327e-01],\n",
      "        [-2.8275e-01,  4.5447e-02],\n",
      "        [ 1.9724e-01,  1.9430e-01],\n",
      "        [ 3.8751e-01,  2.3061e-01],\n",
      "        [ 1.4435e-01, -3.4309e-03],\n",
      "        [ 9.2832e-02,  9.1933e-03],\n",
      "        [-3.8196e-01, -3.4143e-01]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7731, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5573, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.3304, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.3304, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|█████████████████▉                                                    | 56/219 [09:05<26:43,  9.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.1266,  0.2843],\n",
      "        [ 0.0910, -0.1377],\n",
      "        [-0.2093,  0.5164],\n",
      "        [-0.3734,  0.2427],\n",
      "        [-0.0898,  0.2178],\n",
      "        [-0.0514, -0.0566],\n",
      "        [-0.2000,  0.5096],\n",
      "        [-0.1628,  0.4607],\n",
      "        [-0.3310,  0.1866],\n",
      "        [ 0.1273,  0.1478],\n",
      "        [ 0.1732,  0.1395],\n",
      "        [-0.4227,  0.4758],\n",
      "        [ 0.1420,  0.0458],\n",
      "        [ 0.0075,  0.1891],\n",
      "        [-0.0909,  0.2230],\n",
      "        [-0.3157,  0.3889],\n",
      "        [ 0.0593,  0.4210],\n",
      "        [-0.1879,  0.1922],\n",
      "        [ 0.1647,  0.4362],\n",
      "        [-0.0661,  0.1059],\n",
      "        [ 0.0790,  0.2249],\n",
      "        [-0.2768,  0.1219],\n",
      "        [-0.2894, -0.1584],\n",
      "        [-0.1043,  0.3805],\n",
      "        [-0.1775,  0.1178],\n",
      "        [-0.0437,  0.1768],\n",
      "        [-0.1220,  0.3762],\n",
      "        [-0.1885,  0.1520],\n",
      "        [-0.0508,  0.2561],\n",
      "        [-0.1371,  0.0008],\n",
      "        [ 0.0405,  0.2608],\n",
      "        [-0.1795,  0.2942]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.2411, -0.2373],\n",
      "        [-0.1923, -0.1668],\n",
      "        [-0.2877, -0.2551],\n",
      "        [-0.4106, -0.1635],\n",
      "        [-0.2407, -0.4327],\n",
      "        [-0.3252, -0.1474],\n",
      "        [-0.6464, -0.3255],\n",
      "        [-0.4242, -0.3245],\n",
      "        [-0.1930, -0.3085],\n",
      "        [-0.3460, -0.2457],\n",
      "        [-0.3252, -0.2195],\n",
      "        [-0.2462, -0.1117],\n",
      "        [-0.5567,  0.1986],\n",
      "        [-0.2897, -0.2697],\n",
      "        [-0.2490, -0.1368],\n",
      "        [-0.4117, -0.4984],\n",
      "        [-0.5591, -0.1974],\n",
      "        [-0.5913, -0.3659],\n",
      "        [-0.4175, -0.2587],\n",
      "        [-0.1795, -0.1739],\n",
      "        [-0.4577, -0.0743],\n",
      "        [-0.1418, -0.2184],\n",
      "        [-0.5094, -0.0830],\n",
      "        [-0.4273, -0.2535],\n",
      "        [-0.3242, -0.2057],\n",
      "        [-0.1864, -0.3210],\n",
      "        [-0.1859, -0.3697],\n",
      "        [-0.3011, -0.1154],\n",
      "        [-0.3169, -0.1546],\n",
      "        [-0.5566, -0.2815],\n",
      "        [-0.6460, -0.1415],\n",
      "        [-0.5319, -0.1185]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6876, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4984, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1860, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1860, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|██████████████████▏                                                   | 57/219 [09:15<26:35,  9.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-3.2853e-01, -1.1358e-01],\n",
      "        [ 2.5711e-01,  3.4524e-02],\n",
      "        [ 7.3203e-02,  1.5503e-01],\n",
      "        [ 2.1108e-02,  2.4492e-01],\n",
      "        [ 3.3932e-01, -2.7954e-02],\n",
      "        [ 3.5108e-01, -1.0726e-04],\n",
      "        [ 2.7475e-01,  7.5541e-02],\n",
      "        [-5.8777e-02,  1.4751e-01],\n",
      "        [-1.3754e-01,  1.9054e-01],\n",
      "        [-3.0466e-01, -1.0353e-01],\n",
      "        [ 1.8011e-01,  4.4335e-01],\n",
      "        [ 1.4085e-02,  1.4493e-01],\n",
      "        [ 3.5609e-01, -4.2953e-02],\n",
      "        [ 8.0981e-02,  2.4971e-02],\n",
      "        [-2.0701e-01,  1.1331e-01],\n",
      "        [-1.3912e-01,  6.9196e-02],\n",
      "        [ 8.7775e-02,  3.5465e-01],\n",
      "        [-3.0018e-01,  1.2369e-01],\n",
      "        [-9.8320e-02,  2.3752e-01],\n",
      "        [ 1.3536e-01, -3.4515e-02],\n",
      "        [ 1.4830e-01, -6.9917e-02],\n",
      "        [ 2.1534e-01,  2.1677e-01],\n",
      "        [ 4.2040e-03,  2.6814e-01],\n",
      "        [ 1.9212e-01, -8.6010e-02],\n",
      "        [ 6.4202e-02,  1.8988e-01],\n",
      "        [-4.2992e-02,  4.7787e-01],\n",
      "        [ 8.3962e-02,  8.7158e-02],\n",
      "        [ 3.9693e-01,  5.2246e-01],\n",
      "        [-1.5246e-01,  2.0072e-01],\n",
      "        [ 1.1957e-01,  2.4358e-01],\n",
      "        [-1.5557e-01, -1.8764e-01],\n",
      "        [-3.2084e-02, -2.1907e-02]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.2769, -0.3662],\n",
      "        [-0.1953, -0.3276],\n",
      "        [-0.4836, -0.1774],\n",
      "        [-0.5374, -0.0812],\n",
      "        [-0.2419, -0.1893],\n",
      "        [-0.3208, -0.4865],\n",
      "        [-0.1980, -0.5122],\n",
      "        [-0.4269, -0.2418],\n",
      "        [-0.4941, -0.3601],\n",
      "        [-0.2587,  0.0209],\n",
      "        [-0.3677, -0.3989],\n",
      "        [-0.3575, -0.3959],\n",
      "        [-0.2819, -0.1223],\n",
      "        [-0.1516,  0.0470],\n",
      "        [-0.4421, -0.2055],\n",
      "        [-0.3930, -0.1083],\n",
      "        [-0.3558, -0.2946],\n",
      "        [-0.4277, -0.1199],\n",
      "        [-0.1134, -0.3541],\n",
      "        [-0.0747, -0.2897],\n",
      "        [-0.3324, -0.2458],\n",
      "        [-0.3534,  0.0131],\n",
      "        [-0.4628, -0.2436],\n",
      "        [ 0.0970, -0.4521],\n",
      "        [-0.2187, -0.3433],\n",
      "        [-0.3667, -0.2548],\n",
      "        [-0.2085, -0.1919],\n",
      "        [-0.3533, -0.0356],\n",
      "        [-0.5789, -0.5111],\n",
      "        [-0.1592, -0.5210],\n",
      "        [-0.4794, -0.0603],\n",
      "        [-0.2902, -0.2465]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7011, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5502, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2512, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2512, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|██████████████████▌                                                   | 58/219 [09:25<26:28,  9.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1687, -0.2076],\n",
      "        [ 0.6825,  0.0333],\n",
      "        [ 0.5316,  0.0139],\n",
      "        [ 0.6273,  0.1732],\n",
      "        [ 0.6113, -0.6971],\n",
      "        [ 0.5547, -0.0999],\n",
      "        [ 0.4818, -0.2137],\n",
      "        [ 0.5902, -0.2143],\n",
      "        [ 0.3230, -0.0762],\n",
      "        [ 0.2913, -0.3096],\n",
      "        [ 0.8100, -0.0948],\n",
      "        [ 0.6232, -0.1467],\n",
      "        [ 0.4972, -0.2984],\n",
      "        [ 0.5284, -0.2984],\n",
      "        [ 0.5605, -0.1146],\n",
      "        [ 0.5251, -0.1922],\n",
      "        [ 0.3244, -0.0523],\n",
      "        [ 0.2924, -0.1040],\n",
      "        [ 0.5081, -0.0715],\n",
      "        [ 0.5432, -0.0202],\n",
      "        [ 0.7223, -0.2036],\n",
      "        [ 0.3251, -0.1324],\n",
      "        [ 0.5701, -0.2315],\n",
      "        [ 0.3469,  0.0955],\n",
      "        [ 0.3001, -0.1302],\n",
      "        [ 0.4071, -0.2244],\n",
      "        [ 0.5981, -0.1990],\n",
      "        [ 0.5236, -0.2248],\n",
      "        [ 0.3988, -0.0943],\n",
      "        [ 0.2295, -0.0488],\n",
      "        [ 0.4671, -0.0924],\n",
      "        [ 0.4776, -0.3772]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.3724, -0.1442],\n",
      "        [-0.6027, -0.1919],\n",
      "        [-0.3203, -0.5458],\n",
      "        [-0.2298, -0.4678],\n",
      "        [-0.3532, -0.3990],\n",
      "        [-0.5404, -0.1453],\n",
      "        [-0.3958, -0.1726],\n",
      "        [-0.4186, -0.0327],\n",
      "        [-0.3299, -0.4847],\n",
      "        [-0.2133, -0.2252],\n",
      "        [-0.2341, -0.2289],\n",
      "        [-0.0810, -0.2099],\n",
      "        [-0.1663, -0.3598],\n",
      "        [-0.2327, -0.3565],\n",
      "        [-0.2856, -0.2437],\n",
      "        [-0.5445, -0.0292],\n",
      "        [-0.4708, -0.4587],\n",
      "        [ 0.0194, -0.6310],\n",
      "        [-0.4392, -0.3270],\n",
      "        [-0.3294, -0.4576],\n",
      "        [-0.1716, -0.5166],\n",
      "        [-0.4507, -0.1693],\n",
      "        [-0.0115,  0.0167],\n",
      "        [-0.4555, -0.5313],\n",
      "        [-0.6071, -0.2178],\n",
      "        [-0.1741, -0.1031],\n",
      "        [-0.1818, -0.1927],\n",
      "        [-0.3523, -0.1320],\n",
      "        [-0.2187,  0.0413],\n",
      "        [-0.4027, -0.2745],\n",
      "        [-0.1298, -0.3226],\n",
      "        [-0.4118,  0.0462]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7857, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4257, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2114, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2114, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  27%|██████████████████▊                                                   | 59/219 [09:35<26:41, 10.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1148,  0.1572],\n",
      "        [ 0.1115,  0.1727],\n",
      "        [ 0.0541,  0.1280],\n",
      "        [-0.0356, -0.2234],\n",
      "        [ 0.0446, -0.0683],\n",
      "        [-0.0879,  0.1876],\n",
      "        [-0.2580,  0.0800],\n",
      "        [ 0.1761,  0.1652],\n",
      "        [ 0.0900,  0.3367],\n",
      "        [ 0.3074,  0.1799],\n",
      "        [ 0.1598, -0.0810],\n",
      "        [ 0.0087,  0.2979],\n",
      "        [-0.0189,  0.0036],\n",
      "        [ 0.2794,  0.1823],\n",
      "        [ 0.3488, -0.0365],\n",
      "        [-0.0894, -0.0202],\n",
      "        [ 0.1624,  0.0706],\n",
      "        [-0.0111,  0.1977],\n",
      "        [ 0.4001,  0.2101],\n",
      "        [ 0.1104, -0.1797],\n",
      "        [ 0.1830,  0.0147],\n",
      "        [ 0.2306,  0.3191],\n",
      "        [ 0.3182, -0.2219],\n",
      "        [ 0.1466,  0.3636],\n",
      "        [ 0.0964,  0.0858],\n",
      "        [ 0.3104,  0.0657],\n",
      "        [ 0.0311,  0.2081],\n",
      "        [-0.0083,  0.5432],\n",
      "        [-0.0486,  0.0180],\n",
      "        [-0.0626, -0.2738],\n",
      "        [ 0.2541, -0.1792],\n",
      "        [-0.0514,  0.2405]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.4249, -0.1197],\n",
      "        [-0.1161, -0.4203],\n",
      "        [-0.3269,  0.2575],\n",
      "        [-0.4150, -0.0235],\n",
      "        [-0.2963, -0.0915],\n",
      "        [-0.7232, -0.3855],\n",
      "        [-0.3975, -0.4244],\n",
      "        [-0.9414, -0.4774],\n",
      "        [-0.3675, -0.0108],\n",
      "        [-0.5022, -0.1732],\n",
      "        [-0.2468, -0.1598],\n",
      "        [-0.0480, -0.2973],\n",
      "        [-0.2010, -0.1409],\n",
      "        [-0.3707, -0.2211],\n",
      "        [-0.4516, -0.5940],\n",
      "        [-0.4188,  0.0985],\n",
      "        [-0.4367, -0.1337],\n",
      "        [-0.4319, -0.0139],\n",
      "        [-0.5584, -0.5127],\n",
      "        [-0.3507, -0.1488],\n",
      "        [-0.4521, -0.1528],\n",
      "        [-0.1220, -0.0259],\n",
      "        [-0.4253, -0.4679],\n",
      "        [-0.0222, -0.1484],\n",
      "        [-0.3255,  0.0525],\n",
      "        [-0.2218, -0.2045],\n",
      "        [-0.4716, -0.3021],\n",
      "        [-0.2357, -0.2584],\n",
      "        [-0.2269, -0.1393],\n",
      "        [-0.4762, -0.5725],\n",
      "        [-0.3373, -0.1863],\n",
      "        [-0.4145, -0.1906]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7021, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5023, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2044, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2044, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  27%|███████████████████▏                                                  | 60/219 [09:46<26:51, 10.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.2409,  0.1574],\n",
      "        [ 0.2050, -0.0501],\n",
      "        [ 0.4056,  0.0065],\n",
      "        [ 0.0804, -0.0365],\n",
      "        [ 0.2265,  0.0443],\n",
      "        [ 0.4267,  0.1462],\n",
      "        [ 0.1443, -0.1308],\n",
      "        [ 0.0309,  0.2311],\n",
      "        [ 0.2231, -0.1324],\n",
      "        [ 0.4545,  0.0797],\n",
      "        [ 0.1262,  0.1606],\n",
      "        [ 0.2098,  0.2369],\n",
      "        [ 0.2986,  0.1740],\n",
      "        [ 0.1471,  0.1585],\n",
      "        [ 0.0040,  0.2911],\n",
      "        [ 0.1150, -0.0616],\n",
      "        [ 0.2628, -0.0711],\n",
      "        [ 0.3060,  0.0442],\n",
      "        [ 0.0114,  0.2403],\n",
      "        [ 0.0069,  0.1382],\n",
      "        [-0.1305, -0.0090],\n",
      "        [ 0.2658,  0.0575],\n",
      "        [ 0.1509, -0.1516],\n",
      "        [ 0.0061, -0.0301],\n",
      "        [ 0.1176,  0.3623],\n",
      "        [ 0.2446, -0.1670],\n",
      "        [ 0.3267,  0.0380],\n",
      "        [ 0.4141, -0.1608],\n",
      "        [ 0.1863,  0.2326],\n",
      "        [-0.0404,  0.0687],\n",
      "        [ 0.2692,  0.2867],\n",
      "        [ 0.0601,  0.1114]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.4136,  0.0487],\n",
      "        [-0.2203,  0.0750],\n",
      "        [-0.3472,  0.1401],\n",
      "        [-0.4093, -0.2012],\n",
      "        [-0.4861, -0.1026],\n",
      "        [-0.3365, -0.1675],\n",
      "        [-0.3376,  0.2279],\n",
      "        [-0.3145, -0.1814],\n",
      "        [-0.4068, -0.4075],\n",
      "        [-0.3182, -0.1044],\n",
      "        [-0.4419, -0.3130],\n",
      "        [-0.5562, -0.2713],\n",
      "        [-0.2143, -0.2980],\n",
      "        [-0.5435, -0.1547],\n",
      "        [-0.2708,  0.0187],\n",
      "        [-0.3218, -0.0955],\n",
      "        [-0.5540, -0.3452],\n",
      "        [-0.5147,  0.2082],\n",
      "        [-0.3781, -0.1479],\n",
      "        [-0.4033, -0.1429],\n",
      "        [-0.2301, -0.0883],\n",
      "        [-0.2750, -0.1344],\n",
      "        [-0.0078, -0.1299],\n",
      "        [-0.3846, -0.2367],\n",
      "        [-0.5890, -0.0254],\n",
      "        [-0.1491, -0.1751],\n",
      "        [-0.5330, -0.0799],\n",
      "        [-0.2758, -0.0213],\n",
      "        [-0.5091, -0.3246],\n",
      "        [-0.2652, -0.1503],\n",
      "        [-0.1853, -0.0013],\n",
      "        [-0.1898, -0.0155]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7133, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5266, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2399, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2399, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|███████████████████▍                                                  | 61/219 [09:56<26:42, 10.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0794,  0.1374],\n",
      "        [ 0.3309,  0.2640],\n",
      "        [ 0.1578,  0.3039],\n",
      "        [ 0.2389,  0.0551],\n",
      "        [ 0.1840,  0.0594],\n",
      "        [ 0.2412,  0.2564],\n",
      "        [ 0.2940,  0.3828],\n",
      "        [-0.0016,  0.0171],\n",
      "        [ 0.1356,  0.0923],\n",
      "        [-0.0501,  0.0882],\n",
      "        [-0.0126, -0.0193],\n",
      "        [-0.0861,  0.0075],\n",
      "        [ 0.3178,  0.0715],\n",
      "        [ 0.2603,  0.1391],\n",
      "        [-0.0762,  0.0675],\n",
      "        [-0.0616,  0.2069],\n",
      "        [ 0.0152,  0.0796],\n",
      "        [ 0.2707,  0.1754],\n",
      "        [-0.0771,  0.2737],\n",
      "        [ 0.1080, -0.1626],\n",
      "        [ 0.0112, -0.1074],\n",
      "        [ 0.2736, -0.0632],\n",
      "        [ 0.0911,  0.0198],\n",
      "        [ 0.0193,  0.1578],\n",
      "        [ 0.0916,  0.1463],\n",
      "        [ 0.4079,  0.1562],\n",
      "        [ 0.1383,  0.2976],\n",
      "        [ 0.1646,  0.1200],\n",
      "        [ 0.3904,  0.0759],\n",
      "        [ 0.2145,  0.3076],\n",
      "        [ 0.2226,  0.3553],\n",
      "        [ 0.1505,  0.0935]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.4077,  0.0829],\n",
      "        [-0.2754, -0.2697],\n",
      "        [-0.2086,  0.0179],\n",
      "        [-0.5146, -0.0198],\n",
      "        [-0.4008, -0.0319],\n",
      "        [-0.2792,  0.1013],\n",
      "        [-0.3099,  0.0430],\n",
      "        [-0.1269,  0.0158],\n",
      "        [-0.2818, -0.0024],\n",
      "        [-0.2113,  0.1470],\n",
      "        [-0.1864, -0.0646],\n",
      "        [-0.2184,  0.1335],\n",
      "        [-0.2608,  0.0405],\n",
      "        [-0.2917,  0.0351],\n",
      "        [-0.2929, -0.2593],\n",
      "        [ 0.1758, -0.2778],\n",
      "        [-0.3639, -0.1895],\n",
      "        [-0.2048, -0.2259],\n",
      "        [-0.0449, -0.0414],\n",
      "        [-0.4523,  0.2487],\n",
      "        [-0.1562, -0.1248],\n",
      "        [-0.2257,  0.1321],\n",
      "        [-0.0391,  0.1060],\n",
      "        [-0.0687,  0.1837],\n",
      "        [-0.0044, -0.1122],\n",
      "        [-0.0332, -0.3064],\n",
      "        [-0.0958,  0.0939],\n",
      "        [ 0.1416, -0.0254],\n",
      "        [-0.3386, -0.2575],\n",
      "        [-0.3621, -0.1560],\n",
      "        [-0.3856, -0.2886],\n",
      "        [-0.0135, -0.1505]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6947, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.3520, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.0467, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.0467, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|███████████████████▊                                                  | 62/219 [10:07<26:59, 10.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.1046, -0.0704],\n",
      "        [-0.3766,  0.1551],\n",
      "        [-0.0519,  0.1443],\n",
      "        [ 0.1622,  0.2943],\n",
      "        [ 0.0455,  0.1040],\n",
      "        [ 0.1726,  0.2505],\n",
      "        [-0.3952, -0.0546],\n",
      "        [ 0.0637,  0.1571],\n",
      "        [-0.2754,  0.1467],\n",
      "        [-0.1547,  0.1608],\n",
      "        [ 0.1140,  0.3309],\n",
      "        [-0.0659,  0.0926],\n",
      "        [-0.0681,  0.2352],\n",
      "        [-0.0246,  0.2914],\n",
      "        [-0.0346,  0.1334],\n",
      "        [ 0.0163,  0.2680],\n",
      "        [-0.1603,  0.1280],\n",
      "        [-0.3767,  0.1649],\n",
      "        [-0.0767,  0.2701],\n",
      "        [-0.2370,  0.0520],\n",
      "        [-0.0482, -0.1571],\n",
      "        [-0.0328,  0.2699],\n",
      "        [-0.2202, -0.1899],\n",
      "        [-0.1827,  0.3794],\n",
      "        [ 0.0093,  0.1784],\n",
      "        [-0.2195,  0.2012],\n",
      "        [ 0.1928,  0.2323],\n",
      "        [-0.0709,  0.3844],\n",
      "        [-0.0495,  0.1677],\n",
      "        [ 0.0313,  0.3013],\n",
      "        [-0.1393,  0.0169],\n",
      "        [-0.0013,  0.2882]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.0767, -0.0270],\n",
      "        [-0.0643, -0.0686],\n",
      "        [ 0.0361,  0.0260],\n",
      "        [-0.0917, -0.0253],\n",
      "        [ 0.2805, -0.3236],\n",
      "        [-0.3042,  0.1987],\n",
      "        [-0.0951,  0.3554],\n",
      "        [-0.1028,  0.1900],\n",
      "        [-0.1208, -0.1391],\n",
      "        [-0.0616,  0.0196],\n",
      "        [-0.0023,  0.1629],\n",
      "        [-0.0483, -0.2787],\n",
      "        [ 0.1095,  0.1207],\n",
      "        [-0.1025,  0.3040],\n",
      "        [ 0.0144, -0.0758],\n",
      "        [-0.2687, -0.0963],\n",
      "        [-0.3222, -0.0169],\n",
      "        [-0.1957, -0.0931],\n",
      "        [ 0.2353,  0.2907],\n",
      "        [ 0.1496, -0.0031],\n",
      "        [ 0.0066, -0.0479],\n",
      "        [-0.1547,  0.0544],\n",
      "        [-0.0104,  0.1597],\n",
      "        [-0.2649,  0.2788],\n",
      "        [-0.1673,  0.1101],\n",
      "        [ 0.0113,  0.1594],\n",
      "        [-0.0162, -0.0489],\n",
      "        [-0.0422,  0.1452],\n",
      "        [-0.1426, -0.0404],\n",
      "        [-0.2270, -0.1901],\n",
      "        [-0.2018, -0.0019],\n",
      "        [-0.2254, -0.0747]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7072, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4507, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1579, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1579, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  29%|████████████████████▏                                                 | 63/219 [10:17<26:50, 10.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.4169,  0.0685],\n",
      "        [-0.3592,  0.0395],\n",
      "        [-0.4971,  0.1872],\n",
      "        [-0.4265,  0.0937],\n",
      "        [-0.1786,  0.4432],\n",
      "        [-0.5263,  0.1888],\n",
      "        [-0.4509,  0.6178],\n",
      "        [-0.1274,  0.2620],\n",
      "        [-0.5877,  0.3725],\n",
      "        [-0.3371,  0.3345],\n",
      "        [-0.4238,  0.1690],\n",
      "        [-0.5534,  0.3681],\n",
      "        [-0.2812,  0.3316],\n",
      "        [-0.2475,  0.2953],\n",
      "        [-0.5175,  0.4314],\n",
      "        [-0.2395,  0.3878],\n",
      "        [-0.3203,  0.4689],\n",
      "        [-0.3751,  0.3092],\n",
      "        [-0.4136,  0.4886],\n",
      "        [-0.4073,  0.3254],\n",
      "        [-0.4554,  0.1236],\n",
      "        [-0.3359,  0.0733],\n",
      "        [-0.4550,  0.6478],\n",
      "        [-0.5933,  0.3620],\n",
      "        [-0.5103,  0.3325],\n",
      "        [-0.4363,  0.1722],\n",
      "        [-0.2495,  0.3637],\n",
      "        [-0.5987,  0.4163],\n",
      "        [-0.3792,  0.2083],\n",
      "        [-0.4732,  0.0729],\n",
      "        [-0.5462,  0.1466],\n",
      "        [-0.4388,  0.3404]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-1.5387e-02,  7.4686e-02],\n",
      "        [-6.2105e-02,  1.1903e-01],\n",
      "        [-1.4717e-01, -2.6049e-02],\n",
      "        [-2.5486e-03,  1.0675e-01],\n",
      "        [-2.0630e-01, -6.5078e-02],\n",
      "        [-1.2803e-01,  4.1474e-01],\n",
      "        [ 6.7597e-02,  2.6908e-01],\n",
      "        [-1.0147e-01,  1.7943e-01],\n",
      "        [ 4.0510e-02, -1.0227e-02],\n",
      "        [ 9.8179e-02,  2.6335e-01],\n",
      "        [-3.5454e-01,  3.6887e-02],\n",
      "        [ 1.0609e-02,  5.6566e-01],\n",
      "        [-1.6704e-01,  2.2274e-01],\n",
      "        [-1.3409e-01,  3.3680e-01],\n",
      "        [-1.9298e-01,  2.4059e-01],\n",
      "        [ 1.1250e-01,  1.4249e-01],\n",
      "        [-1.4114e-01,  4.8413e-01],\n",
      "        [-1.2381e-01,  1.5371e-01],\n",
      "        [ 3.0702e-04, -2.9803e-01],\n",
      "        [ 5.2065e-03, -1.0060e-01],\n",
      "        [ 4.0318e-02,  4.2001e-01],\n",
      "        [-2.1301e-01,  3.0503e-01],\n",
      "        [-3.4741e-01, -4.0855e-03],\n",
      "        [-9.4509e-02,  3.9581e-01],\n",
      "        [-5.4325e-02,  2.3099e-01],\n",
      "        [-4.3637e-02,  2.6626e-01],\n",
      "        [-7.7987e-03,  2.8759e-01],\n",
      "        [-3.1517e-01,  2.8531e-01],\n",
      "        [-5.3255e-02, -5.8940e-02],\n",
      "        [-4.8517e-02,  1.5562e-01],\n",
      "        [-2.0583e-01,  2.2406e-01],\n",
      "        [-9.6907e-02,  4.0020e-01]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.8252, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5707, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.3959, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.3959, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  29%|████████████████████▍                                                 | 64/219 [10:27<26:29, 10.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.2202,  0.4082],\n",
      "        [-0.4182,  0.2050],\n",
      "        [-0.4456,  0.2072],\n",
      "        [-0.2275,  0.1539],\n",
      "        [ 0.0249,  0.2269],\n",
      "        [-0.3954,  0.2656],\n",
      "        [-0.1514, -0.0270],\n",
      "        [-0.4416,  0.0382],\n",
      "        [-0.2743,  0.1874],\n",
      "        [-0.6656, -0.0089],\n",
      "        [-0.0271,  0.0526],\n",
      "        [-0.1224, -0.0533],\n",
      "        [-0.3140,  0.3004],\n",
      "        [ 0.3185,  0.3048],\n",
      "        [-0.4513,  0.1864],\n",
      "        [-0.0067,  0.1839],\n",
      "        [-0.2893,  0.4275],\n",
      "        [-0.2554, -0.0411],\n",
      "        [-0.3770,  0.4027],\n",
      "        [ 0.0134,  0.2919],\n",
      "        [-0.0604,  0.3348],\n",
      "        [-0.3464,  0.1365],\n",
      "        [-0.0533,  0.0702],\n",
      "        [-0.4469, -0.1753],\n",
      "        [-0.1383,  0.2455],\n",
      "        [-0.2518,  0.3025],\n",
      "        [-0.1248,  0.0812],\n",
      "        [-0.3833,  0.3321],\n",
      "        [-0.2696,  0.2124],\n",
      "        [-0.6293,  0.3093],\n",
      "        [-0.5980,  0.4514],\n",
      "        [-0.1661,  0.6904]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.1428,  0.2486],\n",
      "        [ 0.0965,  0.0899],\n",
      "        [-0.1278,  0.2926],\n",
      "        [ 0.0022,  0.0011],\n",
      "        [-0.1840, -0.0533],\n",
      "        [ 0.0771,  0.1376],\n",
      "        [-0.0004, -0.0477],\n",
      "        [ 0.0668,  0.1788],\n",
      "        [-0.2585,  0.1988],\n",
      "        [ 0.3885,  0.1993],\n",
      "        [-0.1957, -0.0640],\n",
      "        [ 0.0910,  0.2581],\n",
      "        [-0.2582, -0.2400],\n",
      "        [ 0.0376, -0.1004],\n",
      "        [-0.0730,  0.1779],\n",
      "        [ 0.0449, -0.0545],\n",
      "        [ 0.0511,  0.0165],\n",
      "        [-0.1072, -0.1553],\n",
      "        [ 0.1263, -0.0420],\n",
      "        [ 0.0515,  0.0257],\n",
      "        [ 0.0093,  0.0254],\n",
      "        [-0.3351, -0.0219],\n",
      "        [-0.1339, -0.1344],\n",
      "        [-0.1646, -0.0883],\n",
      "        [-0.2459,  0.0534],\n",
      "        [ 0.2360,  0.0282],\n",
      "        [-0.4093, -0.0497],\n",
      "        [-0.1838,  0.2070],\n",
      "        [ 0.1187,  0.0336],\n",
      "        [-0.1906, -0.2349],\n",
      "        [-0.1792,  0.0084],\n",
      "        [-0.0246,  0.2475]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.8018, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.6194, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.4212, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.4212, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  30%|████████████████████▊                                                 | 65/219 [10:37<25:54, 10.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1341,  0.4985],\n",
      "        [-0.0457, -0.0784],\n",
      "        [ 0.1648,  0.1542],\n",
      "        [ 0.0793,  0.0845],\n",
      "        [ 0.0277, -0.1061],\n",
      "        [ 0.1760,  0.0234],\n",
      "        [-0.0314,  0.1710],\n",
      "        [ 0.0445,  0.0532],\n",
      "        [ 0.1707,  0.2344],\n",
      "        [ 0.3009, -0.0047],\n",
      "        [ 0.0367,  0.0315],\n",
      "        [ 0.1634,  0.3738],\n",
      "        [ 0.3972, -0.0237],\n",
      "        [ 0.1182,  0.0967],\n",
      "        [ 0.0059,  0.1341],\n",
      "        [ 0.5257, -0.0287],\n",
      "        [ 0.2622, -0.2931],\n",
      "        [ 0.2241,  0.0852],\n",
      "        [ 0.0528,  0.0756],\n",
      "        [ 0.2126,  0.0295],\n",
      "        [-0.1782, -0.0294],\n",
      "        [ 0.1371,  0.1895],\n",
      "        [ 0.1949,  0.2879],\n",
      "        [ 0.1207,  0.4746],\n",
      "        [-0.0429, -0.1955],\n",
      "        [ 0.1498,  0.0267],\n",
      "        [ 0.0217,  0.1100],\n",
      "        [ 0.2002,  0.2665],\n",
      "        [-0.1152,  0.1811],\n",
      "        [-0.0465,  0.3804],\n",
      "        [ 0.1482, -0.0296],\n",
      "        [-0.0191,  0.2519]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.5358, -0.1226],\n",
      "        [ 0.0715,  0.0031],\n",
      "        [-0.2462, -0.4102],\n",
      "        [-0.3305, -0.1538],\n",
      "        [-0.3392, -0.1160],\n",
      "        [-0.0576, -0.2558],\n",
      "        [-0.3997,  0.1123],\n",
      "        [-0.1068, -0.1750],\n",
      "        [-0.4059, -0.0294],\n",
      "        [ 0.0212, -0.1318],\n",
      "        [ 0.1126,  0.2019],\n",
      "        [-0.1560, -0.2852],\n",
      "        [-0.2740, -0.0173],\n",
      "        [ 0.1101, -0.3093],\n",
      "        [-0.1915, -0.1112],\n",
      "        [-0.4728, -0.1874],\n",
      "        [-0.1841, -0.2191],\n",
      "        [-0.2492, -0.1647],\n",
      "        [-0.1973, -0.1465],\n",
      "        [-0.0614, -0.1841],\n",
      "        [-0.2903,  0.0053],\n",
      "        [-0.1261,  0.1686],\n",
      "        [-0.1641, -0.0855],\n",
      "        [-0.3463, -0.0375],\n",
      "        [-0.2593,  0.1044],\n",
      "        [-0.1787, -0.2636],\n",
      "        [-0.3139,  0.0065],\n",
      "        [-0.1699, -0.0706],\n",
      "        [-0.1176,  0.0342],\n",
      "        [-0.2630,  0.0656],\n",
      "        [-0.2463, -0.0851],\n",
      "        [-0.1029, -0.4300]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7381, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4499, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1880, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1880, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  30%|█████████████████████                                                 | 66/219 [10:46<25:28,  9.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 1.9128e-01, -5.8358e-02],\n",
      "        [-1.7159e-01, -3.8527e-02],\n",
      "        [-1.5887e-01,  1.0075e-01],\n",
      "        [ 3.4871e-01,  1.6378e-03],\n",
      "        [ 1.4710e-01,  1.2785e-01],\n",
      "        [ 3.2024e-01,  1.7691e-01],\n",
      "        [ 3.2528e-01,  5.4096e-02],\n",
      "        [ 2.8385e-01,  1.2579e-02],\n",
      "        [-1.3361e-01, -5.6433e-02],\n",
      "        [ 3.8355e-01,  1.1488e-01],\n",
      "        [ 1.2413e-01,  1.7467e-01],\n",
      "        [-1.5844e-01,  5.7386e-02],\n",
      "        [-5.4392e-03, -4.1881e-02],\n",
      "        [-3.9500e-02, -1.5857e-01],\n",
      "        [ 1.0496e-01,  1.5337e-01],\n",
      "        [ 4.8583e-01,  4.7202e-02],\n",
      "        [ 3.9330e-01,  2.8718e-01],\n",
      "        [ 1.5503e-01,  7.1210e-02],\n",
      "        [ 8.9351e-02,  1.6412e-01],\n",
      "        [ 3.0977e-01,  3.2911e-01],\n",
      "        [-3.3596e-04,  2.7794e-01],\n",
      "        [ 9.2912e-02, -2.8405e-01],\n",
      "        [ 6.6275e-02, -1.6694e-01],\n",
      "        [ 1.7640e-01, -1.3335e-01],\n",
      "        [ 3.8749e-01, -1.7564e-01],\n",
      "        [ 2.0539e-01,  2.9703e-01],\n",
      "        [ 4.5283e-02,  2.6741e-02],\n",
      "        [ 3.4470e-01,  1.5239e-01],\n",
      "        [ 2.0489e-01, -2.9340e-01],\n",
      "        [ 1.4780e-01,  1.9632e-01],\n",
      "        [ 2.7755e-01, -3.8923e-02],\n",
      "        [ 2.2845e-01, -1.7083e-02]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.3743,  0.0593],\n",
      "        [-0.4330, -0.0534],\n",
      "        [-0.1395, -0.2053],\n",
      "        [-0.3271, -0.2047],\n",
      "        [-0.3450, -0.3583],\n",
      "        [-0.4533,  0.1431],\n",
      "        [-0.4098, -0.1409],\n",
      "        [-0.4706, -0.1522],\n",
      "        [-0.1279, -0.4638],\n",
      "        [-0.2387,  0.0919],\n",
      "        [-0.2176,  0.0718],\n",
      "        [-0.3043,  0.0058],\n",
      "        [-0.1634,  0.0060],\n",
      "        [-0.5475, -0.2147],\n",
      "        [-0.4336, -0.0289],\n",
      "        [-0.3960, -0.1771],\n",
      "        [ 0.0231,  0.0858],\n",
      "        [-0.3535, -0.0123],\n",
      "        [-0.4780,  0.0414],\n",
      "        [-0.1741, -0.1681],\n",
      "        [-0.2788,  0.0461],\n",
      "        [-0.2565, -0.0500],\n",
      "        [-0.3401, -0.1375],\n",
      "        [-0.4951, -0.2467],\n",
      "        [-0.2848, -0.3326],\n",
      "        [-0.0721, -0.5497],\n",
      "        [-0.3924, -0.0593],\n",
      "        [-0.2327, -0.1260],\n",
      "        [-0.2172, -0.1517],\n",
      "        [ 0.0576, -0.1446],\n",
      "        [-0.3316, -0.3232],\n",
      "        [-0.0837, -0.2557]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7177, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5746, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2923, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2923, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  31%|█████████████████████▍                                                | 67/219 [10:56<25:06,  9.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 2.3788e-01,  1.2284e-01],\n",
      "        [ 3.2789e-01,  4.6587e-02],\n",
      "        [ 2.7503e-01,  2.4857e-01],\n",
      "        [ 8.0839e-02,  1.3438e-01],\n",
      "        [ 2.1113e-01,  4.9970e-01],\n",
      "        [ 2.0926e-01, -4.3558e-02],\n",
      "        [-6.9627e-02, -3.4910e-01],\n",
      "        [ 3.9305e-01,  5.2239e-03],\n",
      "        [ 2.9919e-01, -7.0444e-04],\n",
      "        [ 4.9938e-01, -7.6199e-02],\n",
      "        [ 1.9300e-01,  1.4066e-01],\n",
      "        [ 7.3752e-01, -6.5732e-03],\n",
      "        [ 1.4026e-01, -3.4913e-01],\n",
      "        [ 2.5794e-01,  6.9319e-03],\n",
      "        [ 2.2666e-01, -9.1297e-02],\n",
      "        [ 3.6854e-01,  2.0631e-01],\n",
      "        [ 4.6597e-01,  1.8157e-01],\n",
      "        [ 4.0678e-01,  2.2497e-02],\n",
      "        [ 3.6604e-01,  7.9737e-02],\n",
      "        [ 4.7036e-01,  4.2412e-01],\n",
      "        [ 3.3149e-01,  2.6591e-01],\n",
      "        [ 2.6336e-02,  2.4650e-01],\n",
      "        [ 1.6570e-01,  1.6453e-01],\n",
      "        [-6.5632e-03,  6.0162e-02],\n",
      "        [-1.6109e-01, -1.9295e-02],\n",
      "        [ 3.2401e-01,  2.1450e-02],\n",
      "        [-2.8611e-02, -1.5531e-01],\n",
      "        [ 1.4767e-01, -1.4311e-03],\n",
      "        [ 2.0222e-01, -1.5549e-01],\n",
      "        [ 2.4574e-01, -4.1814e-01],\n",
      "        [ 2.0918e-01,  3.4521e-02],\n",
      "        [ 2.0880e-01,  7.6057e-02]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.5363, -0.0908],\n",
      "        [-0.4068, -0.1747],\n",
      "        [-0.2989, -0.3299],\n",
      "        [-0.1537, -0.1830],\n",
      "        [-0.5253, -0.2313],\n",
      "        [-0.2716, -0.1063],\n",
      "        [-0.4063, -0.0787],\n",
      "        [-0.2450, -0.0368],\n",
      "        [-0.4811, -0.3934],\n",
      "        [-0.1100, -0.0733],\n",
      "        [-0.5621, -0.1768],\n",
      "        [-0.2724,  0.1079],\n",
      "        [-0.5278,  0.0349],\n",
      "        [-0.3168,  0.0640],\n",
      "        [-0.2115,  0.0540],\n",
      "        [-0.2907, -0.1423],\n",
      "        [-0.3981, -0.2864],\n",
      "        [-0.2464,  0.0679],\n",
      "        [-0.4872, -0.2489],\n",
      "        [-0.3306, -0.2723],\n",
      "        [-0.1088, -0.3076],\n",
      "        [-0.3040, -0.3603],\n",
      "        [-0.6039, -0.4966],\n",
      "        [-0.3812, -0.5052],\n",
      "        [-0.1996, -0.1703],\n",
      "        [-0.4839,  0.0333],\n",
      "        [-0.1743, -0.4854],\n",
      "        [-0.2751, -0.2485],\n",
      "        [-0.3253, -0.0552],\n",
      "        [-0.4449, -0.2706],\n",
      "        [-0.6142,  0.0211],\n",
      "        [-0.2212,  0.0434]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.6810, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5236, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2046, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2046, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  31%|█████████████████████▋                                                | 68/219 [11:06<24:57,  9.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.4087,  0.1221],\n",
      "        [ 0.2396, -0.0311],\n",
      "        [-0.1158, -0.1745],\n",
      "        [ 0.4176, -0.3143],\n",
      "        [ 0.2962,  0.0559],\n",
      "        [ 0.4012,  0.1754],\n",
      "        [ 0.3610,  0.1014],\n",
      "        [ 0.0428, -0.1227],\n",
      "        [ 0.1252, -0.0748],\n",
      "        [ 0.3211, -0.2508],\n",
      "        [ 0.4002, -0.1311],\n",
      "        [ 0.4607, -0.1687],\n",
      "        [ 0.2067,  0.0493],\n",
      "        [ 0.3682, -0.1346],\n",
      "        [ 0.5154, -0.0389],\n",
      "        [ 0.2019,  0.0780],\n",
      "        [ 0.1226, -0.2188],\n",
      "        [ 0.3797, -0.0213],\n",
      "        [ 0.2652, -0.2644],\n",
      "        [ 0.2001, -0.0948],\n",
      "        [ 0.0989,  0.0766],\n",
      "        [ 0.2580, -0.1411],\n",
      "        [ 0.3803, -0.0561],\n",
      "        [ 0.3372,  0.2159],\n",
      "        [ 0.1801,  0.1309],\n",
      "        [ 0.0988, -0.5120],\n",
      "        [ 0.3202, -0.3050],\n",
      "        [ 0.3221,  0.1814],\n",
      "        [ 0.3820, -0.1246],\n",
      "        [ 0.1504,  0.1518],\n",
      "        [ 0.1500, -0.3222],\n",
      "        [ 0.2163, -0.0488]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.5710, -0.2265],\n",
      "        [-0.3334, -0.1645],\n",
      "        [-0.4279, -0.1818],\n",
      "        [-0.5034, -0.0840],\n",
      "        [-0.4197,  0.0302],\n",
      "        [-0.0686, -0.0172],\n",
      "        [-0.3376, -0.2768],\n",
      "        [-0.1409, -0.2186],\n",
      "        [-0.5927, -0.1324],\n",
      "        [-0.5434, -0.1637],\n",
      "        [-0.2493,  0.2903],\n",
      "        [-0.3981, -0.0046],\n",
      "        [-0.3349, -0.0953],\n",
      "        [-0.2102,  0.3516],\n",
      "        [-0.6777,  0.0095],\n",
      "        [-0.2178, -0.2464],\n",
      "        [-0.4981, -0.3568],\n",
      "        [-0.2760, -0.2894],\n",
      "        [-0.1114, -0.1332],\n",
      "        [-0.4823, -0.4582],\n",
      "        [-0.0953, -0.0946],\n",
      "        [-0.3580, -0.0554],\n",
      "        [-0.6619, -0.4464],\n",
      "        [-0.4051, -0.1764],\n",
      "        [-0.2913, -0.1827],\n",
      "        [-0.2927, -0.2399],\n",
      "        [-0.4219, -0.4546],\n",
      "        [-0.3535, -0.4747],\n",
      "        [-0.3542, -0.1300],\n",
      "        [-0.1994, -0.5950],\n",
      "        [-0.1885, -0.1969],\n",
      "        [-0.3014, -0.1824]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7721, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.3769, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1491, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1491, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|██████████████████████                                                | 69/219 [11:16<24:38,  9.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1491, -0.0509],\n",
      "        [ 0.6983,  0.0747],\n",
      "        [ 0.1681,  0.2566],\n",
      "        [ 0.1985, -0.3593],\n",
      "        [ 0.2514,  0.1974],\n",
      "        [-0.0541,  0.1119],\n",
      "        [ 0.3017,  0.1155],\n",
      "        [-0.0297, -0.1575],\n",
      "        [-0.2184,  0.1304],\n",
      "        [-0.0183, -0.2002],\n",
      "        [ 0.0338, -0.0514],\n",
      "        [ 0.0595, -0.2305],\n",
      "        [ 0.2090,  0.4257],\n",
      "        [ 0.1468,  0.2283],\n",
      "        [ 0.1534, -0.0315],\n",
      "        [ 0.2878, -0.0395],\n",
      "        [ 0.3164, -0.1068],\n",
      "        [ 0.1718, -0.1789],\n",
      "        [ 0.3745, -0.0178],\n",
      "        [ 0.2368, -0.2215],\n",
      "        [ 0.3106,  0.2264],\n",
      "        [ 0.2242,  0.1402],\n",
      "        [ 0.1050,  0.1227],\n",
      "        [ 0.1872,  0.0082],\n",
      "        [ 0.0035, -0.0655],\n",
      "        [ 0.1996, -0.0386],\n",
      "        [ 0.2370,  0.4999],\n",
      "        [ 0.1458,  0.4052],\n",
      "        [ 0.1791,  0.3850],\n",
      "        [ 0.4171,  0.0995],\n",
      "        [ 0.2739,  0.1868],\n",
      "        [-0.0531,  0.2872]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.2516, -0.0980],\n",
      "        [-0.6735, -0.1615],\n",
      "        [-0.3623, -0.1704],\n",
      "        [-0.6114, -0.6203],\n",
      "        [-0.5746, -0.4233],\n",
      "        [-0.5863, -0.2360],\n",
      "        [-0.3805, -0.1509],\n",
      "        [-0.3290, -0.4280],\n",
      "        [-0.3751, -0.1419],\n",
      "        [-0.4020, -0.2679],\n",
      "        [-0.2018, -0.6003],\n",
      "        [-0.3612, -0.2894],\n",
      "        [-0.4145, -0.1872],\n",
      "        [-0.4172, -0.1938],\n",
      "        [-0.3760, -0.2310],\n",
      "        [-0.5058, -0.2223],\n",
      "        [-0.4602, -0.1974],\n",
      "        [-0.2590, -0.3893],\n",
      "        [-0.3680, -0.0198],\n",
      "        [-0.7333, -0.2564],\n",
      "        [-0.0927, -0.3988],\n",
      "        [-0.1949, -0.4449],\n",
      "        [-0.4037, -0.0697],\n",
      "        [-0.3377, -0.2066],\n",
      "        [-0.2533, -0.0636],\n",
      "        [-0.2558,  0.0266],\n",
      "        [-0.1699, -0.1257],\n",
      "        [-0.2969, -0.1160],\n",
      "        [-0.1165, -0.5962],\n",
      "        [-0.4716, -0.2098],\n",
      "        [-0.2818, -0.3030],\n",
      "        [-0.3606, -0.4648]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7160, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4748, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1908, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1908, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|██████████████████████▎                                               | 70/219 [11:26<24:39,  9.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0289,  0.0695],\n",
      "        [-0.1723,  0.1055],\n",
      "        [ 0.1731, -0.0434],\n",
      "        [ 0.0545,  0.0717],\n",
      "        [ 0.0017,  0.2981],\n",
      "        [-0.1726, -0.0387],\n",
      "        [-0.1179, -0.0223],\n",
      "        [-0.0438,  0.2303],\n",
      "        [-0.0799,  0.0218],\n",
      "        [ 0.2141,  0.2773],\n",
      "        [-0.0308,  0.2023],\n",
      "        [-0.0228,  0.3701],\n",
      "        [-0.0324,  0.1515],\n",
      "        [ 0.0949,  0.2468],\n",
      "        [-0.0358,  0.2803],\n",
      "        [ 0.1424,  0.2950],\n",
      "        [ 0.2231,  0.1123],\n",
      "        [ 0.0356,  0.5339],\n",
      "        [ 0.2149,  0.2458],\n",
      "        [ 0.3497,  0.2702],\n",
      "        [ 0.1281,  0.0337],\n",
      "        [ 0.1836,  0.4296],\n",
      "        [ 0.0960,  0.1353],\n",
      "        [-0.2161, -0.1256],\n",
      "        [-0.2562,  0.1795],\n",
      "        [-0.1311,  0.0532],\n",
      "        [ 0.1997,  0.3516],\n",
      "        [-0.0041, -0.0466],\n",
      "        [ 0.2110,  0.2748],\n",
      "        [-0.0392,  0.3183],\n",
      "        [ 0.0575,  0.0550],\n",
      "        [-0.3123,  0.0768]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.3486, -0.1364],\n",
      "        [-0.2714, -0.3483],\n",
      "        [-0.2577, -0.1041],\n",
      "        [-0.3344, -0.3372],\n",
      "        [ 0.0831, -0.2806],\n",
      "        [-0.4268, -0.0191],\n",
      "        [-0.3540, -0.2092],\n",
      "        [-0.5259, -0.1935],\n",
      "        [-0.0771, -0.1802],\n",
      "        [-0.3183, -0.4173],\n",
      "        [-0.1483, -0.2694],\n",
      "        [-0.4385, -0.1784],\n",
      "        [-0.4003, -0.3570],\n",
      "        [-0.5482, -0.2075],\n",
      "        [-0.5234, -0.0747],\n",
      "        [-0.0714, -0.3290],\n",
      "        [-0.4239, -0.0300],\n",
      "        [-0.1906, -0.4656],\n",
      "        [-0.4381, -0.2842],\n",
      "        [-0.3890, -0.0459],\n",
      "        [-0.4975, -0.0825],\n",
      "        [-0.3259, -0.2888],\n",
      "        [-0.6752, -0.5233],\n",
      "        [-0.2721, -0.0959],\n",
      "        [-0.5638, -0.3660],\n",
      "        [-0.2908, -0.2066],\n",
      "        [-0.4478,  0.0488],\n",
      "        [-0.4088, -0.1104],\n",
      "        [-0.3072, -0.2072],\n",
      "        [-0.2322, -0.0916],\n",
      "        [-0.1746, -0.1802],\n",
      "        [-0.5572, -0.4103]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7050, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.6241, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.3291, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.3291, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|██████████████████████▋                                               | 71/219 [11:36<24:27,  9.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.1555,  0.1390],\n",
      "        [ 0.0364,  0.1238],\n",
      "        [ 0.0344, -0.1905],\n",
      "        [ 0.0343,  0.2872],\n",
      "        [ 0.3778,  0.1571],\n",
      "        [ 0.0906,  0.1088],\n",
      "        [ 0.2150,  0.1954],\n",
      "        [ 0.0282,  0.0273],\n",
      "        [ 0.1171,  0.0085],\n",
      "        [-0.1264,  0.1069],\n",
      "        [ 0.0181,  0.1688],\n",
      "        [ 0.0261,  0.1509],\n",
      "        [ 0.1425,  0.1601],\n",
      "        [ 0.0133,  0.0388],\n",
      "        [ 0.0170,  0.3007],\n",
      "        [-0.1994,  0.2762],\n",
      "        [ 0.0220, -0.0039],\n",
      "        [-0.1072, -0.2665],\n",
      "        [ 0.1687,  0.0219],\n",
      "        [ 0.2063,  0.0405],\n",
      "        [ 0.1496, -0.0041],\n",
      "        [ 0.2253,  0.1033],\n",
      "        [-0.1415, -0.0306],\n",
      "        [ 0.0036,  0.0406],\n",
      "        [-0.0988,  0.4490],\n",
      "        [ 0.2348,  0.1738],\n",
      "        [-0.0725,  0.1895],\n",
      "        [ 0.1761, -0.1136],\n",
      "        [ 0.0325,  0.0798],\n",
      "        [-0.0063,  0.1291],\n",
      "        [ 0.0973,  0.1650],\n",
      "        [-0.0096,  0.1363]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.4609, -0.2020],\n",
      "        [-0.2749, -0.4702],\n",
      "        [-0.3337, -0.2839],\n",
      "        [-0.3294, -0.3060],\n",
      "        [-0.3572, -0.3414],\n",
      "        [-0.4073, -0.0604],\n",
      "        [-0.1196, -0.1712],\n",
      "        [-0.2885, -0.4017],\n",
      "        [-0.4221, -0.3657],\n",
      "        [-0.4956, -0.2684],\n",
      "        [-0.5943, -0.2363],\n",
      "        [-0.5837, -0.4976],\n",
      "        [-0.5562, -0.2718],\n",
      "        [-0.2467, -0.1839],\n",
      "        [-0.3730, -0.3380],\n",
      "        [-0.4084, -0.1149],\n",
      "        [-0.4888, -0.0726],\n",
      "        [ 0.0727, -0.4230],\n",
      "        [-0.4825, -0.3341],\n",
      "        [-0.4332, -0.1340],\n",
      "        [-0.4885,  0.0128],\n",
      "        [-0.3909, -0.3233],\n",
      "        [-0.2177, -0.2546],\n",
      "        [-0.0328, -0.2368],\n",
      "        [-0.5342, -0.3134],\n",
      "        [-0.1811, -0.2434],\n",
      "        [-0.2328, -0.1593],\n",
      "        [-0.4064, -0.4837],\n",
      "        [-0.3490, -0.0286],\n",
      "        [-0.1882, -0.1825],\n",
      "        [-0.5190, -0.2166],\n",
      "        [-0.0751, -0.3254]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7059, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5494, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2552, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2552, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  33%|███████████████████████                                               | 72/219 [11:46<24:07,  9.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.0249, -0.3148],\n",
      "        [-0.0431,  0.0101],\n",
      "        [ 0.0667,  0.1318],\n",
      "        [-0.0500,  0.2607],\n",
      "        [ 0.3007,  0.1043],\n",
      "        [ 0.4256,  0.0819],\n",
      "        [-0.0189,  0.0905],\n",
      "        [-0.0925,  0.2607],\n",
      "        [-0.1948,  0.0580],\n",
      "        [-0.0791,  0.2266],\n",
      "        [ 0.1003,  0.1371],\n",
      "        [ 0.3390,  0.1487],\n",
      "        [ 0.2398,  0.0495],\n",
      "        [ 0.0473,  0.3364],\n",
      "        [-0.1382,  0.1655],\n",
      "        [-0.2833,  0.1098],\n",
      "        [ 0.1332,  0.0447],\n",
      "        [ 0.2035,  0.0492],\n",
      "        [ 0.0536, -0.0590],\n",
      "        [ 0.1313,  0.0075],\n",
      "        [ 0.1165,  0.1260],\n",
      "        [ 0.0155, -0.0379],\n",
      "        [ 0.0744,  0.1430],\n",
      "        [ 0.2080, -0.1566],\n",
      "        [ 0.2301, -0.0753],\n",
      "        [ 0.1734, -0.1067],\n",
      "        [ 0.2225,  0.3941],\n",
      "        [-0.1685, -0.1370],\n",
      "        [ 0.3010,  0.0554],\n",
      "        [-0.1317,  0.0704],\n",
      "        [ 0.0017,  0.1015],\n",
      "        [ 0.3420,  0.1574]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.4429, -0.4989],\n",
      "        [-0.2764, -0.5100],\n",
      "        [-0.6078, -0.3636],\n",
      "        [-0.1105, -0.2421],\n",
      "        [-0.4568, -0.2753],\n",
      "        [-0.1323, -0.2929],\n",
      "        [-0.4758, -0.4561],\n",
      "        [ 0.2073, -0.2910],\n",
      "        [-0.3152, -0.1733],\n",
      "        [-0.2977, -0.0515],\n",
      "        [-0.2841, -0.3581],\n",
      "        [-0.2807, -0.2013],\n",
      "        [-0.4175, -0.0976],\n",
      "        [-0.3583, -0.2099],\n",
      "        [-0.4336, -0.1473],\n",
      "        [-0.3109, -0.2749],\n",
      "        [-0.2806, -0.2883],\n",
      "        [-0.1454, -0.3817],\n",
      "        [-0.4979, -0.2193],\n",
      "        [-0.3490, -0.2312],\n",
      "        [-0.1646, -0.2231],\n",
      "        [-0.2067, -0.2985],\n",
      "        [-0.3788, -0.2391],\n",
      "        [-0.3118, -0.2461],\n",
      "        [-0.3950, -0.2756],\n",
      "        [-0.1944, -0.1765],\n",
      "        [-0.2975, -0.6358],\n",
      "        [-0.0505, -0.0625],\n",
      "        [-0.7111, -0.3938],\n",
      "        [-0.3600, -0.5441],\n",
      "        [-0.1573, -0.4227],\n",
      "        [-0.5019, -0.5861]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7036, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.4759, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.1795, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.1795, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  33%|███████████████████████▎                                              | 73/219 [11:55<23:49,  9.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[ 0.1044,  0.3056],\n",
      "        [ 0.2009, -0.1014],\n",
      "        [-0.4855,  0.3576],\n",
      "        [ 0.3056,  0.1277],\n",
      "        [ 0.1591,  0.0184],\n",
      "        [ 0.3755,  0.2151],\n",
      "        [ 0.0999, -0.2284],\n",
      "        [ 0.0884,  0.3289],\n",
      "        [-0.1518,  0.1098],\n",
      "        [ 0.0092,  0.2647],\n",
      "        [ 0.2620,  0.2656],\n",
      "        [ 0.1621,  0.1714],\n",
      "        [ 0.0681,  0.0135],\n",
      "        [ 0.0407,  0.5468],\n",
      "        [-0.1770, -0.1784],\n",
      "        [-0.0120,  0.1566],\n",
      "        [ 0.0771,  0.0411],\n",
      "        [-0.2928,  0.4299],\n",
      "        [-0.1464,  0.0494],\n",
      "        [-0.0250,  0.0272],\n",
      "        [ 0.0989, -0.0970],\n",
      "        [ 0.1947,  0.4544],\n",
      "        [ 0.0675, -0.4055],\n",
      "        [-0.2738,  0.1908],\n",
      "        [ 0.0705,  0.2868],\n",
      "        [ 0.3908, -0.0344],\n",
      "        [-0.1774,  0.1369],\n",
      "        [-0.2174, -0.1639],\n",
      "        [-0.0316, -0.1408],\n",
      "        [-0.1758,  0.2875],\n",
      "        [-0.1669, -0.0496],\n",
      "        [ 0.3294,  0.3272]], grad_fn=<AddmmBackward>)\n",
      "logits_cos:\n",
      "tensor([[-0.6315, -0.4128],\n",
      "        [-0.3227,  0.2805],\n",
      "        [-0.6045, -0.6309],\n",
      "        [-0.1312, -0.1709],\n",
      "        [-0.1188, -0.1522],\n",
      "        [-0.5511, -0.1161],\n",
      "        [-0.1644, -0.0397],\n",
      "        [-0.8196, -0.3825],\n",
      "        [-0.4311, -0.1544],\n",
      "        [-0.2272, -0.1759],\n",
      "        [-0.1681, -0.3244],\n",
      "        [-0.4081, -0.3223],\n",
      "        [-0.5292, -0.2556],\n",
      "        [-0.4692, -0.4051],\n",
      "        [-0.2531, -0.0125],\n",
      "        [-0.5796, -0.2136],\n",
      "        [-0.1372, -0.5019],\n",
      "        [-0.3169, -0.3594],\n",
      "        [-0.3281, -0.5004],\n",
      "        [-0.4641, -0.2138],\n",
      "        [-0.0502, -0.3402],\n",
      "        [-0.0648, -0.3026],\n",
      "        [-0.3256, -0.2190],\n",
      "        [-0.1178, -0.2256],\n",
      "        [-0.0493, -0.5685],\n",
      "        [-0.0153, -0.1945],\n",
      "        [-0.3575, -0.6731],\n",
      "        [-0.2604, -0.1094],\n",
      "        [-0.3759, -0.1792],\n",
      "        [-0.1078, -0.4155],\n",
      "        [-0.2379, -0.1738],\n",
      "        [-0.2499, -0.2497]], grad_fn=<AddmmBackward>)\n",
      "loss_ce:\n",
      "tensor(0.7260, grad_fn=<NllLossBackward>)\n",
      "loss_cos:\n",
      "tensor(0.5517, grad_fn=<MeanBackward0>)\n",
      "final loss:\n",
      "tensor(1.2778, grad_fn=<AddBackward0>)\n",
      "out_results:\n",
      "tensor(1.2778, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  34%|███████████████████████▋                                              | 74/219 [12:05<23:46,  9.84s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids, claim_input_ids, claim_input_mask, claim_segment_ids, claim_label_ids = batch\n",
    "#         ce_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "#         cos_loss = model(claim_input_ids, claim_segment_ids, claim_input_mask, claim_label_ids)\n",
    "        \n",
    "#         print(\"start\")\n",
    "#         print(input_ids)\n",
    "#         print(input_mask)\n",
    "#         print(segment_ids)\n",
    "#         print(label_ids)\n",
    "#         print(claim_input_ids)\n",
    "#         print(claim_input_mask)\n",
    "#         print(claim_segment_ids)\n",
    "#         print(claim_label_ids)\n",
    "#         print(\"end\")\n",
    "    \n",
    "        out_results = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, labels=label_ids, input_ids2=claim_input_ids, token_type_ids2=claim_segment_ids, attention_mask2=claim_input_mask, labels2=claim_label_ids)\n",
    "#         loss = ce_loss + cos_loss\n",
    "        print(\"out_results:\")\n",
    "        print(out_results)\n",
    "        loss = out_results\n",
    "#         print(cos_loss)\n",
    "#         print(loss.item())\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "#         if fp16 and loss_scale != 1.0:\n",
    "#             # rescale loss for fp16 training\n",
    "#             # see https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html\n",
    "#             loss = loss * loss_scale\n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "#             if fp16 or optimize_on_cpu:\n",
    "#                 if fp16 and loss_scale != 1.0:\n",
    "#                     # scale down gradients for fp16 training\n",
    "#                     for param in model.parameters():\n",
    "#                         if param.grad is not None:\n",
    "#                             param.grad.data = param.grad.data / loss_scale           \n",
    "#                 is_nan = set_optimizer_params_grad(param_optimizer, model.named_parameters(), test_nan=True)\n",
    "#                 if is_nan:\n",
    "#                     logger.info(\"FP16 TRAINING: Nan in gradients, reducing loss scaling\")\n",
    "#                     loss_scale = loss_scale / 2\n",
    "#                     model.zero_grad()\n",
    "#                     continue \n",
    "#                 optimizer.step()\n",
    "# #                 scheduler.step()\n",
    "#                 copy_optimizer_params_to_model(model.named_parameters(), param_optimizer)\n",
    "#             else:\n",
    "#                 torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "#                 scheduler.step()\n",
    "            model.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "        \n",
    "## v2: concat\n",
    "## v3: multiply\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "torch.save(model.state_dict(), output_dir + \"cos_emb.pth\")\n",
    "torch.save(model_to_save.state_dict(), output_dir + \"finetuned_cos_emb.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "def train_and_test(data_dir, bert_model=\"bert-base-uncased\", task_name=None,\n",
    "                   output_dir=None, max_seq_length=32, do_train=False, do_eval=False, do_lower_case=False,\n",
    "                   train_batch_size=32, eval_batch_size=8, learning_rate=5e-5, num_train_epochs=3,\n",
    "                   warmup_proportion=0.1,no_cuda=False, local_rank=-1, seed=42, gradient_accumulation_steps=1,\n",
    "                   optimize_on_cpu=False, fp16=False, loss_scale=128, saved_model=\"\"):\n",
    "\n",
    "\n",
    "    # ## Required parameters\n",
    "    # parser.add_argument(\"--data_dir\",\n",
    "    #                     default=None,\n",
    "    #                     type=str,\n",
    "    #                     required=True,\n",
    "    #                     help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n",
    "    # parser.add_argument(\"--bert_model\", default=None, type=str, required=True,\n",
    "    #                     help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
    "    #                          \"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\")\n",
    "    # parser.add_argument(\"--task_name\",\n",
    "    #                     default=None,\n",
    "    #                     type=str,\n",
    "    #                     required=True,\n",
    "    #                     help=\"The name of the task to train.\")\n",
    "    # parser.add_argument(\"--output_dir\",\n",
    "    #                     default=None,\n",
    "    #                     type=str,\n",
    "    #                     required=True,\n",
    "    #                     help=\"The output directory where the model checkpoints will be written.\")\n",
    "\n",
    "    ## Other parameters\n",
    "    # parser.add_argument(\"--max_seq_length\",\n",
    "    #                     default=128,\n",
    "    #                     type=int,\n",
    "    #                     help=\"The maximum total input sequence length after WordPiece tokenization. \\n\"\n",
    "    #                          \"Sequences longer than this will be truncated, and sequences shorter \\n\"\n",
    "    #                          \"than this will be padded.\")\n",
    "    # parser.add_argument(\"--do_train\",\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to run training.\")\n",
    "    # parser.add_argument(\"--do_eval\",\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to run eval on the dev set.\")\n",
    "    # parser.add_argument(\"--do_lower_case\",\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Set this flag if you are using an uncased model.\")\n",
    "    # parser.add_argument(\"--train_batch_size\",\n",
    "    #                     default=32,\n",
    "    #                     type=int,\n",
    "    #                     help=\"Total batch size for training.\")\n",
    "    # parser.add_argument(\"--eval_batch_size\",\n",
    "    #                     default=8,\n",
    "    #                     type=int,\n",
    "    #                     help=\"Total batch size for eval.\")\n",
    "    # parser.add_argument(\"--learning_rate\",\n",
    "    #                     default=5e-5,\n",
    "    #                     type=float,\n",
    "    #                     help=\"The initial learning rate for Adam.\")\n",
    "    # parser.add_argument(\"--num_train_epochs\",\n",
    "    #                     default=3.0,\n",
    "    #                     type=float,\n",
    "    #                     help=\"Total number of training epochs to perform.\")\n",
    "    # parser.add_argument(\"--warmup_proportion\",\n",
    "    #                     default=0.1,\n",
    "    #                     type=float,\n",
    "    #                     help=\"Proportion of training to perform linear learning rate warmup for. \"\n",
    "    #                          \"E.g., 0.1 = 10%% of training.\")\n",
    "    # parser.add_argument(\"--no_cuda\",\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether not to use CUDA when available\")\n",
    "    # parser.add_argument(\"--local_rank\",\n",
    "    #                     type=int,\n",
    "    #                     default=-1,\n",
    "    #                     help=\"local_rank for distributed training on gpus\")\n",
    "    # parser.add_argument('--seed',\n",
    "    #                     type=int,\n",
    "    #                     default=42,\n",
    "    #                     help=\"random seed for initialization\")\n",
    "    # parser.add_argument('--gradient_accumulation_steps',\n",
    "    #                     type=int,\n",
    "    #                     default=1,\n",
    "    #                     help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "    # parser.add_argument('--optimize_on_cpu',\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to perform optimization and keep the optimizer averages on CPU\")\n",
    "    # parser.add_argument('--fp16',\n",
    "    #                     default=False,\n",
    "    #                     action='store_true',\n",
    "    #                     help=\"Whether to use 16-bit float precision instead of 32-bit\")\n",
    "    # parser.add_argument('--loss_scale',\n",
    "    #                     type=float, default=128,\n",
    "    #                     help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    processors = {\n",
    "#         \"cola\": ColaProcessor,\n",
    "#         \"mnli\": MnliProcessor,\n",
    "        \"mrpc\": MrpcProcessor,\n",
    "    }\n",
    "\n",
    "    if local_rank == -1 or no_cuda:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "    else:\n",
    "        device = torch.device(\"cuda\", local_rank)\n",
    "        n_gpu = 1\n",
    "        # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "        torch.distributed.init_process_group(backend='nccl')\n",
    "        if fp16:\n",
    "            logger.info(\"16-bits training currently not supported in distributed training\")\n",
    "            fp16 = False # (see https://github.com/pytorch/pytorch/pull/13496)\n",
    "    logger.info(\"device %s n_gpu %d distributed training %r\", device, n_gpu, bool(local_rank != -1))\n",
    "\n",
    "    if gradient_accumulation_steps < 1:\n",
    "        raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(\n",
    "                            gradient_accumulation_steps))\n",
    "\n",
    "    train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    if not do_train and not do_eval:\n",
    "        raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "    if do_train:\n",
    "        if os.path.exists(output_dir) and os.listdir(output_dir):\n",
    "            raise ValueError(\"Output directory ({}) already exists and is not emp1ty.\".format(output_dir))\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    task_name = task_name.lower()\n",
    "\n",
    "    if task_name not in processors:\n",
    "        raise ValueError(\"Task not found: %s\" % (task_name))\n",
    "\n",
    "    processor = processors[task_name]()\n",
    "    label_list = processor.get_labels()\n",
    "\n",
    "#     tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=do_lower_case)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    train_examples = None\n",
    "    num_train_steps = None\n",
    "    if do_train:\n",
    "        train_examples = processor.get_train_examples(data_dir)\n",
    "        num_train_steps = int(\n",
    "            len(train_examples) / train_batch_size / gradient_accumulation_steps * num_train_epochs)\n",
    "\n",
    "    # Prepare model\n",
    "#     model = BertForSequenceClassification.from_pretrained(bert_model,\n",
    "#                 cache_dir=PYTORCH_PRETRAINED_BERT_CACHE / 'distributed_{}'.format(local_rank), num_labels = 2)\n",
    "\n",
    "        model = BertForConsistencyCueClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "        model.to(device)\n",
    "        if fp16:\n",
    "            model.half()\n",
    "\n",
    "        if local_rank != -1:\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank],\n",
    "                                                              output_device=local_rank)\n",
    "        elif n_gpu > 1:\n",
    "            model = torch.nn.DataParallel(model)\n",
    "\n",
    "        # Prepare optimizer\n",
    "        if fp16:\n",
    "            param_optimizer = [(n, param.clone().detach().to('cpu').float().requires_grad_()) \\\n",
    "                                for n, param in model.named_parameters()]\n",
    "        elif optimize_on_cpu:\n",
    "            param_optimizer = [(n, param.clone().detach().to('cpu').requires_grad_()) \\\n",
    "                                for n, param in model.named_parameters()]\n",
    "        else:\n",
    "            param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "            ]\n",
    "        t_total = num_train_steps\n",
    "#     print(t_total)\n",
    "    if local_rank != -1:\n",
    "        t_total = t_total // torch.distributed.get_world_size()\n",
    "    if do_train:\n",
    "        optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=learning_rate,\n",
    "                         warmup=warmup_proportion,\n",
    "                         t_total=t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    if do_train:\n",
    "        train_features = convert_examples_to_features(\n",
    "            train_examples, label_list, max_seq_length, tokenizer)\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "        logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "        logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "        train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "        if local_rank == -1:\n",
    "            train_sampler = RandomSampler(train_data)\n",
    "        else:\n",
    "            train_sampler = DistributedSampler(train_data)\n",
    "        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
    "\n",
    "        model.train()\n",
    "        for _ in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
    "            tr_loss = 0\n",
    "            nb_tr_examples, nb_tr_steps = 0, 0\n",
    "            for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids, input_mask, segment_ids, label_ids, = batch\n",
    "                loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "                if n_gpu > 1:\n",
    "                    loss = loss.mean() # mean() to average on multi-gpu.\n",
    "                if fp16 and loss_scale != 1.0:\n",
    "                    # rescale loss for fp16 training\n",
    "                    # see https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html\n",
    "                    loss = loss * loss_scale\n",
    "                if gradient_accumulation_steps > 1:\n",
    "                    loss = loss / gradient_accumulation_steps\n",
    "                loss.backward()\n",
    "                tr_loss += loss.item()\n",
    "                nb_tr_examples += input_ids.size(0)\n",
    "                nb_tr_steps += 1\n",
    "                if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                    if fp16 or optimize_on_cpu:\n",
    "                        if fp16 and loss_scale != 1.0:\n",
    "                            # scale down gradients for fp16 training\n",
    "                            for param in model.parameters():\n",
    "                                if param.grad is not None:\n",
    "                                    param.grad.data = param.grad.data / loss_scale\n",
    "                        is_nan = set_optimizer_params_grad(param_optimizer, model.named_parameters(), test_nan=True)\n",
    "                        if is_nan:\n",
    "                            logger.info(\"FP16 TRAINING: Nan in gradients, reducing loss scaling\")\n",
    "                            loss_scale = loss_scale / 2\n",
    "                            model.zero_grad()\n",
    "                            continue\n",
    "                        optimizer.step()\n",
    "                        copy_optimizer_params_to_model(model.named_parameters(), param_optimizer)\n",
    "                    else:\n",
    "                        optimizer.step()\n",
    "                    model.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "        torch.save(model.state_dict(), output_dir + \"output.pth\")\n",
    "\n",
    "\n",
    "    if do_eval and (local_rank == -1 or torch.distributed.get_rank() == 0):\n",
    "        eval_examples = processor.get_test_examples(data_dir)\n",
    "#         eval_examples = processor.get_dev_examples(data_dir)\n",
    "        eval_features = convert_examples_to_features(\n",
    "            eval_examples, label_list, max_seq_length, tokenizer)\n",
    "        claim_features = convert_claims_to_features(eval_examples, label_list, max_seq_length, tokenizer)    \n",
    "    \n",
    "        logger.info(\"***** Running evaluation *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "        logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "        \n",
    "        claims_input_ids = torch.tensor([f.input_ids for f in claim_features], dtype=torch.long)\n",
    "        claims_input_mask = torch.tensor([f.input_mask for f in claim_features], dtype=torch.long)\n",
    "        claims_segment_ids = torch.tensor([f.segment_ids for f in claim_features], dtype=torch.long)\n",
    "        claims_label_ids = torch.tensor([f.label_id for f in claim_features], dtype=torch.long)\n",
    "        \n",
    "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, claims_input_ids, claims_input_mask, claims_segment_ids, claims_label_ids)\n",
    "        # Run prediction for full data\n",
    "#         eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "#         print('all_input_ids:')\n",
    "#         print(all_input_ids)\n",
    "        \n",
    "        \n",
    "\n",
    "#         model.load_state_dict(torch.load(saved_model))\n",
    "        model_state_dict = torch.load(saved_model)\n",
    "        model = BertForConsistencyCueClassification.from_pretrained('bert-base-uncased', num_labels=2, state_dict=model_state_dict)\n",
    "        model.to(device)\n",
    "        \n",
    "        model.eval()\n",
    "        # eval_loss, eval_accuracy = 0, 0\n",
    "\n",
    "        eval_tp, eval_pred_c, eval_gold_c = 0, 0, 0\n",
    "        eval_loss, eval_macro_p, eval_macro_r = 0, 0, 0\n",
    "\n",
    "        raw_score = []\n",
    "\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "        for input_ids, input_mask, segment_ids, label_ids, claim_input_ids, claim_input_mask, claim_segment_ids, claim_label_ids in eval_dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "            claim_input_ids = claim_input_ids.to(device)\n",
    "            claim_input_mask = claim_input_mask.to(device)\n",
    "            claim_segment_ids = claim_segment_ids.to(device)\n",
    "            claim_label_ids = claim_label_ids.to(device)\n",
    "\n",
    "#             print(\"start\")\n",
    "#             print(input_ids)\n",
    "#             print(input_mask)\n",
    "#             print(segment_ids)\n",
    "#             print(label_ids)\n",
    "#             print(claim_input_ids)\n",
    "#             print(claim_input_mask)\n",
    "#             print(claim_segment_ids)\n",
    "#             print(claim_label_ids)\n",
    "#             print(\"end\")\n",
    "            with torch.no_grad():\n",
    "                tmp_eval_loss = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, labels=label_ids, input_ids2=claim_input_ids, token_type_ids2=claim_segment_ids, attention_mask2=claim_input_mask, labels2=claim_label_ids)\n",
    "                \n",
    "                logits = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, input_ids2=claim_input_ids, token_type_ids2=claim_segment_ids, attention_mask2=claim_input_mask)\n",
    "            \n",
    "            print(logits)\n",
    "#             print(logits[0])\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            print(logits)\n",
    "            label_ids = label_ids.to('cpu').numpy()\n",
    "#             print(label_ids)\n",
    "\n",
    "            # Micro F1 (aggregated tp, fp, fn counts across all examples)\n",
    "            tmp_tp, tmp_pred_c, tmp_gold_c = tp_pcount_gcount(logits, label_ids)\n",
    "            eval_tp += tmp_tp\n",
    "            eval_pred_c += tmp_pred_c\n",
    "            eval_gold_c += tmp_gold_c\n",
    "            \n",
    "            pred_label = np.argmax(logits, axis=1)\n",
    "            raw_score += zip(logits, pred_label, label_ids)\n",
    "            \n",
    "            # Macro F1 (averaged P, R across mini batches)\n",
    "            tmp_eval_p, tmp_eval_r, tmp_eval_f1 = p_r_f1(logits, label_ids)\n",
    "\n",
    "            eval_macro_p += tmp_eval_p\n",
    "            eval_macro_r += tmp_eval_r\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_examples += input_ids.size(0)\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "\n",
    "        # Micro F1 (aggregated tp, fp, fn counts across all examples)\n",
    "        eval_micro_p = eval_tp / eval_pred_c\n",
    "        eval_micro_r = eval_tp / eval_gold_c\n",
    "        eval_micro_f1 = 2 * eval_micro_p * eval_micro_r / (eval_micro_p + eval_micro_r)\n",
    "\n",
    "        # Macro F1 (averaged P, R across mini batches)\n",
    "        eval_macro_p = eval_macro_p / nb_eval_steps\n",
    "        eval_macro_r = eval_macro_r / nb_eval_steps\n",
    "        eval_macro_f1 = 2 * eval_macro_p * eval_macro_r / (eval_macro_p + eval_macro_r)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        result = {\n",
    "                  'eval_loss': eval_loss,\n",
    "                  'eval_micro_p': eval_micro_p,\n",
    "                  'eval_micro_r': eval_micro_r,\n",
    "                  'eval_micro_f1': eval_micro_f1,\n",
    "                  'eval_macro_p': eval_macro_p,\n",
    "                  'eval_macro_r': eval_macro_r,\n",
    "                  'eval_macro_f1': eval_macro_f1,\n",
    "#                   'global_step': global_step,\n",
    "#                   'loss': tr_loss/nb_tr_steps\n",
    "                  }\n",
    "\n",
    "        output_eval_file = os.path.join(output_dir, \"v5_cos_dev_eval_results.txt\")\n",
    "        output_raw_score = os.path.join(output_dir, \"v5_cos_dev_raw_score.csv\")\n",
    "        with open(output_eval_file, \"w\") as writer:\n",
    "            logger.info(\"***** Eval results *****\")\n",
    "            for key in sorted(result.keys()):\n",
    "                logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "        with open(output_raw_score, 'w') as fout:\n",
    "            fields = [\"undermine_score\", \"support_score\",\"predict_label\", \"gold\"]\n",
    "            writer = csv.DictWriter(fout, fieldnames=fields)\n",
    "            writer.writeheader()\n",
    "            for score, pred, gold in raw_score:\n",
    "                writer.writerow({\n",
    "                    \"undermine_score\": str(score[0]),\n",
    "                    \"support_score\": str(score[1]),\n",
    "                    \"predict_label\": str(pred),\n",
    "                    \"gold\": str(gold)\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiments():\n",
    "    data_dir = \"D:/Jupyter/data/dataset/perspective_stances/\"\n",
    "#     data_dir = \"/home/syg340/Dataset/\"\n",
    "\n",
    "    # data_dir_output = data_dir + \"output2/\"\n",
    "    data_dir_output = \"D:/Projects/Stance/Models/\"\n",
    "    train_and_test(data_dir=data_dir, do_train=True, do_eval=True, output_dir=data_dir_output,task_name=\"Mrpc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_with_pretrained():\n",
    "    bert_model = \"D:/Projects/Stance/Models/Consistency_Cues/cos_emb.pth\"\n",
    "    data_dir = \"D:/Jupyter/data/dataset/perspective_stances/\"\n",
    "    # data_dir_output = data_dir + \"output2/\"\n",
    "    ## v2: concat\n",
    "    ## v3: multiply\n",
    "    data_dir_output = \"D:/Projects/Stance/Evaluation/bert_dummy_output/cos_emb\"\n",
    "    train_and_test(data_dir=data_dir, do_train=False, do_eval=True, output_dir=data_dir_output,task_name=\"mrpc\",saved_model=bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2020 18:56:57 - INFO - run_classifier -   device cuda n_gpu 1 distributed training False\n",
      "05/04/2020 18:56:59 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\arsen\\.cache\\torch\\transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   guid: test-1\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] lessons would feel less broken . [SEP]\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 8220 2052 2514 2625 3714 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   guid: test-2\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] not enough fund ##ng . . . [SEP]\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2025 2438 4636 3070 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   guid: test-3\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] so much easier for parents ! [SEP]\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2061 2172 6082 2005 3008 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   guid: test-4\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] less need for homework . [SEP]\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2625 2342 2005 19453 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   *** Example ***\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   guid: test-5\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP] time to finish activities [SEP]\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 2051 2000 3926 3450 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:56:59 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   guid: test-1\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP]\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   guid: test-2\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP]\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   label: 0 (id = 0)\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   guid: test-3\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP]\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   guid: test-4\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP]\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   *** Claim Example ***\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   guid: test-5\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   tokens: [CLS] school day should be extended [SEP]\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_ids: 101 2082 2154 2323 2022 3668 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/04/2020 18:57:00 - INFO - run_classifier -   label: 1 (id = 1)\n",
      "05/04/2020 18:57:01 - INFO - run_classifier -   ***** Running evaluation *****\n",
      "05/04/2020 18:57:01 - INFO - run_classifier -     Num examples = 2773\n",
      "05/04/2020 18:57:01 - INFO - run_classifier -     Batch size = 8\n",
      "05/04/2020 18:57:02 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\arsen\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "05/04/2020 18:57:02 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file C:\\Users\\arsen\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\arsen\\AppData\\Local\\Temp\\tmp5viwdsdd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2020 18:57:05 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0515, -0.0181],\n",
      "        [-0.0517, -0.0180],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0514, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2802, -0.2851]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6808, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8058, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0515, -0.0181],\n",
      "        [-0.0517, -0.0180],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0514, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2802, -0.2851]], device='cuda:0')\n",
      "[[-0.27977967 -0.28498852]\n",
      " [-0.27959052 -0.28497428]\n",
      " [-0.27981746 -0.28502113]\n",
      " [-0.27980983 -0.28500932]\n",
      " [-0.2802535  -0.28503895]\n",
      " [-0.2804121  -0.28502113]\n",
      " [-0.2804786  -0.28501478]\n",
      " [-0.2802497  -0.28505084]]\n",
      "logits_ce:\n",
      "tensor([[-0.0518, -0.0180],\n",
      "        [-0.0517, -0.0181],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0512, -0.0183],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2805, -0.2850],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2802, -0.2851],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6890, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0640, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0518, -0.0180],\n",
      "        [-0.0517, -0.0181],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0512, -0.0183],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2805, -0.2850],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2802, -0.2851],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "[[-0.2804786  -0.28501478]\n",
      " [-0.28040233 -0.28502455]\n",
      " [-0.27977    -0.28499871]\n",
      " [-0.28047982 -0.2850105 ]\n",
      " [-0.2804883  -0.28501427]\n",
      " [-0.28010368 -0.28504372]\n",
      " [-0.28019235 -0.28505382]\n",
      " [-0.2796355  -0.28496626]]\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2798, -0.2850],\n",
      "        [-0.2802, -0.2851],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6974, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3224, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2798, -0.2850],\n",
      "        [-0.2802, -0.2851],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27983546 -0.28499162]\n",
      " [-0.28019235 -0.28505382]\n",
      " [-0.27978197 -0.28500134]\n",
      " [-0.27981436 -0.28500345]\n",
      " [-0.27976686 -0.2849885 ]\n",
      " [-0.2796203  -0.28497064]\n",
      " [-0.27979475 -0.28499228]\n",
      " [-0.2797786  -0.28498897]]\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0186],\n",
      "        [-0.0515, -0.0181],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0517, -0.0181]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2849],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2804, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6770, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.7136e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6770, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0186],\n",
      "        [-0.0515, -0.0181],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0517, -0.0181]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2849],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2804, -0.2850]], device='cuda:0')\n",
      "[[-0.27944046 -0.28493732]\n",
      " [-0.28029686 -0.28504056]\n",
      " [-0.27967262 -0.28496248]\n",
      " [-0.27971667 -0.28497708]\n",
      " [-0.28002548 -0.28502733]\n",
      " [-0.27972847 -0.28499347]\n",
      " [-0.27986407 -0.28501827]\n",
      " [-0.28040153 -0.28502333]]\n",
      "logits_ce:\n",
      "tensor([[-0.0510, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0505, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0512, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7095, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.0000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.7095, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0510, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0505, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0512, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "[[-0.27991426 -0.2850117 ]\n",
      " [-0.2797864  -0.2850017 ]\n",
      " [-0.27964398 -0.28497118]\n",
      " [-0.28005353 -0.28502798]\n",
      " [-0.2798956  -0.28500867]\n",
      " [-0.27951312 -0.28497288]\n",
      " [-0.2793017  -0.28492844]\n",
      " [-0.28006786 -0.28502995]]\n",
      "logits_ce:\n",
      "tensor([[-0.0512, -0.0183],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0508, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0512, -0.0183],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6975, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3225, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0512, -0.0183],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0508, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0512, -0.0183],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.28008503 -0.28503984]\n",
      " [-0.27971298 -0.28498745]\n",
      " [-0.27973706 -0.284984  ]\n",
      " [-0.27995116 -0.28501925]\n",
      " [-0.28010952 -0.28504276]\n",
      " [-0.27933797 -0.2849415 ]\n",
      " [-0.27920783 -0.28491414]\n",
      " [-0.27917242 -0.2849245 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0515, -0.0181],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0514, -0.0182],\n",
      "        [-0.0516, -0.0181]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2803, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2804, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0515, -0.0181],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0514, -0.0182],\n",
      "        [-0.0516, -0.0181]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2803, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2804, -0.2850]], device='cuda:0')\n",
      "[[-0.280309   -0.285046  ]\n",
      " [-0.28002164 -0.28503913]\n",
      " [-0.2798847  -0.28500497]\n",
      " [-0.27989626 -0.28501517]\n",
      " [-0.2792287  -0.28493637]\n",
      " [-0.27920875 -0.28492454]\n",
      " [-0.28023398 -0.285046  ]\n",
      " [-0.28035247 -0.28503296]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0187],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6853, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.2500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.9353, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0187],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "[[-0.2792005  -0.28492808]\n",
      " [-0.27984607 -0.28501937]\n",
      " [-0.27974936 -0.28499725]\n",
      " [-0.27995378 -0.28500566]\n",
      " [-0.2793475  -0.28492332]\n",
      " [-0.27903038 -0.28486866]\n",
      " [-0.2797125  -0.28496498]\n",
      " [-0.27931863 -0.28493172]]\n",
      "logits_ce:\n",
      "tensor([[-0.0513, -0.0182],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0513, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6895, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0645, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0513, -0.0182],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0513, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "[[-0.28014976 -0.28503123]\n",
      " [-0.27992553 -0.2849974 ]\n",
      " [-0.27963656 -0.28494602]\n",
      " [-0.2791425  -0.28489745]\n",
      " [-0.2792517  -0.284915  ]\n",
      " [-0.27907515 -0.2848994 ]\n",
      " [-0.27970004 -0.2849565 ]\n",
      " [-0.28012455 -0.28502393]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0499, -0.0190],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2788, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0499, -0.0190],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2788, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.27907914 -0.2849362 ]\n",
      " [-0.27924788 -0.28492093]\n",
      " [-0.27926433 -0.28494027]\n",
      " [-0.27883583 -0.2848794 ]\n",
      " [-0.27973062 -0.2849868 ]\n",
      " [-0.27975753 -0.28499657]\n",
      " [-0.27968848 -0.28497994]\n",
      " [-0.27971196 -0.2849828 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0513, -0.0182],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0515, -0.0181]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2803, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6810, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8060, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0513, -0.0182],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0515, -0.0181]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2803, -0.2850]], device='cuda:0')\n",
      "[[-0.28011113 -0.28502822]\n",
      " [-0.27961057 -0.28498065]\n",
      " [-0.27946752 -0.28495157]\n",
      " [-0.28014025 -0.28503388]\n",
      " [-0.27981752 -0.28499532]\n",
      " [-0.27948236 -0.2849519 ]\n",
      " [-0.27967042 -0.28499252]\n",
      " [-0.28027615 -0.28502452]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2799, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6933, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1933, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2799, -0.2850]], device='cuda:0')\n",
      "[[-0.27965456 -0.28496766]\n",
      " [-0.27966094 -0.2849837 ]\n",
      " [-0.2796692  -0.28497094]\n",
      " [-0.27988052 -0.28501523]\n",
      " [-0.2801091  -0.28503793]\n",
      " [-0.27910423 -0.28490654]\n",
      " [-0.27997345 -0.2850076 ]\n",
      " [-0.27986708 -0.2849974 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0514, -0.0181],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2802, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6773, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(2.1607e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6773, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0514, -0.0181],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2802, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "[[-0.2802477  -0.2850435 ]\n",
      " [-0.27924123 -0.2849477 ]\n",
      " [-0.27904457 -0.28492638]\n",
      " [-0.2793963  -0.28494447]\n",
      " [-0.27918744 -0.28491586]\n",
      " [-0.27981052 -0.28500342]\n",
      " [-0.27935272 -0.284954  ]\n",
      " [-0.27948004 -0.28496888]]\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0516, -0.0181],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0503, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2790, -0.2850],\n",
      "        [-0.2790, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6895, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0645, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0516, -0.0181],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0503, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2790, -0.2850],\n",
      "        [-0.2790, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.2791939  -0.28493035]\n",
      " [-0.28035933 -0.28503066]\n",
      " [-0.27958584 -0.28499696]\n",
      " [-0.2795864  -0.2849906 ]\n",
      " [-0.2790218  -0.28495458]\n",
      " [-0.27895683 -0.2849601 ]\n",
      " [-0.27983683 -0.28500775]\n",
      " [-0.2792424  -0.28490373]]\n",
      "logits_ce:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0504, -0.0186],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7012, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.7500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.4512, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0186],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2850]], device='cuda:0')\n",
      "[[-0.27934378 -0.28492177]\n",
      " [-0.27977717 -0.2849794 ]\n",
      " [-0.2793106  -0.28491682]\n",
      " [-0.27930248 -0.28493834]\n",
      " [-0.27929556 -0.2849214 ]\n",
      " [-0.27925307 -0.2849248 ]\n",
      " [-0.27929872 -0.2849357 ]\n",
      " [-0.2794284  -0.28495482]]\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.27925125 -0.284922  ]\n",
      " [-0.27942142 -0.28495765]\n",
      " [-0.27929837 -0.28493434]\n",
      " [-0.27924222 -0.284927  ]\n",
      " [-0.27955344 -0.28495786]\n",
      " [-0.27951658 -0.28495508]\n",
      " [-0.279492   -0.2849466 ]\n",
      " [-0.27922043 -0.28492677]]\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0186],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2794, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6853, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.2500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.9353, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0186],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2794, -0.2849]], device='cuda:0')\n",
      "[[-0.27951676 -0.28495875]\n",
      " [-0.27942473 -0.2849319 ]\n",
      " [-0.27916047 -0.28492603]\n",
      " [-0.2795961  -0.28496888]\n",
      " [-0.27969986 -0.2849928 ]\n",
      " [-0.27944833 -0.28494468]\n",
      " [-0.27945453 -0.28495133]\n",
      " [-0.27944762 -0.28494543]]\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6812, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8062, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27949083 -0.28495574]\n",
      " [-0.27970588 -0.28498238]\n",
      " [-0.27991626 -0.28500783]\n",
      " [-0.27964252 -0.28497863]\n",
      " [-0.2796536  -0.28497526]\n",
      " [-0.2797345  -0.28496996]\n",
      " [-0.27922976 -0.28491375]\n",
      " [-0.2798227  -0.28499907]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6772, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(2.6077e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6772, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27964622 -0.28497875]\n",
      " [-0.2794354  -0.28494453]\n",
      " [-0.279602   -0.28496194]\n",
      " [-0.27994    -0.28501767]\n",
      " [-0.27970713 -0.28496784]\n",
      " [-0.27947822 -0.28495902]\n",
      " [-0.27975345 -0.2849728 ]\n",
      " [-0.27977663 -0.2849809 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0510, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2800, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6891, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0641, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0510, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2800, -0.2850]], device='cuda:0')\n",
      "[[-0.2796295  -0.28496578]\n",
      " [-0.27955675 -0.28494096]\n",
      " [-0.2796965  -0.28496456]\n",
      " [-0.27956668 -0.28495443]\n",
      " [-0.27933604 -0.2849361 ]\n",
      " [-0.27897716 -0.28490767]\n",
      " [-0.27912104 -0.2849027 ]\n",
      " [-0.27998042 -0.2850076 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2794, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6972, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3222, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2794, -0.2849]], device='cuda:0')\n",
      "[[-0.27963012 -0.28496575]\n",
      " [-0.2797322  -0.28498542]\n",
      " [-0.2796753  -0.28496838]\n",
      " [-0.27954924 -0.28493983]\n",
      " [-0.27962917 -0.2849896 ]\n",
      " [-0.27956298 -0.28496736]\n",
      " [-0.27914047 -0.2849325 ]\n",
      " [-0.27943265 -0.28493077]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6813, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8063, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "[[-0.27946383 -0.28493732]\n",
      " [-0.2796023  -0.2849361 ]\n",
      " [-0.27949113 -0.28495246]\n",
      " [-0.27928028 -0.28491837]\n",
      " [-0.2794091  -0.28495318]\n",
      " [-0.27969992 -0.28498763]\n",
      " [-0.27962232 -0.2849838 ]\n",
      " [-0.27934414 -0.2849421 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0512, -0.0183],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0499, -0.0187],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6933, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1933, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0512, -0.0183],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0499, -0.0187],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.27961165 -0.28495312]\n",
      " [-0.27959    -0.28494895]\n",
      " [-0.279696   -0.28497875]\n",
      " [-0.280118   -0.28502005]\n",
      " [-0.28005248 -0.28501976]\n",
      " [-0.27938455 -0.28493798]\n",
      " [-0.27887627 -0.28486264]\n",
      " [-0.27916694 -0.2848775 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0500, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2788, -0.2849],\n",
      "        [-0.2790, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6933, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1933, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0500, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2788, -0.2849],\n",
      "        [-0.2790, -0.2849]], device='cuda:0')\n",
      "[[-0.27903655 -0.2848573 ]\n",
      " [-0.27894652 -0.28488496]\n",
      " [-0.27925813 -0.28487912]\n",
      " [-0.2789544  -0.2849444 ]\n",
      " [-0.27921814 -0.2849142 ]\n",
      " [-0.27896166 -0.28489548]\n",
      " [-0.2788381  -0.28492364]\n",
      " [-0.27897787 -0.28488958]]\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0507, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0513, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2789, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2797, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2848],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6892, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0642, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0507, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0513, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2789, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2797, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2848],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "[[-0.27892792 -0.28490964]\n",
      " [-0.2790209  -0.2849071 ]\n",
      " [-0.2796865  -0.2849498 ]\n",
      " [-0.27963036 -0.2849447 ]\n",
      " [-0.2794308  -0.28493533]\n",
      " [-0.2791689  -0.2848456 ]\n",
      " [-0.27919257 -0.28487605]\n",
      " [-0.280141   -0.28503096]]\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6774, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(2.6822e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6774, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.27960044 -0.28495574]\n",
      " [-0.2797221  -0.2849584 ]\n",
      " [-0.2791452  -0.2848764 ]\n",
      " [-0.2792728  -0.28490847]\n",
      " [-0.27927506 -0.2848781 ]\n",
      " [-0.27926606 -0.28486928]\n",
      " [-0.27949774 -0.28491625]\n",
      " [-0.2791937  -0.284858  ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0498, -0.0188],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2789, -0.2850],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2788, -0.2850],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6852, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.2500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.9352, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0498, -0.0188],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2789, -0.2850],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2788, -0.2850],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27931404 -0.28488696]\n",
      " [-0.27890894 -0.28495204]\n",
      " [-0.27887642 -0.28492138]\n",
      " [-0.27879483 -0.28496003]\n",
      " [-0.279298   -0.28495574]\n",
      " [-0.2799554  -0.28501606]\n",
      " [-0.27948487 -0.28494775]\n",
      " [-0.27980122 -0.28500435]]\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2795, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6813, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8063, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2796, -0.2849],\n",
      "        [-0.2795, -0.2849]], device='cuda:0')\n",
      "[[-0.27941    -0.28494042]\n",
      " [-0.27951908 -0.28494525]\n",
      " [-0.2798277  -0.28499398]\n",
      " [-0.27991465 -0.28500143]\n",
      " [-0.27944422 -0.2849412 ]\n",
      " [-0.27955103 -0.284946  ]\n",
      " [-0.27962005 -0.2849446 ]\n",
      " [-0.27953607 -0.28494287]]\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6973, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3223, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "[[-0.2797488  -0.28497237]\n",
      " [-0.27934515 -0.2849381 ]\n",
      " [-0.2791713  -0.2849025 ]\n",
      " [-0.27977985 -0.28498697]\n",
      " [-0.27969897 -0.28497016]\n",
      " [-0.27925342 -0.28491077]\n",
      " [-0.27964658 -0.28496137]\n",
      " [-0.27957746 -0.2849607 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0184],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0188],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7012, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.7500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.4512, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0184],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0188],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "[[-0.27949405 -0.2849524 ]\n",
      " [-0.27910757 -0.28489462]\n",
      " [-0.2789886  -0.28490603]\n",
      " [-0.27952176 -0.2849522 ]\n",
      " [-0.27905208 -0.28489712]\n",
      " [-0.27907658 -0.28488728]\n",
      " [-0.27954054 -0.28495574]\n",
      " [-0.2791309  -0.28491083]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6815, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8065, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.27904755 -0.2849146 ]\n",
      " [-0.27922153 -0.28492284]\n",
      " [-0.27913228 -0.2848984 ]\n",
      " [-0.27903548 -0.28489226]\n",
      " [-0.27915835 -0.28491053]\n",
      " [-0.2791323  -0.2848956 ]\n",
      " [-0.2790568  -0.28488344]\n",
      " [-0.27916384 -0.28487766]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6776, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(2.2352e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6776, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2792, -0.2849]], device='cuda:0')\n",
      "[[-0.27908152 -0.284889  ]\n",
      " [-0.27910137 -0.28488553]\n",
      " [-0.27908796 -0.28491086]\n",
      " [-0.27906585 -0.28487438]\n",
      " [-0.27897632 -0.28485543]\n",
      " [-0.27917784 -0.2848891 ]\n",
      " [-0.27902836 -0.28486985]\n",
      " [-0.27917522 -0.28489068]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6775, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.6391e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6775, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "[[-0.2791199  -0.28489438]\n",
      " [-0.27930218 -0.28490555]\n",
      " [-0.27911967 -0.28489184]\n",
      " [-0.27909523 -0.28488335]\n",
      " [-0.27904928 -0.284881  ]\n",
      " [-0.27905053 -0.28487054]\n",
      " [-0.27916706 -0.2848994 ]\n",
      " [-0.2790887  -0.28490204]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6774, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.4156e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6774, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "[[-0.279089   -0.28490672]\n",
      " [-0.27929458 -0.28491086]\n",
      " [-0.27918324 -0.28489786]\n",
      " [-0.2792561  -0.2849062 ]\n",
      " [-0.27933082 -0.28491783]\n",
      " [-0.27940965 -0.2849229 ]\n",
      " [-0.27922946 -0.28490752]\n",
      " [-0.27933323 -0.28491935]]\n",
      "logits_ce:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0514, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0512, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6973, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3223, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0514, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0512, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "[[-0.27930543 -0.28491932]\n",
      " [-0.27959052 -0.28495115]\n",
      " [-0.2801915  -0.2850276 ]\n",
      " [-0.2796395  -0.28497878]\n",
      " [-0.28001547 -0.28501087]\n",
      " [-0.27967423 -0.2849651 ]\n",
      " [-0.2800098  -0.285013  ]\n",
      " [-0.2800771  -0.2850156 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0514, -0.0181],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6770, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.7881e-07, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.6770, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0514, -0.0181],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.27956566 -0.28496814]\n",
      " [-0.27984402 -0.28497973]\n",
      " [-0.27977937 -0.2849648 ]\n",
      " [-0.27974987 -0.28495848]\n",
      " [-0.27982792 -0.28496632]\n",
      " [-0.2796315  -0.28495532]\n",
      " [-0.280235   -0.2850265 ]\n",
      " [-0.2796619  -0.28497285]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6932, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1932, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2849]], device='cuda:0')\n",
      "[[-0.27961853 -0.28498352]\n",
      " [-0.2799171  -0.28499797]\n",
      " [-0.27984092 -0.28498602]\n",
      " [-0.27989566 -0.28499782]\n",
      " [-0.27959433 -0.28496045]\n",
      " [-0.27978814 -0.28496462]\n",
      " [-0.2796419  -0.28496268]\n",
      " [-0.2795429  -0.28494775]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0499, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0500, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2789, -0.2848],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2790, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6932, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1932, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0499, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0500, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2789, -0.2848],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2790, -0.2849]], device='cuda:0')\n",
      "[[-0.2796543  -0.28496277]\n",
      " [-0.27902895 -0.2849219 ]\n",
      " [-0.27887994 -0.28487203]\n",
      " [-0.27894044 -0.28484023]\n",
      " [-0.27890375 -0.2849021 ]\n",
      " [-0.27946472 -0.2849404 ]\n",
      " [-0.27947605 -0.28494132]\n",
      " [-0.27897984 -0.28490865]]\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0498, -0.0190],\n",
      "        [-0.0499, -0.0189],\n",
      "        [-0.0498, -0.0190],\n",
      "        [-0.0498, -0.0190],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2789, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2786, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0498, -0.0190],\n",
      "        [-0.0499, -0.0189],\n",
      "        [-0.0498, -0.0190],\n",
      "        [-0.0498, -0.0190],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2789, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2786, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "[[-0.27892494 -0.2848693 ]\n",
      " [-0.27866286 -0.28490272]\n",
      " [-0.27873966 -0.2849157 ]\n",
      " [-0.27865943 -0.28490943]\n",
      " [-0.27863497 -0.28489244]\n",
      " [-0.27919912 -0.28489757]\n",
      " [-0.27915254 -0.28490597]\n",
      " [-0.27964717 -0.28496394]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7013, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.7500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.4513, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.2791456  -0.28489104]\n",
      " [-0.27918425 -0.284918  ]\n",
      " [-0.2796076  -0.28495455]\n",
      " [-0.28004533 -0.2850244 ]\n",
      " [-0.27908075 -0.28489694]\n",
      " [-0.27926865 -0.28490353]\n",
      " [-0.27944294 -0.28493738]\n",
      " [-0.27969885 -0.2849796 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0501, -0.0187]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0501, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "[[-0.2794248  -0.28493848]\n",
      " [-0.27945757 -0.28493315]\n",
      " [-0.2793044  -0.28492182]\n",
      " [-0.2791955  -0.28486878]\n",
      " [-0.27986825 -0.28499755]\n",
      " [-0.2798436  -0.28500473]\n",
      " [-0.2796015  -0.28497052]\n",
      " [-0.27905315 -0.28489122]]\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2794, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7054, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.8750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.5804, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0504, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2794, -0.2849]], device='cuda:0')\n",
      "[[-0.27930662 -0.2849338 ]\n",
      " [-0.27929753 -0.28496122]\n",
      " [-0.28002495 -0.2850247 ]\n",
      " [-0.2793835  -0.28494725]\n",
      " [-0.279525   -0.28495222]\n",
      " [-0.27952474 -0.28496462]\n",
      " [-0.27990538 -0.28500712]\n",
      " [-0.27936366 -0.28493994]]\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0502, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "[[-0.2792462  -0.2849186 ]\n",
      " [-0.27958387 -0.2849532 ]\n",
      " [-0.2791777  -0.28490782]\n",
      " [-0.2795611  -0.28496552]\n",
      " [-0.27960116 -0.28497934]\n",
      " [-0.27919292 -0.2849332 ]\n",
      " [-0.2793077  -0.28492975]\n",
      " [-0.27914822 -0.28490517]]\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6933, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1933, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "[[-0.27911127 -0.2849352 ]\n",
      " [-0.27905995 -0.28489453]\n",
      " [-0.2792171  -0.2849247 ]\n",
      " [-0.27961177 -0.28496504]\n",
      " [-0.27926546 -0.28493255]\n",
      " [-0.27964866 -0.28496373]\n",
      " [-0.2792814  -0.28492895]\n",
      " [-0.2795276  -0.28496853]]\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0498, -0.0189],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2788, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6851, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.2500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.9351, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0505, -0.0185],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0498, -0.0189],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2788, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "[[-0.2794662  -0.28496233]\n",
      " [-0.27977267 -0.2849946 ]\n",
      " [-0.2797373  -0.2849854 ]\n",
      " [-0.2798716  -0.2849974 ]\n",
      " [-0.27950513 -0.28493732]\n",
      " [-0.27879766 -0.28490764]\n",
      " [-0.27950516 -0.2849685 ]\n",
      " [-0.27948695 -0.2849584 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0500, -0.0188],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6815, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8065, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0500, -0.0188],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2849]], device='cuda:0')\n",
      "[[-0.27909452 -0.2849293 ]\n",
      " [-0.2789266  -0.2848929 ]\n",
      " [-0.279141   -0.28491777]\n",
      " [-0.27903557 -0.28492567]\n",
      " [-0.27895224 -0.28493354]\n",
      " [-0.2793091  -0.28493375]\n",
      " [-0.27934188 -0.28494835]\n",
      " [-0.2794609  -0.28494677]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0501, -0.0188],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0499, -0.0189]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2850],\n",
      "        [-0.2788, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6934, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1934, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0501, -0.0188],\n",
      "        [-0.0499, -0.0188],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0499, -0.0189]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2850],\n",
      "        [-0.2788, -0.2850]], device='cuda:0')\n",
      "[[-0.27965194 -0.2849526 ]\n",
      " [-0.2790187  -0.28493506]\n",
      " [-0.27888918 -0.28490323]\n",
      " [-0.2791248  -0.2849323 ]\n",
      " [-0.2790838  -0.28494334]\n",
      " [-0.2795148  -0.28494227]\n",
      " [-0.2791736  -0.28495103]\n",
      " [-0.2787584  -0.2849692 ]]\n",
      "logits_ce:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7013, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.7500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.4513, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0506, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "[[-0.27911723 -0.2849078 ]\n",
      " [-0.27903652 -0.28491995]\n",
      " [-0.27965057 -0.2849552 ]\n",
      " [-0.27913618 -0.2849204 ]\n",
      " [-0.2790577  -0.28493592]\n",
      " [-0.27947092 -0.2849332 ]\n",
      " [-0.27924842 -0.284925  ]\n",
      " [-0.27962294 -0.2849586 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0185],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0514, -0.0181],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0503, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2848],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6812, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8062, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0503, -0.0185],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0501, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0514, -0.0181],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0503, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2791, -0.2848],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "[[-0.2792654  -0.28492776]\n",
      " [-0.27925417 -0.28490394]\n",
      " [-0.2790956  -0.28484792]\n",
      " [-0.2796386  -0.284966  ]\n",
      " [-0.27936336 -0.28491384]\n",
      " [-0.28015983 -0.2850121 ]\n",
      " [-0.2796247  -0.28495532]\n",
      " [-0.27934653 -0.2848885 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0183],\n",
      "        [-0.0510, -0.0182],\n",
      "        [-0.0507, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0498, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0499, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2789, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7092, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.0000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.7092, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0183],\n",
      "        [-0.0510, -0.0182],\n",
      "        [-0.0507, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0498, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0499, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2787, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2789, -0.2849]], device='cuda:0')\n",
      "[[-0.27970123 -0.2849625 ]\n",
      " [-0.27994055 -0.28501773]\n",
      " [-0.27973056 -0.28494442]\n",
      " [-0.27952978 -0.28494614]\n",
      " [-0.27894646 -0.28488278]\n",
      " [-0.27873933 -0.28489462]\n",
      " [-0.2788852  -0.2848965 ]\n",
      " [-0.2789274  -0.28493816]]\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0188],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2790, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2790, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6853, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.2500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.9353, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0500, -0.0188],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2790, -0.2849],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2790, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2789, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "[[-0.27899235 -0.284945  ]\n",
      " [-0.27900696 -0.28493476]\n",
      " [-0.27900168 -0.28495723]\n",
      " [-0.27897084 -0.28493595]\n",
      " [-0.27892828 -0.28493506]\n",
      " [-0.27954525 -0.28496215]\n",
      " [-0.279774   -0.2849928 ]\n",
      " [-0.27961928 -0.28499484]]\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0515, -0.0181],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0510, -0.0182],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6932, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1932, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0505, -0.0184],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0515, -0.0181],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0510, -0.0182],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2795, -0.2849],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.27974594 -0.28498676]\n",
      " [-0.27929646 -0.28489453]\n",
      " [-0.27950293 -0.28489476]\n",
      " [-0.27961293 -0.28495193]\n",
      " [-0.28028715 -0.28503424]\n",
      " [-0.27974617 -0.2849541 ]\n",
      " [-0.27987683 -0.28498155]\n",
      " [-0.27965218 -0.28495818]]\n",
      "logits_ce:\n",
      "tensor([[-0.0509, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6974, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3224, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0509, -0.0183],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.2798691  -0.28499153]\n",
      " [-0.27971452 -0.28495908]\n",
      " [-0.27987364 -0.28499043]\n",
      " [-0.27984464 -0.28496832]\n",
      " [-0.27998078 -0.2849974 ]\n",
      " [-0.27966136 -0.2849686 ]\n",
      " [-0.27987283 -0.28500804]\n",
      " [-0.27970627 -0.28499997]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0502, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0503, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6933, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1933, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0502, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0503, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "[[-0.27963877 -0.28499454]\n",
      " [-0.27998957 -0.285     ]\n",
      " [-0.27927035 -0.28485996]\n",
      " [-0.27941483 -0.2849231 ]\n",
      " [-0.27976108 -0.2849887 ]\n",
      " [-0.2791878  -0.2848831 ]\n",
      " [-0.2800591  -0.2850086 ]\n",
      " [-0.2793274  -0.2849383 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0509, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6853, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.2500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.9353, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0183],\n",
      "        [-0.0506, -0.0184],\n",
      "        [-0.0503, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0511, -0.0182],\n",
      "        [-0.0509, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2798, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27979988 -0.28497738]\n",
      " [-0.2796176  -0.28498012]\n",
      " [-0.27929282 -0.28494972]\n",
      " [-0.27996048 -0.28499687]\n",
      " [-0.27984557 -0.2849843 ]\n",
      " [-0.27927387 -0.28493145]\n",
      " [-0.28002656 -0.2850002 ]\n",
      " [-0.27982235 -0.28497982]]\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0503, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2849],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6935, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1935, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0185],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0518, -0.0180],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0503, -0.0186]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2849],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2805, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2793, -0.2849]], device='cuda:0')\n",
      "[[-0.2795785  -0.28494793]\n",
      " [-0.27993542 -0.2850057 ]\n",
      " [-0.2801038  -0.28501016]\n",
      " [-0.28048015 -0.28499687]\n",
      " [-0.27975672 -0.28500634]\n",
      " [-0.27983236 -0.2850082 ]\n",
      " [-0.2793381  -0.28494263]\n",
      " [-0.2792859  -0.2849426 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0516, -0.0180],\n",
      "        [-0.0514, -0.0181],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0497, -0.0190]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2785, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6933, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1933, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0500, -0.0187],\n",
      "        [-0.0516, -0.0180],\n",
      "        [-0.0514, -0.0181],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0497, -0.0190]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2785, -0.2850]], device='cuda:0')\n",
      "[[-0.2797019  -0.28500873]\n",
      " [-0.27973127 -0.28498036]\n",
      " [-0.27979252 -0.28497478]\n",
      " [-0.27903086 -0.28486776]\n",
      " [-0.28037262 -0.28501675]\n",
      " [-0.28024253 -0.28503174]\n",
      " [-0.2801528  -0.28503036]\n",
      " [-0.27851582 -0.28496632]]\n",
      "logits_ce:\n",
      "tensor([[-0.0513, -0.0182],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0513, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6891, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0641, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0513, -0.0182],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0511, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0513, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2800, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "[[-0.28013968 -0.2850064 ]\n",
      " [-0.28002024 -0.28500727]\n",
      " [-0.28010654 -0.2850206 ]\n",
      " [-0.28009373 -0.28499767]\n",
      " [-0.27980027 -0.2849583 ]\n",
      " [-0.27995974 -0.2849955 ]\n",
      " [-0.27986845 -0.28498703]\n",
      " [-0.28014654 -0.28500736]]\n",
      "logits_ce:\n",
      "tensor([[-0.0512, -0.0182],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2797, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2799, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6810, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.1250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(0.8060, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0512, -0.0182],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0513, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0509, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2801, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2802, -0.2850],\n",
      "        [-0.2797, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2799, -0.2850]], device='cuda:0')\n",
      "[[-0.28006947 -0.28501302]\n",
      " [-0.27990395 -0.28498513]\n",
      " [-0.28015915 -0.285021  ]\n",
      " [-0.27973992 -0.2849437 ]\n",
      " [-0.27980524 -0.2849716 ]\n",
      " [-0.27992725 -0.28498667]\n",
      " [-0.27990133 -0.28498125]\n",
      " [-0.2798531  -0.28495473]]\n",
      "logits_ce:\n",
      "tensor([[-0.0499, -0.0188],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0500, -0.0188],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0501, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2789, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6934, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.5000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.1934, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0499, -0.0188],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0502, -0.0187],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0500, -0.0188],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0501, -0.0187]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2789, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2790, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2791, -0.2849]], device='cuda:0')\n",
      "[[-0.2789051  -0.2849191 ]\n",
      " [-0.27930152 -0.28493685]\n",
      " [-0.2792347  -0.28493002]\n",
      " [-0.2795267  -0.28497022]\n",
      " [-0.27899724 -0.2849095 ]\n",
      " [-0.27942675 -0.28496864]\n",
      " [-0.27950245 -0.28497344]\n",
      " [-0.27908692 -0.28493932]]\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0516, -0.0180],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0508, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6975, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3225, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0516, -0.0180],\n",
      "        [-0.0508, -0.0183],\n",
      "        [-0.0508, -0.0183]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2792, -0.2849],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2804, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.27919948 -0.28494856]\n",
      " [-0.27937198 -0.2849683 ]\n",
      " [-0.2793079  -0.28496295]\n",
      " [-0.2793823  -0.28496575]\n",
      " [-0.27980304 -0.28497514]\n",
      " [-0.28037435 -0.28500122]\n",
      " [-0.27982318 -0.28498435]\n",
      " [-0.27974045 -0.28498292]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0516, -0.0181],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0512, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0516, -0.0181],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0502, -0.0186],\n",
      "        [-0.0512, -0.0182]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2803, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2792, -0.2849],\n",
      "        [-0.2801, -0.2850]], device='cuda:0')\n",
      "[[-0.27973765 -0.28497228]\n",
      " [-0.2796666  -0.28495055]\n",
      " [-0.2803258  -0.2850072 ]\n",
      " [-0.27983782 -0.28498387]\n",
      " [-0.27972382 -0.28496146]\n",
      " [-0.27941233 -0.28493455]\n",
      " [-0.27916205 -0.28490567]\n",
      " [-0.28005195 -0.28502095]]\n",
      "logits_ce:\n",
      "tensor([[-0.0509, -0.0183],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2799, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6893, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0643, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0509, -0.0183],\n",
      "        [-0.0501, -0.0187],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0509, -0.0183],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2799, -0.2850],\n",
      "        [-0.2791, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "[[-0.279856   -0.2850076 ]\n",
      " [-0.27911568 -0.2849219 ]\n",
      " [-0.27948362 -0.28495556]\n",
      " [-0.27949452 -0.28495508]\n",
      " [-0.27982002 -0.2850039 ]\n",
      " [-0.27951068 -0.2849512 ]\n",
      " [-0.2794103  -0.2849594 ]\n",
      " [-0.2795191  -0.28496578]]\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7013, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.7500, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.4513, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2794, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2796, -0.2850]], device='cuda:0')\n",
      "[[-0.27939427 -0.28495193]\n",
      " [-0.2794931  -0.28497142]\n",
      " [-0.2795577  -0.28498173]\n",
      " [-0.2793735  -0.28494984]\n",
      " [-0.27949363 -0.2849739 ]\n",
      " [-0.27955627 -0.28497624]\n",
      " [-0.27941677 -0.28495574]\n",
      " [-0.27958375 -0.2849751 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6973, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3223, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0504, -0.0185],\n",
      "        [-0.0507, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0503, -0.0186],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2794, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2793, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27970976 -0.28499657]\n",
      " [-0.2795785  -0.28497213]\n",
      " [-0.2793793  -0.2849607 ]\n",
      " [-0.27969435 -0.28499264]\n",
      " [-0.2795324  -0.28496647]\n",
      " [-0.27926403 -0.28495407]\n",
      " [-0.27968594 -0.2849967 ]\n",
      " [-0.27975142 -0.28501487]]\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6974, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.6250, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.3224, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0506, -0.0184],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0505, -0.0185],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.2796067  -0.28498176]\n",
      " [-0.27950197 -0.2849687 ]\n",
      " [-0.2795137  -0.28497216]\n",
      " [-0.2795875  -0.28498393]\n",
      " [-0.27980435 -0.2850126 ]\n",
      " [-0.27985936 -0.28501266]\n",
      " [-0.27972966 -0.2850027 ]\n",
      " [-0.27966315 -0.28498983]]\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7095, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(1.0000, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.7095, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0508, -0.0184],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0509, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0510, -0.0183],\n",
      "        [-0.0508, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2794, -0.2849],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2799, -0.2850],\n",
      "        [-0.2798, -0.2850]], device='cuda:0')\n",
      "[[-0.27974123 -0.28499228]\n",
      " [-0.27935833 -0.28494948]\n",
      " [-0.27979377 -0.2850131 ]\n",
      " [-0.27973437 -0.2850088 ]\n",
      " [-0.2796703  -0.28499314]\n",
      " [-0.27975482 -0.28500307]\n",
      " [-0.27990547 -0.28502744]\n",
      " [-0.27977765 -0.28499705]]\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.7054, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.8750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.5804, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0506, -0.0185],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0506, -0.0185]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2798, -0.2850],\n",
      "        [-0.2795, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2796, -0.2850],\n",
      "        [-0.2795, -0.2850]], device='cuda:0')\n",
      "[[-0.27966785 -0.28500122]\n",
      " [-0.27969277 -0.28498107]\n",
      " [-0.27975976 -0.2849939 ]\n",
      " [-0.2795133  -0.28496945]\n",
      " [-0.27963    -0.28496975]\n",
      " [-0.27971715 -0.28498682]\n",
      " [-0.27964658 -0.28498328]\n",
      " [-0.27954143 -0.2849785 ]]\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "loss_ce:\n",
      "tensor(0.6894, device='cuda:0')\n",
      "loss_cos:\n",
      "tensor(0.3750, device='cuda:0')\n",
      "final loss:\n",
      "tensor(1.0644, device='cuda:0')\n",
      "logits_ce:\n",
      "tensor([[-0.0502, -0.0186],\n",
      "        [-0.0504, -0.0186],\n",
      "        [-0.0512, -0.0182],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0508, -0.0184],\n",
      "        [-0.0507, -0.0184],\n",
      "        [-0.0507, -0.0184]], device='cuda:0')\n",
      "logits_cos:\n",
      "tensor([[-0.2791, -0.2849],\n",
      "        [-0.2793, -0.2849],\n",
      "        [-0.2801, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850],\n",
      "        [-0.2797, -0.2850]], device='cuda:0')\n",
      "[[-0.27914393 -0.28494364]\n",
      " [-0.27934742 -0.28494763]\n",
      " [-0.28005713 -0.28503725]\n",
      " [-0.27966112 -0.28498727]\n",
      " [-0.27974093 -0.28500116]\n",
      " [-0.27973807 -0.2849947 ]\n",
      " [-0.27967346 -0.2849724 ]\n",
      " [-0.27965558 -0.28500712]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-70908a0f3daf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#     experiments()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mevaluation_with_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-f78e1a5e62df>\u001b[0m in \u001b[0;36mevaluation_with_pretrained\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m## v3: multiply\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdata_dir_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"D:/Projects/Stance/Evaluation/bert_dummy_output/cos_emb\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain_and_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dir_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mrpc\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-c3347218546b>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[1;34m(data_dir, bert_model, task_name, output_dir, max_seq_length, do_train, do_eval, do_lower_case, train_batch_size, eval_batch_size, learning_rate, num_train_epochs, warmup_proportion, no_cuda, local_rank, seed, gradient_accumulation_steps, optimize_on_cpu, fp16, loss_scale, saved_model)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;31m#             print(\"end\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                 \u001b[0mtmp_eval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_segment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_label_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_segment_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclaim_input_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-29d3ae39e15c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, input_ids2, attention_mask2, token_type_ids2, position_ids2, head_mask2, inputs_embeds2, labels2)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;31m#             position_ids=position_ids,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m#             head_mask=head_mask,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[0;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[0;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[0;32m    734\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_tensor, attention_mask)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[0mself_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\dropout.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m    805\u001b[0m     return (_VF.dropout_(input, p, training)\n\u001b[0;32m    806\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m             else _VF.dropout(input, p, training))\n\u001b[0m\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     experiments()\n",
    "    evaluation_with_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
